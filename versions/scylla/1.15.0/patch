diff --git a/.github/workflows/bench-tests.yml b/.github/workflows/bench-tests.yml
new file mode 100644
index 0000000..854bb31
--- /dev/null
+++ b/.github/workflows/bench-tests.yml
@@ -0,0 +1,20 @@
+name: Run benchmark tests
+
+on:
+  push:
+    branches:
+      - master
+  pull_request:
+    types: [opened, synchronize, reopened]
+
+jobs:
+  bench-tests:
+    if: contains(github.event.pull_request.labels.*.name, 'run-benchmark-tests')
+    name: Run benchmark tests
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - uses: actions/setup-go@v5
+
+      - name: Run benchmark tests
+        run: make test-bench
diff --git a/.github/workflows/main.yml b/.github/workflows/main.yml
index 95c653e..da6e845 100644
--- a/.github/workflows/main.yml
+++ b/.github/workflows/main.yml
@@ -11,31 +11,21 @@ jobs:
   build:
     name: Build
     runs-on: ubuntu-latest
-    env:
-      SCYLLA_IMAGE: scylladb/scylla:6.1.1
     steps:
       - uses: actions/checkout@v4
       - uses: actions/setup-go@v5
-      - uses: actions/cache@v4
-        id: gomod-cache
-        with:
-          path: ~/go/pkg/mod
-          key: ${{ runner.os }}-go-${{ hashFiles('go.mod') }}
-          restore-keys: |
-            ${{ runner.os }}-go-

-      - run: go vet ./...
+      - name: Run linters
+        run: make check

       - name: Run unit tests
-        run: go test -tags unit -race ./...
-
-      - name: Setup environment
-        uses: ./.github/actions/setup-environment
-        with:
-          ccm_version: 'master'
-          java_version: '11'
-          docker_compose_version: '2.20.0'
+        run: make test-unit

       - run: sudo sh -c "echo 2097152 >> /proc/sys/fs/aio-max-nr"
-      - run: ./integration.sh integration
-      - run: ./integration.sh ccm
+
+      - name: Run integration suite
+        run: make test-integration-scylla
+
+      - name: Run CCM integration suite
+        run: TEST_INTEGRATION_TAGS="ccm gocql_debug" make test-integration-scylla
+
diff --git a/.gitignore b/.gitignore
index bce6cf5..4f1b2e3 100644
--- a/.gitignore
+++ b/.gitignore
@@ -3,3 +3,9 @@ fuzz-corpus
 fuzz-work
 gocql.test
 .idea
+
+testdata/pki/.keystore
+testdata/pki/.truststore
+testdata/pki/*.crt
+testdata/pki/*.key
+testdata/pki/*.p12
\ No newline at end of file
diff --git a/Makefile b/Makefile
index 65dae37..1d3dc5a 100644
--- a/Makefile
+++ b/Makefile
@@ -1,5 +1,213 @@
-# Makefile to run the Docker cleanup script
+SHELL := bash
+MAKEFILE_PATH := $(abspath $(dir $(abspath $(lastword $(MAKEFILE_LIST)))))
+KEY_PATH = ${MAKEFILE_PATH}/testdata/pki

-clean-old-temporary-docker-images:
-	@echo "Running Docker Hub image cleanup script..."
-	python ci/clean-old-temporary-docker-images.py
+CASSANDRA_VERSION ?= 4.1.6
+SCYLLA_VERSION ?= release:6.1.1
+
+TEST_CQL_PROTOCOL ?= 4
+TEST_COMPRESSOR ?= snappy
+TEST_OPTS ?=
+TEST_INTEGRATION_TAGS ?= integration gocql_debug
+JVM_EXTRA_OPTS ?= -Dcassandra.test.fail_writes_ks=test -Dcassandra.custom_query_handler_class=org.apache.cassandra.cql3.CustomPayloadMirroringQueryHandler
+
+CCM_CASSANDRA_CLUSTER_NAME = gocql_cassandra_integration_test
+CCM_CASSANDRA_IP_PREFIX = 127.0.1.
+CCM_CASSANDRA_REPO ?= github.com/apache/cassandra-ccm
+CCM_CASSANDRA_VERSION ?= d3225ac6565242b231129e0c4f8f0b7a041219cf
+
+CCM_SCYLLA_CLUSTER_NAME = gocql_scylla_integration_test
+CCM_SCYLLA_IP_PREFIX = 127.0.2.
+CCM_SCYLLA_REPO ?= github.com/scylladb/scylla-ccm
+CCM_SCYLLA_VERSION ?= master
+
+ifeq (${CCM_CONFIG_DIR},)
+	CCM_CONFIG_DIR = ~/.ccm
+endif
+CCM_CONFIG_DIR := $(shell readlink --canonicalize ${CCM_CONFIG_DIR})
+
+CASSANDRA_CONFIG ?= "client_encryption_options.enabled: true" \
+"client_encryption_options.keystore: ${KEY_PATH}/.keystore" \
+"client_encryption_options.keystore_password: cassandra" \
+"client_encryption_options.require_client_auth: true" \
+"client_encryption_options.truststore: ${KEY_PATH}/.truststore" \
+"client_encryption_options.truststore_password: cassandra" \
+"concurrent_reads: 2" \
+"concurrent_writes: 2" \
+"write_request_timeout_in_ms: 5000" \
+"read_request_timeout_in_ms: 5000"
+
+ifeq ($(shell echo "${CASSANDRA_VERSION}" | grep -oP "3\.[0-9]+\.[0-9]+" ),${CASSANDRA_VERSION})
+	CASSANDRA_CONFIG += "rpc_server_type: sync" \
+"rpc_min_threads: 2" \
+"rpc_max_threads: 2" \
+"enable_user_defined_functions: true" \
+"enable_materialized_views: true" \
+
+else ifeq ($(shell echo "${CASSANDRA_VERSION}" | grep -oP "4\.0\.[0-9]+" ),${CASSANDRA_VERSION})
+	CASSANDRA_CONFIG +=	"enable_user_defined_functions: true" \
+"enable_materialized_views: true"
+else
+	CASSANDRA_CONFIG += "user_defined_functions_enabled: true" \
+"materialized_views_enabled: true"
+endif
+
+SCYLLA_CONFIG = "native_transport_port_ssl: 9142" \
+"native_transport_port: 9042" \
+"native_shard_aware_transport_port: 19042" \
+"native_shard_aware_transport_port_ssl: 19142" \
+"client_encryption_options.enabled: true" \
+"client_encryption_options.certificate: ${KEY_PATH}/cassandra.crt" \
+"client_encryption_options.keyfile: ${KEY_PATH}/cassandra.key" \
+"client_encryption_options.truststore: ${KEY_PATH}/ca.crt" \
+"client_encryption_options.require_client_auth: true" \
+"maintenance_socket: workdir" \
+"enable_tablets: true" \
+"enable_user_defined_functions: true" \
+"experimental_features: [udf]"
+
+export JVM_EXTRA_OPTS
+export JAVA11_HOME=${JAVA_HOME_11_X64}
+export JAVA17_HOME=${JAVA_HOME_17_X64}
+export JAVA_HOME=${JAVA_HOME_11_X64}
+
+cassandra-start: .prepare-pki .prepare-cassandra-ccm .prepare-java
+	@if [ -d ${CCM_CONFIG_DIR}/${CCM_CASSANDRA_CLUSTER_NAME} ] && ccm switch ${CCM_CASSANDRA_CLUSTER_NAME} 2>/dev/null 1>&2 && ccm status | grep UP 2>/dev/null 1>&2; then \
+		echo "Cassandra cluster is already started"; \
+  	else \
+		echo "Start cassandra ${CASSANDRA_VERSION} cluster"; \
+		ccm stop ${CCM_CASSANDRA_CLUSTER_NAME} 2>/dev/null 1>&2 || true; \
+		ccm remove ${CCM_CASSANDRA_CLUSTER_NAME} 2>/dev/null 1>&2 || true; \
+		ccm create ${CCM_CASSANDRA_CLUSTER_NAME} -i ${CCM_CASSANDRA_IP_PREFIX} -v ${CASSANDRA_VERSION} -n 3 -d --vnodes --jvm_arg="-Xmx256m -XX:NewSize=100m" && \
+		ccm updateconf ${CASSANDRA_CONFIG} && \
+		ccm start --wait-for-binary-proto --wait-other-notice --verbose && \
+		ccm status && \
+		ccm node1 nodetool status; \
+  	fi
+
+scylla-start: .prepare-pki .prepare-scylla-ccm .prepare-java
+	@if [ -d ${CCM_CONFIG_DIR}/${CCM_SCYLLA_CLUSTER_NAME} ] && ccm switch ${CCM_SCYLLA_CLUSTER_NAME} 2>/dev/null 1>&2 && ccm status | grep UP 2>/dev/null 1>&2; then \
+		echo "Scylla cluster is already started"; \
+  	else \
+		echo "Start scylla ${SCYLLA_VERSION} cluster"; \
+		ccm stop ${CCM_SCYLLA_CLUSTER_NAME} 2>/dev/null 1>&2 || true; \
+		ccm remove ${CCM_SCYLLA_CLUSTER_NAME} 2>/dev/null 1>&2 || true; \
+		ccm create ${CCM_SCYLLA_CLUSTER_NAME} -i ${CCM_SCYLLA_IP_PREFIX} --scylla -v ${SCYLLA_VERSION} -n 3 -d --jvm_arg="--smp 2 --memory 1G --experimental-features udf --enable-user-defined-functions true" && \
+		ccm updateconf ${SCYLLA_CONFIG} && \
+		ccm start --wait-for-binary-proto --wait-other-notice --verbose && \
+		ccm status && \
+		ccm node1 nodetool status && \
+		sudo chmod 0777 ${CCM_CONFIG_DIR}/${CCM_SCYLLA_CLUSTER_NAME}/node1/cql.m && \
+		sudo chmod 0777 ${CCM_CONFIG_DIR}/${CCM_SCYLLA_CLUSTER_NAME}/node2/cql.m && \
+		sudo chmod 0777 ${CCM_CONFIG_DIR}/${CCM_SCYLLA_CLUSTER_NAME}/node3/cql.m; \
+	fi
+
+cassandra-stop: .prepare-cassandra-ccm
+	@echo "Stop cassandra cluster"
+	@ccm stop --not-gently ${CCM_CASSANDRA_CLUSTER_NAME} 2>/dev/null 1>&2 || true
+	@ccm remove ${CCM_CASSANDRA_CLUSTER_NAME} 2>/dev/null 1>&2 || true
+
+scylla-stop: .prepare-scylla-ccm
+	@echo "Stop scylla cluster"
+	@ccm stop --not-gently ${CCM_SCYLLA_CLUSTER_NAME} 2>/dev/null 1>&2 || true
+	@ccm remove ${CCM_SCYLLA_CLUSTER_NAME} 2>/dev/null 1>&2 || true
+
+test-integration-cassandra: cassandra-start
+	@echo "Run integration tests for proto ${TEST_CQL_PROTOCOL} on cassandra ${CASSANDRA_VERSION}"
+	go test -v ${TEST_OPTS} -tags "${TEST_INTEGRATION_TAGS}" -timeout=5m -runauth -gocql.timeout=60s -runssl -proto=${TEST_CQL_PROTOCOL} -rf=3 -clusterSize=3 -autowait=2000ms -compressor=${TEST_COMPRESSOR} -gocql.cversion=$$(ccm node1 versionfrombuild) -cluster=$$(ccm liveset) ./...
+
+test-integration-scylla: scylla-start
+	@echo "Run integration tests for proto ${TEST_CQL_PROTOCOL} on scylla ${SCYLLA_IMAGE}"
+	go test -v ${TEST_OPTS} -tags "${TEST_INTEGRATION_TAGS}" -cluster-socket ${CCM_CONFIG_DIR}/${CCM_SCYLLA_CLUSTER_NAME}/node1/cql.m -timeout=5m -gocql.timeout=60s -proto=${TEST_CQL_PROTOCOL} -rf=3 -clusterSize=3 -autowait=2000ms -compressor=${TEST_COMPRESSOR} -gocql.cversion=$$(ccm node1 versionfrombuild) -cluster=$$(ccm liveset) ./...
+
+test-unit: .prepare-pki
+	@echo "Run unit tests"
+	@go clean -testcache
+ifeq ($(shell if [[ -n "$${GITHUB_STEP_SUMMARY}" ]]; then echo "running-in-workflow"; else echo "running-in-shell"; fi), running-in-workflow)
+	@echo "### Unit Test Results" >>$${GITHUB_STEP_SUMMARY}
+	@echo '```' >>$${GITHUB_STEP_SUMMARY}
+	@echo go test -tags unit -timeout=5m -race ./...
+	@go test -tags unit -timeout=5m -race ./... | tee -a $${GITHUB_STEP_SUMMARY}
+	@echo '```' >>$${GITHUB_STEP_SUMMARY}
+else
+	go test -v -tags unit -timeout=5m -race ./...
+endif
+
+test-bench:
+	@echo "Run benchmark tests"
+ifeq ($(shell if [[ -n "$${GITHUB_STEP_SUMMARY}" ]]; then echo "running-in-workflow"; else echo "running-in-shell"; fi), running-in-workflow)
+	@echo "### Benchmark Results" >>$${GITHUB_STEP_SUMMARY}
+	@echo '```' >>$${GITHUB_STEP_SUMMARY}
+	@echo go test -bench=. -benchmem ./...
+	@go test -bench=. -benchmem ./... | tee -a >>$${GITHUB_STEP_SUMMARY}
+	@echo '```' >>$${GITHUB_STEP_SUMMARY}
+else
+	go test -bench=. -benchmem ./...
+endif
+
+check:
+	@echo "Run go vet linter"
+	go vet --tags "unit all ccm cassandra integration" ./...
+
+.prepare-java:
+ifeq ($(shell if [ -f ~/.sdkman/bin/sdkman-init.sh ]; then echo "installed"; else echo "not-installed"; fi), not-installed)
+	@$(MAKE) install-java
+endif
+
+install-java:
+	@echo "Installing SDKMAN..."
+	@curl -s "https://get.sdkman.io" | bash
+	@echo "sdkman_auto_answer=true" >> ~/.sdkman/etc/config
+	@( \
+		source ~/.sdkman/bin/sdkman-init.sh; \
+		export PATH=${PATH}:~/.sdkman/bin; \
+		echo "Installing Java versions..."; \
+		sdk install java 11.0.24-zulu; \
+		sdk install java 17.0.12-zulu; \
+		sdk default java 11.0.24-zulu; \
+		sdk use java 11.0.24-zulu \
+	)
+
+.prepare-cassandra-ccm:
+	@ccm --help 2>/dev/null 1>&2; if [[ $$? -lt 127 ]] && grep CASSANDRA ${CCM_CONFIG_DIR}/ccm-type 2>/dev/null 1>&2 && grep ${CCM_CASSANDRA_VERSION} ${CCM_CONFIG_DIR}/ccm-version 2>/dev//null  1>&2; then \
+		echo "Cassandra CCM ${CCM_CASSANDRA_VERSION} is already installed"; \
+  	else \
+		echo "Installing Cassandra CCM ${CCM_CASSANDRA_VERSION}"; \
+		pip install "git+https://${CCM_CASSANDRA_REPO}.git@${CCM_CASSANDRA_VERSION}"; \
+		mkdir ${CCM_CONFIG_DIR} 2>/dev/null || true; \
+		echo CASSANDRA > ${CCM_CONFIG_DIR}/ccm-type; \
+		echo ${CCM_CASSANDRA_VERSION} > ${CCM_CONFIG_DIR}/ccm-version; \
+  	fi
+
+install-cassandra-ccm: cassandra-start
+	@echo "Install CCM ${CCM_CASSANDRA_VERSION}"
+	@pip install "git+https://${CCM_CASSANDRA_REPO}.git@${CCM_CASSANDRA_VERSION}"
+	@mkdir ${CCM_CONFIG_DIR} 2>/dev/null || true
+	@echo CASSANDRA > ${CCM_CONFIG_DIR}/ccm-type
+	@echo ${CCM_CASSANDRA_VERSION} > ${CCM_CONFIG_DIR}/ccm-version
+
+.prepare-scylla-ccm:
+	@ccm --help 2>/dev/null 1>&2; if [[ $$? -lt 127 ]] && grep SCYLLA ${CCM_CONFIG_DIR}/ccm-type 2>/dev/null 1>&2 && grep ${CCM_SCYLLA_VERSION} ${CCM_CONFIG_DIR}/ccm-version 2>/dev//null  1>&2; then \
+		echo "Scylla CCM ${CCM_SCYLLA_VERSION} is already installed"; \
+  	else \
+		echo "Installing Scylla CCM ${CCM_SCYLLA_VERSION}"; \
+		pip install "git+https://${CCM_SCYLLA_REPO}.git@${CCM_SCYLLA_VERSION}"; \
+		mkdir ${CCM_CONFIG_DIR} 2>/dev/null || true; \
+		echo SCYLLA > ${CCM_CONFIG_DIR}/ccm-type; \
+		echo ${CCM_SCYLLA_VERSION} > ${CCM_CONFIG_DIR}/ccm-version; \
+  	fi
+
+install-scylla-ccm:
+	@echo "Installing Scylla CCM ${CCM_SCYLLA_VERSION}"
+	@pip install "git+https://${CCM_SCYLLA_REPO}.git@${CCM_SCYLLA_VERSION}"
+	@mkdir ${CCM_CONFIG_DIR} 2>/dev/null || true
+	@echo SCYLLA > ${CCM_CONFIG_DIR}/ccm-type
+	@echo ${CCM_SCYLLA_VERSION} > ${CCM_CONFIG_DIR}/ccm-version
+
+.prepare-pki:
+	@[ -f "testdata/pki/cassandra.key" ] || (echo "Generating new PKI" && cd testdata/pki/ && bash ./generate_certs.sh)
+
+generate-pki:
+	@echo "Generating new PKI"
+	@rm -f testdata/pki/.keystore testdata/pki/.truststore testdata/pki/*.p12 testdata/pki/*.key testdata/pki/*.crt || true
+	@cd testdata/pki/ && bash ./generate_certs.sh
diff --git a/address_translators_test.go b/address_translators_test.go
index 9f0ef14..50cd805 100644
--- a/address_translators_test.go
+++ b/address_translators_test.go
@@ -28,6 +28,7 @@
 package gocql

 import (
+	"github.com/gocql/gocql/internal/tests"
 	"net"
 	"testing"
 )
@@ -45,7 +46,7 @@ func TestIdentityAddressTranslator_NilAddrAndZeroPort(t *testing.T) {
 	if addr != nil {
 		t.Errorf("expected translated host to be (nil) but was (%+v) instead", addr)
 	}
-	assertEqual(t, "translated port", 0, port)
+	tests.AssertEqual(t, "translated port", 0, port)
 }

 func TestIdentityAddressTranslator_HostProvided(t *testing.T) {
@@ -61,5 +62,5 @@ func TestIdentityAddressTranslator_HostProvided(t *testing.T) {
 	if !hostIP.Equal(addr) {
 		t.Errorf("expected translated addr to be (%+v) but was (%+v) instead", hostIP, addr)
 	}
-	assertEqual(t, "translated port", 9042, port)
+	tests.AssertEqual(t, "translated port", 9042, port)
 }
diff --git a/batch_test.go b/batch_test.go
index 1802940..449dae1 100644
--- a/batch_test.go
+++ b/batch_test.go
@@ -33,16 +33,9 @@ import (
 )

 func TestBatch_Errors(t *testing.T) {
-	if *flagProto == 1 {
-	}
-
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < protoVersion2 {
-		t.Skip("atomic batches not supported. Please use Cassandra >= 2.0")
-	}
-
 	if err := createTable(session, `CREATE TABLE gocql_test.batch_errors (id int primary key, val inet)`); err != nil {
 		t.Fatal(err)
 	}
@@ -58,10 +51,6 @@ func TestBatch_WithTimestamp(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("Batch timestamps are only available on protocol >= 3")
-	}
-
 	if err := createTable(session, `CREATE TABLE gocql_test.batch_ts (id int primary key, val text)`); err != nil {
 		t.Fatal(err)
 	}
diff --git a/cassandra_test.go b/cassandra_test.go
index 98750ec..17d10df 100644
--- a/cassandra_test.go
+++ b/cassandra_test.go
@@ -32,6 +32,7 @@ import (
 	"context"
 	"errors"
 	"fmt"
+	"github.com/gocql/gocql/internal/tests"
 	"math"
 	"math/big"
 	"net"
@@ -311,10 +312,6 @@ func TestPaging(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("Paging not supported. Please use Cassandra >= 2.0")
-	}
-
 	if err := createTable(session, "CREATE TABLE gocql_test.paging (id int primary key)"); err != nil {
 		t.Fatal("create table:", err)
 	}
@@ -348,10 +345,6 @@ func TestPagingWithAllowFiltering(t *testing.T) {
 		session.Close()
 	})

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("Paging not supported. Please use Cassandra >= 2.0")
-	}
-
 	const (
 		targetP1             = 50
 		targetP2             = 50
@@ -479,10 +472,6 @@ func TestPagingWithBind(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("Paging not supported. Please use Cassandra >= 2.0")
-	}
-
 	if err := createTable(session, "CREATE TABLE gocql_test.paging_bind (id int, val int, primary key(id,val))"); err != nil {
 		t.Fatal("create table:", err)
 	}
@@ -525,10 +514,6 @@ func TestCAS(t *testing.T) {
 	session := createSessionFromClusterTabletsDisabled(cluster, t)
 	defer session.Close()

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("lightweight transactions not supported. Please use Cassandra >= 2.0")
-	}
-
 	if err := createTable(session, `CREATE TABLE cas_table (
 			title         varchar,
 			revid   	  timeuuid,
@@ -780,7 +765,7 @@ func TestDurationType(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < 5 {
+	if session.cfg.ProtoVersion < protoVersion5 {
 		t.Skip("Duration type is not supported. Please use protocol version >= 4 and cassandra version >= 3.11")
 	}

@@ -832,10 +817,6 @@ func TestMapScanCAS(t *testing.T) {
 	session := createSessionFromClusterTabletsDisabled(createCluster(), t)
 	defer session.Close()

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("lightweight transactions not supported. Please use Cassandra >= 2.0")
-	}
-
 	if err := createTable(session, `CREATE TABLE cas_table2 (
 			title         varchar,
 			revid   	  timeuuid,
@@ -874,10 +855,6 @@ func TestBatch(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("atomic batches not supported. Please use Cassandra >= 2.0")
-	}
-
 	if err := createTable(session, `CREATE TABLE gocql_test.batch_table (id int primary key)`); err != nil {
 		t.Fatal("create table:", err)
 	}
@@ -904,20 +881,11 @@ func TestUnpreparedBatch(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("atomic batches not supported. Please use Cassandra >= 2.0")
-	}
-
 	if err := createTable(session, `CREATE TABLE gocql_test.batch_unprepared (id int primary key, c counter)`); err != nil {
 		t.Fatal("create table:", err)
 	}

-	var batch *Batch
-	if session.cfg.ProtoVersion == 2 {
-		batch = session.Batch(CounterBatch)
-	} else {
-		batch = session.Batch(UnloggedBatch)
-	}
+	batch := session.Batch(UnloggedBatch)

 	for i := 0; i < 100; i++ {
 		batch.Query(`UPDATE batch_unprepared SET c = c + 1 WHERE id = 1`)
@@ -947,10 +915,6 @@ func TestBatchLimit(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("atomic batches not supported. Please use Cassandra >= 2.0")
-	}
-
 	if err := createTable(session, `CREATE TABLE gocql_test.batch_table2 (id int primary key)`); err != nil {
 		t.Fatal("create table:", err)
 	}
@@ -995,10 +959,6 @@ func TestTooManyQueryArgs(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("atomic batches not supported. Please use Cassandra >= 2.0")
-	}
-
 	if err := createTable(session, `CREATE TABLE gocql_test.too_many_query_args (id int primary key, value int)`); err != nil {
 		t.Fatal("create table:", err)
 	}
@@ -1027,10 +987,6 @@ func TestNotEnoughQueryArgs(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("atomic batches not supported. Please use Cassandra >= 2.0")
-	}
-
 	if err := createTable(session, `CREATE TABLE gocql_test.not_enough_query_args (id int, cluster int, value int, primary key (id, cluster))`); err != nil {
 		t.Fatal("create table:", err)
 	}
@@ -1202,20 +1158,20 @@ func TestMapScan(t *testing.T) {
 	if !iter.MapScan(row) {
 		t.Fatal("select:", iter.Close())
 	}
-	assertEqual(t, "fullname", "Ada Lovelace", row["fullname"])
-	assertEqual(t, "age", 30, row["age"])
-	assertEqual(t, "address", "10.0.0.2", row["address"])
-	assertDeepEqual(t, "data", []byte(`{"foo": "bar"}`), row["data"])
+	tests.AssertEqual(t, "fullname", "Ada Lovelace", row["fullname"])
+	tests.AssertEqual(t, "age", 30, row["age"])
+	tests.AssertEqual(t, "address", "10.0.0.2", row["address"])
+	tests.AssertDeepEqual(t, "data", []byte(`{"foo": "bar"}`), row["data"])

 	// Second iteration using a new map
 	row = make(map[string]interface{})
 	if !iter.MapScan(row) {
 		t.Fatal("select:", iter.Close())
 	}
-	assertEqual(t, "fullname", "Grace Hopper", row["fullname"])
-	assertEqual(t, "age", 31, row["age"])
-	assertEqual(t, "address", "10.0.0.1", row["address"])
-	assertDeepEqual(t, "data", []byte(nil), row["data"])
+	tests.AssertEqual(t, "fullname", "Grace Hopper", row["fullname"])
+	tests.AssertEqual(t, "age", 31, row["age"])
+	tests.AssertEqual(t, "address", "10.0.0.1", row["address"])
+	tests.AssertDeepEqual(t, "data", []byte(nil), row["data"])
 }

 func TestSliceMap(t *testing.T) {
@@ -1398,10 +1354,6 @@ func TestSmallInt(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < protoVersion4 {
-		t.Skip("smallint is only supported in cassandra 2.2+")
-	}
-
 	if err := createTable(session, `CREATE TABLE gocql_test.smallint_table (
 			testsmallint  smallint PRIMARY KEY,
 		)`); err != nil {
@@ -1459,10 +1411,6 @@ func TestScanCASWithNilArguments(t *testing.T) {
 	session := createSessionFromClusterTabletsDisabled(createCluster(), t)
 	defer session.Close()

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("lightweight transactions not supported. Please use Cassandra >= 2.0")
-	}
-
 	if err := createTable(session, `CREATE TABLE scan_cas_with_nil_arguments (
 		foo   varchar,
 		bar   varchar,
@@ -1654,10 +1602,6 @@ func TestBatchQueryInfo(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("atomic batches not supported. Please use Cassandra >= 2.0")
-	}
-
 	if err := createTable(session, "CREATE TABLE gocql_test.batch_query_info (id int, cluster int, value text, PRIMARY KEY (id, cluster))"); err != nil {
 		t.Fatalf("failed to create table with error '%v'", err)
 	}
@@ -1793,10 +1737,6 @@ func TestPrepare_ReprepareBatch(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("atomic batches not supported. Please use Cassandra >= 2.0")
-	}
-
 	stmt, conn := injectInvalidPreparedStatement(t, session, "test_reprepare_statement_batch")
 	batch := session.Batch(UnloggedBatch)
 	batch.Query(stmt, "bar")
@@ -1820,10 +1760,8 @@ func TestQueryInfo(t *testing.T) {
 		t.Fatalf("Was not expecting meta data for %d query arguments, but got %d\n", 1, x)
 	}

-	if session.cfg.ProtoVersion > 1 {
-		if x := len(info.response.columns); x != 2 {
-			t.Fatalf("Was not expecting meta data for %d result columns, but got %d\n", 2, x)
-		}
+	if x := len(info.response.columns); x != 2 {
+		t.Fatalf("Was not expecting meta data for %d result columns, but got %d\n", 2, x)
 	}
 }

@@ -2174,10 +2112,6 @@ func TestBatchStats(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("atomic batches not supported. Please use Cassandra >= 2.0")
-	}
-
 	if err := createTable(session, "CREATE TABLE gocql_test.batchStats (id int, PRIMARY KEY (id))"); err != nil {
 		t.Fatalf("failed to create table with error '%v'", err)
 	}
@@ -2208,10 +2142,6 @@ func TestBatchObserve(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion == 1 {
-		t.Skip("atomic batches not supported. Please use Cassandra >= 2.0")
-	}
-
 	if err := createTable(session, `CREATE TABLE gocql_test.batch_observe_table (id int, other int, PRIMARY KEY (id))`); err != nil {
 		t.Fatal("create table:", err)
 	}
@@ -2263,7 +2193,7 @@ func TestBatchObserve(t *testing.T) {
 			t.Fatal("unexpected query", stmt)
 		}

-		assertDeepEqual(t, "observed value", []interface{}{i}, observedBatch.observedValues[i])
+		tests.AssertDeepEqual(t, "observed value", []interface{}{i}, observedBatch.observedValues[i])
 	}
 }

@@ -2372,6 +2302,8 @@ func TestRoutingKey(t *testing.T) {
 		t.Fatalf("failed to create table with error '%v'", err)
 	}

+	initCacheSize := session.routingKeyInfoCache.lru.Len()
+
 	routingKeyInfo, err := session.routingKeyInfo(context.Background(), "SELECT * FROM test_single_routing_key WHERE second_id=? AND first_id=?")
 	if err != nil {
 		t.Fatalf("failed to get routing key info due to error: %v", err)
@@ -2416,8 +2348,8 @@ func TestRoutingKey(t *testing.T) {
 		t.Fatalf("Expected routing key types[0] to be %v but was %v", TypeInt, routingKeyInfo.types[0].Type())
 	}
 	cacheSize := session.routingKeyInfoCache.lru.Len()
-	if cacheSize != 1 {
-		t.Errorf("Expected cache size to be 1 but was %d", cacheSize)
+	if cacheSize != initCacheSize+1 {
+		t.Errorf("Expected cache size to be %d but was %d", initCacheSize+1, cacheSize)
 	}

 	query := session.Query("SELECT * FROM test_single_routing_key WHERE second_id=? AND first_id=?", 1, 2)
@@ -2474,8 +2406,8 @@ func TestRoutingKey(t *testing.T) {

 	// verify the cache is working
 	cacheSize = session.routingKeyInfoCache.lru.Len()
-	if cacheSize != 2 {
-		t.Errorf("Expected cache size to be 2 but was %d", cacheSize)
+	if cacheSize != initCacheSize+2 {
+		t.Errorf("Expected cache size to be %d but was %d", initCacheSize+2, cacheSize)
 	}
 }

@@ -2633,7 +2565,7 @@ func TestJSONSupport(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < 4 {
+	if session.cfg.ProtoVersion < protoVersion4 {
 		t.Skip("skipping JSON support on proto < 4")
 	}

@@ -2677,10 +2609,6 @@ func TestUnmarshallNestedTypes(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("can not have frozen types in cassandra < 2.1.3")
-	}
-
 	if err := createTable(session, `CREATE TABLE gocql_test.test_557 (
 		    id text PRIMARY KEY,
 		    val list<frozen<map<text, text> > >
@@ -2810,7 +2738,7 @@ func TestUnsetCol(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < 4 {
+	if session.cfg.ProtoVersion < protoVersion4 {
 		t.Skip("Unset Values are not supported in protocol < 4")
 	}

@@ -2839,7 +2767,7 @@ func TestUnsetColBatch(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < 4 {
+	if session.cfg.ProtoVersion < protoVersion4 {
 		t.Skip("Unset Values are not supported in protocol < 4")
 	}

@@ -2881,10 +2809,6 @@ func TestQuery_NamedValues(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < 3 {
-		t.Skip("named Values are not supported in protocol < 3")
-	}
-
 	if err := createTable(session, "CREATE TABLE gocql_test.named_query(id int, value text, PRIMARY KEY (id))"); err != nil {
 		t.Fatal(err)
 	}
diff --git a/cluster.go b/cluster.go
index 693e3bb..e1b6c21 100644
--- a/cluster.go
+++ b/cluster.go
@@ -314,12 +314,20 @@ type ClusterConfig struct {
 	disableInit        bool

 	DNSResolver DNSResolver
+
+	ApplicationInfo ApplicationInfo
 }

 type DNSResolver interface {
 	LookupIP(host string) ([]net.IP, error)
 }

+type ApplicationInfo struct {
+	ApplicationName    string
+	ApplicationVersion string
+	ClientID           string
+}
+
 type SimpleDNSResolver struct {
 	hostLookupPreferV4 bool
 }
diff --git a/cluster_test.go b/cluster_test.go
index 4183735..742df38 100644
--- a/cluster_test.go
+++ b/cluster_test.go
@@ -28,6 +28,7 @@
 package gocql

 import (
+	"github.com/gocql/gocql/internal/tests"
 	"net"
 	"reflect"
 	"testing"
@@ -38,20 +39,20 @@ func TestNewCluster_Defaults(t *testing.T) {
 	t.Parallel()

 	cfg := NewCluster()
-	assertEqual(t, "cluster config cql version", "3.0.0", cfg.CQLVersion)
-	assertEqual(t, "cluster config timeout", 11*time.Second, cfg.Timeout)
-	assertEqual(t, "cluster config port", 9042, cfg.Port)
-	assertEqual(t, "cluster config num-conns", 2, cfg.NumConns)
-	assertEqual(t, "cluster config consistency", Quorum, cfg.Consistency)
-	assertEqual(t, "cluster config max prepared statements", defaultMaxPreparedStmts, cfg.MaxPreparedStmts)
-	assertEqual(t, "cluster config max routing key info", 1000, cfg.MaxRoutingKeyInfo)
-	assertEqual(t, "cluster config page-size", 5000, cfg.PageSize)
-	assertEqual(t, "cluster config default timestamp", true, cfg.DefaultTimestamp)
-	assertEqual(t, "cluster config max wait schema agreement", 60*time.Second, cfg.MaxWaitSchemaAgreement)
-	assertEqual(t, "cluster config reconnect interval", 60*time.Second, cfg.ReconnectInterval)
-	assertTrue(t, "cluster config conviction policy",
+	tests.AssertEqual(t, "cluster config cql version", "3.0.0", cfg.CQLVersion)
+	tests.AssertEqual(t, "cluster config timeout", 11*time.Second, cfg.Timeout)
+	tests.AssertEqual(t, "cluster config port", 9042, cfg.Port)
+	tests.AssertEqual(t, "cluster config num-conns", 2, cfg.NumConns)
+	tests.AssertEqual(t, "cluster config consistency", Quorum, cfg.Consistency)
+	tests.AssertEqual(t, "cluster config max prepared statements", defaultMaxPreparedStmts, cfg.MaxPreparedStmts)
+	tests.AssertEqual(t, "cluster config max routing key info", 1000, cfg.MaxRoutingKeyInfo)
+	tests.AssertEqual(t, "cluster config page-size", 5000, cfg.PageSize)
+	tests.AssertEqual(t, "cluster config default timestamp", true, cfg.DefaultTimestamp)
+	tests.AssertEqual(t, "cluster config max wait schema agreement", 60*time.Second, cfg.MaxWaitSchemaAgreement)
+	tests.AssertEqual(t, "cluster config reconnect interval", 60*time.Second, cfg.ReconnectInterval)
+	tests.AssertTrue(t, "cluster config conviction policy",
 		reflect.DeepEqual(&SimpleConvictionPolicy{}, cfg.ConvictionPolicy))
-	assertTrue(t, "cluster config reconnection policy",
+	tests.AssertTrue(t, "cluster config reconnection policy",
 		reflect.DeepEqual(&ConstantReconnectionPolicy{MaxRetries: 3, Interval: 1 * time.Second}, cfg.ReconnectionPolicy))
 }

@@ -59,19 +60,19 @@ func TestNewCluster_WithHosts(t *testing.T) {
 	t.Parallel()

 	cfg := NewCluster("addr1", "addr2")
-	assertEqual(t, "cluster config hosts length", 2, len(cfg.Hosts))
-	assertEqual(t, "cluster config host 0", "addr1", cfg.Hosts[0])
-	assertEqual(t, "cluster config host 1", "addr2", cfg.Hosts[1])
+	tests.AssertEqual(t, "cluster config hosts length", 2, len(cfg.Hosts))
+	tests.AssertEqual(t, "cluster config host 0", "addr1", cfg.Hosts[0])
+	tests.AssertEqual(t, "cluster config host 1", "addr2", cfg.Hosts[1])
 }

 func TestClusterConfig_translateAddressAndPort_NilTranslator(t *testing.T) {
 	t.Parallel()

 	cfg := NewCluster()
-	assertNil(t, "cluster config address translator", cfg.AddressTranslator)
+	tests.AssertNil(t, "cluster config address translator", cfg.AddressTranslator)
 	newAddr, newPort := cfg.translateAddressPort(net.ParseIP("10.0.0.1"), 1234)
-	assertTrue(t, "same address as provided", net.ParseIP("10.0.0.1").Equal(newAddr))
-	assertEqual(t, "translated host and port", 1234, newPort)
+	tests.AssertTrue(t, "same address as provided", net.ParseIP("10.0.0.1").Equal(newAddr))
+	tests.AssertEqual(t, "translated host and port", 1234, newPort)
 }

 func TestClusterConfig_translateAddressAndPort_EmptyAddr(t *testing.T) {
@@ -80,8 +81,8 @@ func TestClusterConfig_translateAddressAndPort_EmptyAddr(t *testing.T) {
 	cfg := NewCluster()
 	cfg.AddressTranslator = staticAddressTranslator(net.ParseIP("10.10.10.10"), 5432)
 	newAddr, newPort := cfg.translateAddressPort(net.IP([]byte{}), 0)
-	assertTrue(t, "translated address is still empty", len(newAddr) == 0)
-	assertEqual(t, "translated port", 0, newPort)
+	tests.AssertTrue(t, "translated address is still empty", len(newAddr) == 0)
+	tests.AssertEqual(t, "translated port", 0, newPort)
 }

 func TestClusterConfig_translateAddressAndPort_Success(t *testing.T) {
@@ -90,6 +91,6 @@ func TestClusterConfig_translateAddressAndPort_Success(t *testing.T) {
 	cfg := NewCluster()
 	cfg.AddressTranslator = staticAddressTranslator(net.ParseIP("10.10.10.10"), 5432)
 	newAddr, newPort := cfg.translateAddressPort(net.ParseIP("10.0.0.1"), 2345)
-	assertTrue(t, "translated address", net.ParseIP("10.10.10.10").Equal(newAddr))
-	assertEqual(t, "translated port", 5432, newPort)
+	tests.AssertTrue(t, "translated address", net.ParseIP("10.10.10.10").Equal(newAddr))
+	tests.AssertEqual(t, "translated port", 5432, newPort)
 }
diff --git a/common_test.go b/common_test.go
index b50d96c..1838474 100644
--- a/common_test.go
+++ b/common_test.go
@@ -29,7 +29,6 @@ import (
 	"fmt"
 	"log"
 	"net"
-	"reflect"
 	"strings"
 	"sync"
 	"testing"
@@ -37,19 +36,19 @@ import (
 )

 var (
-	flagCluster      = flag.String("cluster", "127.0.0.1", "a comma-separated list of host:port tuples")
-	flagProto        = flag.Int("proto", 0, "protcol version")
-	flagCQL          = flag.String("cql", "3.0.0", "CQL version")
-	flagRF           = flag.Int("rf", 1, "replication factor for test keyspace")
-	clusterSize      = flag.Int("clusterSize", 1, "the expected size of the cluster")
-	flagRetry        = flag.Int("retries", 5, "number of times to retry queries")
-	flagAutoWait     = flag.Duration("autowait", 1000*time.Millisecond, "time to wait for autodiscovery to fill the hosts poll")
-	flagRunSslTest   = flag.Bool("runssl", false, "Set to true to run ssl test")
-	flagRunAuthTest  = flag.Bool("runauth", false, "Set to true to run authentication test")
-	flagCompressTest = flag.String("compressor", "", "compressor to use")
-	flagTimeout      = flag.Duration("gocql.timeout", 5*time.Second, "sets the connection `timeout` for all operations")
-
-	flagCassVersion cassVersion
+	flagCluster       = flag.String("cluster", "127.0.0.1", "a comma-separated list of host:port tuples")
+	flagProto         = flag.Int("proto", 0, "protcol version")
+	flagCQL           = flag.String("cql", "3.0.0", "CQL version")
+	flagRF            = flag.Int("rf", 1, "replication factor for test keyspace")
+	clusterSize       = flag.Int("clusterSize", 1, "the expected size of the cluster")
+	flagRetry         = flag.Int("retries", 5, "number of times to retry queries")
+	flagAutoWait      = flag.Duration("autowait", 1000*time.Millisecond, "time to wait for autodiscovery to fill the hosts poll")
+	flagRunSslTest    = flag.Bool("runssl", false, "Set to true to run ssl test")
+	flagRunAuthTest   = flag.Bool("runauth", false, "Set to true to run authentication test")
+	flagCompressTest  = flag.String("compressor", "", "compressor to use")
+	flagTimeout       = flag.Duration("gocql.timeout", 5*time.Second, "sets the connection `timeout` for all operations")
+	flagClusterSocket = flag.String("cluster-socket", "", "nodes socket files separated by comma")
+	flagCassVersion   cassVersion
 )

 func init() {
@@ -99,6 +98,90 @@ func (o *OnceManager) GetOnce(key string) *sync.Once {

 var initKeyspaceOnce = NewOnceManager()

+var isTabletsSupportedFlag *bool
+var isTabletsSupportedOnce sync.RWMutex
+
+func isTabletsSupported() bool {
+	isTabletsSupportedOnce.RLock()
+	if isTabletsSupportedFlag != nil {
+		isTabletsSupportedOnce.RUnlock()
+		return *isTabletsSupportedFlag
+	}
+	isTabletsSupportedOnce.RUnlock()
+	isTabletsSupportedOnce.Lock()
+	defer isTabletsSupportedOnce.Unlock()
+	if isTabletsSupportedFlag != nil {
+		return *isTabletsSupportedFlag
+	}
+	var result bool
+
+	s, err := createCluster().CreateSession()
+	if err != nil {
+		panic(fmt.Errorf("failed to create session: %v", err))
+	}
+	res := make(map[string]interface{})
+	err = s.Query("select * from system.local").MapScan(res)
+	if err != nil {
+		panic(fmt.Errorf("failed to read system.local: %v", err))
+	}
+
+	features, _ := res["supported_features"]
+	featuresCasted, _ := features.(string)
+	for _, feature := range strings.Split(featuresCasted, ",") {
+		if feature == "TABLETS" {
+			result = true
+			isTabletsSupportedFlag = &result
+			return true
+		}
+	}
+	result = false
+	isTabletsSupportedFlag = &result
+	return false
+}
+
+var isTabletsAutoEnabledFlag *bool
+var isTabletsAutoEnabledOnce sync.RWMutex
+
+func isTabletsAutoEnabled() bool {
+	isTabletsAutoEnabledOnce.RLock()
+	if isTabletsAutoEnabledFlag != nil {
+		isTabletsAutoEnabledOnce.RUnlock()
+		return *isTabletsAutoEnabledFlag
+	}
+	isTabletsAutoEnabledOnce.RUnlock()
+	isTabletsAutoEnabledOnce.Lock()
+	defer isTabletsAutoEnabledOnce.Unlock()
+	if isTabletsAutoEnabledFlag != nil {
+		return *isTabletsAutoEnabledFlag
+	}
+
+	s, err := createCluster().CreateSession()
+	if err != nil {
+		panic(fmt.Errorf("failed to create session: %v", err))
+	}
+
+	err = s.Query("DROP KEYSPACE IF EXISTS gocql_check_tablets_enabled").Exec()
+	if err != nil {
+		panic(fmt.Errorf("failed to delete keyspace: %v", err))
+	}
+	err = s.Query("CREATE KEYSPACE gocql_check_tablets_enabled WITH replication = {'class': 'NetworkTopologyStrategy', 'replication_factor': '1'}").Exec()
+	if err != nil {
+		panic(fmt.Errorf("failed to delete keyspace: %v", err))
+	}
+
+	res := make(map[string]interface{})
+	err = s.Query("describe keyspace gocql_check_tablets_enabled").MapScan(res)
+	if err != nil {
+		panic(fmt.Errorf("failed to read system.local: %v", err))
+	}
+
+	createStmt, _ := res["create_statement"]
+	createStmtCasted, _ := createStmt.(string)
+	result := strings.Contains(strings.ToLower(createStmtCasted), "and tablets")
+	isTabletsAutoEnabledFlag = &result
+	return result
+}
+
 func createTable(s *Session, table string) error {
 	// lets just be really sure
 	if err := s.control.awaitSchemaAgreement(); err != nil {
@@ -171,10 +254,12 @@ func createKeyspace(tb testing.TB, cluster *ClusterConfig, keyspace string, disa
 		'replication_factor' : %d
 	}`, keyspace, *flagRF)

-	if disableTablets {
-		query += " AND tablets = {'enabled': false}"
-	} else {
-		query += " AND tablets = {'enabled': true, 'initial': 8};"
+	if isTabletsSupported() {
+		if disableTablets {
+			query += " AND tablets = {'enabled': false}"
+		} else if !isTabletsAutoEnabled() {
+			query += " AND tablets = {'enabled': true};"
+		}
 	}

 	err = createTable(session, query)
@@ -214,6 +299,16 @@ func createSessionFromClusterHelper(cluster *ClusterConfig, tb testing.TB, opts
 	return session
 }

+func getClusterSocketFile() []string {
+	var res []string
+	for _, socketFile := range strings.Split(*flagClusterSocket, ",") {
+		if socketFile != "" {
+			res = append(res, socketFile)
+		}
+	}
+	return res
+}
+
 func createSessionFromClusterTabletsDisabled(cluster *ClusterConfig, tb testing.TB) *Session {
 	return createSessionFromClusterHelper(cluster, tb, testKeyspaceOpts{tabletsDisabled: true})
 }
@@ -319,31 +414,3 @@ func staticAddressTranslator(newAddr net.IP, newPort int) AddressTranslator {
 		return newAddr, newPort
 	})
 }
-
-func assertTrue(t *testing.T, description string, value bool) {
-	t.Helper()
-	if !value {
-		t.Fatalf("expected %s to be true", description)
-	}
-}
-
-func assertEqual(t *testing.T, description string, expected, actual interface{}) {
-	t.Helper()
-	if expected != actual {
-		t.Fatalf("expected %s to be (%+v) but was (%+v) instead", description, expected, actual)
-	}
-}
-
-func assertDeepEqual(t *testing.T, description string, expected, actual interface{}) {
-	t.Helper()
-	if !reflect.DeepEqual(expected, actual) {
-		t.Fatalf("expected %s to be (%+v) but was (%+v) instead", description, expected, actual)
-	}
-}
-
-func assertNil(t *testing.T, description string, actual interface{}) {
-	t.Helper()
-	if actual != nil {
-		t.Fatalf("expected %s to be (nil) but was (%+v) instead", description, actual)
-	}
-}
diff --git a/compressor_test.go b/compressor_test.go
index 6ee3c28..34fd6f8 100644
--- a/compressor_test.go
+++ b/compressor_test.go
@@ -122,7 +122,8 @@ func TestSnappyCompressor(t *testing.T) {
 		c := gocql.SnappyCompressor{}

 		t.Run("Encode", func(t *testing.T) {
-			for _, frame := range frameExamples.Requests {
+			for id := range frameExamples.Requests {
+				frame := frameExamples.Requests[id]
 				t.Run(frame.Name, func(t *testing.T) {
 					t.Parallel()

@@ -144,7 +145,8 @@ func TestSnappyCompressor(t *testing.T) {
 		})

 		t.Run("Decode", func(t *testing.T) {
-			for _, frame := range frameExamples.Responses {
+			for id := range frameExamples.Responses {
+				frame := frameExamples.Responses[id]
 				t.Run(frame.Name, func(t *testing.T) {
 					t.Parallel()

diff --git a/conn.go b/conn.go
index d1733b3..186d8c6 100644
--- a/conn.go
+++ b/conn.go
@@ -30,6 +30,7 @@ import (
 	"crypto/tls"
 	"errors"
 	"fmt"
+	"github.com/gocql/gocql/tablets"
 	"io"
 	"io/ioutil"
 	"net"
@@ -198,7 +199,7 @@ type Conn struct {
 	frameObserver  FrameHeaderObserver
 	streamObserver StreamObserver

-	headerBuf [maxFrameHeaderSize]byte
+	headerBuf [headSize]byte

 	streams *streams.IDGenerator
 	mu      sync.Mutex
@@ -323,7 +324,7 @@ func (s *Session) dialWithoutObserver(ctx context.Context, host *HostInfo, cfg *
 		errorHandler:  errorHandler,
 		compressor:    cfg.Compressor,
 		session:       s,
-		streams:       s.streamIDGenerator(cfg.ProtoVersion),
+		streams:       s.streamIDGenerator(),
 		host:          host,
 		isSchemaV2:    true, // Try using "system.peers_v2" until proven otherwise
 		frameObserver: s.frameObserver,
@@ -349,11 +350,11 @@ func (s *Session) dialWithoutObserver(ctx context.Context, host *HostInfo, cfg *
 	return c, nil
 }

-func (s *Session) streamIDGenerator(protocol int) *streams.IDGenerator {
+func (s *Session) streamIDGenerator() *streams.IDGenerator {
 	if s.cfg.MaxRequestsPerConn > 0 {
 		return streams.NewLimited(s.cfg.MaxRequestsPerConn)
 	}
-	return streams.New(protocol)
+	return streams.New()
 }

 func (c *Conn) init(ctx context.Context, dialedHost *DialedHost) error {
@@ -512,6 +513,16 @@ func (s *startupCoordinator) startup(ctx context.Context) error {
 		"DRIVER_VERSION": s.conn.session.cfg.DriverVersion,
 	}

+	if s.conn.session.cfg.ApplicationInfo.ApplicationName != "" {
+		m["APPLICATION_NAME"] = s.conn.session.cfg.ApplicationInfo.ApplicationName
+	}
+	if s.conn.session.cfg.ApplicationInfo.ApplicationVersion != "" {
+		m["APPLICATION_VERSION"] = s.conn.session.cfg.ApplicationInfo.ApplicationVersion
+	}
+	if s.conn.session.cfg.ApplicationInfo.ClientID != "" {
+		m["CLIENT_ID"] = s.conn.session.cfg.ApplicationInfo.ClientID
+	}
+
 	if s.conn.compressor != nil {
 		comp := s.conn.supported["COMPRESSION"]
 		name := s.conn.compressor.Name()
@@ -1519,11 +1530,8 @@ func (c *Conn) executeQuery(ctx context.Context, qry *Query) (iter *Iter) {

 	if len(framer.customPayload) > 0 {
 		if tabletInfo, ok := framer.customPayload["tablets-routing-v1"]; ok {
-			var firstToken string
-			var lastToken string
-			var replicas [][]interface{}
-			tabletInfoValue := []interface{}{&firstToken, &lastToken, &replicas}
-			Unmarshal(TupleTypeInfo{
+			tabletBuilder := tablets.NewTabletInfoBuilder()
+			err = Unmarshal(TupleTypeInfo{
 				NativeType: NativeType{proto: c.version, typ: TypeTuple},
 				Elems: []TypeInfo{
 					NativeType{typ: TypeBigInt},
@@ -1538,39 +1546,17 @@ func (c *Conn) executeQuery(ctx context.Context, qry *Query) (iter *Iter) {
 							}},
 					},
 				},
-			}, tabletInfo, tabletInfoValue)
-
-			tablet := TabletInfo{}
-			tablet.firstToken, err = strconv.ParseInt(firstToken, 10, 64)
+			}, tabletInfo, []interface{}{&tabletBuilder.FirstToken, &tabletBuilder.LastToken, &tabletBuilder.Replicas})
 			if err != nil {
 				return &Iter{err: err}
 			}
-			tablet.lastToken, err = strconv.ParseInt(lastToken, 10, 64)
+			tabletBuilder.KeyspaceName = qry.routingInfo.keyspace
+			tabletBuilder.TableName = qry.routingInfo.table
+			tablet, err := tabletBuilder.Build()
 			if err != nil {
 				return &Iter{err: err}
 			}
-
-			tabletReplicas := make([]ReplicaInfo, 0, len(replicas))
-			for _, replica := range replicas {
-				if len(replica) != 2 {
-					return &Iter{err: err}
-				}
-				if hostId, ok := replica[0].(UUID); ok {
-					if shardId, ok := replica[1].(int); ok {
-						repInfo := ReplicaInfo{hostId, shardId}
-						tabletReplicas = append(tabletReplicas, repInfo)
-					} else {
-						return &Iter{err: err}
-					}
-				} else {
-					return &Iter{err: err}
-				}
-			}
-			tablet.replicas = tabletReplicas
-			tablet.keyspaceName = qry.routingInfo.keyspace
-			tablet.tableName = qry.routingInfo.table
-
-			c.session.metadataDescriber.AddTablet(&tablet)
+			c.session.metadataDescriber.AddTablet(tablet)
 		}
 	}

@@ -1699,10 +1685,6 @@ func (c *Conn) executeBatch(ctx context.Context, batch *Batch) (iter *Iter) {
 		}
 	}()

-	if c.version == protoVersion1 {
-		return &Iter{err: ErrUnsupported}
-	}
-
 	n := len(batch.Entries)
 	req := &writeBatchFrame{
 		typ:                   batch.Type,
@@ -1834,7 +1816,7 @@ func (c *Conn) querySystem(ctx context.Context, query string) *Iter {
 }

 const qrySystemPeers = "SELECT * FROM system.peers"
-const qrySystemPeersV2 = "SELECT * FROM system.peers_2"
+const qrySystemPeersV2 = "SELECT * FROM system.peers_v2"

 const qrySystemLocal = "SELECT * FROM system.local WHERE key='local'"

@@ -1897,7 +1879,7 @@ func (c *Conn) awaitSchemaAgreement(ctx context.Context) error {
 	for time.Now().Before(endDeadline) {
 		var iter *Iter
 		if c.getIsSchemaV2() {
-			iter = c.querySystem(ctx, "SELECT host_id, data_center, rack, schema_version, rpc_address FROM system.peers_2")
+			iter = c.querySystem(ctx, "SELECT host_id, data_center, rack, schema_version, preferred_ip FROM system.peers_v2")
 		} else {
 			iter = c.querySystem(ctx, "SELECT host_id, data_center, rack, schema_version, rpc_address FROM system.peers")
 		}
diff --git a/conn_test.go b/conn_test.go
index b1eecd8..a617f36 100644
--- a/conn_test.go
+++ b/conn_test.go
@@ -54,7 +54,7 @@ import (
 )

 const (
-	defaultProto = protoVersion2
+	defaultProto = protoVersion3
 )

 type brokenDNSResolver struct{}
@@ -106,6 +106,7 @@ func testCluster(proto protoVersion, addresses ...string) *ClusterConfig {
 	cluster := NewCluster(addresses...)
 	cluster.ProtoVersion = int(proto)
 	cluster.disableControlConn = true
+	cluster.PoolConfig.HostSelectionPolicy = RoundRobinHostPolicy()
 	return cluster
 }

@@ -342,15 +343,16 @@ func TestCancel(t *testing.T) {
 	wg.Add(1)

 	go func() {
-		if err := qry.Exec(); !errors.Is(err, context.Canceled) {
-			t.Fatalf("expected to get context cancel error: '%v', got '%v'", context.Canceled, err)
-		}
+		err = qry.Exec()
 		wg.Done()
 	}()
-
 	// The query will timeout after about 1 seconds, so cancel it after a short pause
 	time.AfterFunc(20*time.Millisecond, cancel)
 	wg.Wait()
+
+	if !errors.Is(err, context.Canceled) {
+		t.Fatalf("expected to get context cancel error: '%v', got '%v'", context.Canceled, err)
+	}
 }

 type testQueryObserver struct {
@@ -451,7 +453,13 @@ func TestQueryMultinodeWithMetrics(t *testing.T) {
 	}

 	for i, ip := range addresses {
-		host := &HostInfo{connectAddress: net.ParseIP(ip)}
+		var host *HostInfo
+		for _, clusterHost := range db.GetHosts() {
+			if clusterHost.connectAddress.String() == ip {
+				host = clusterHost
+			}
+		}
+
 		queryMetric := qry.metrics.hostMetrics(host)
 		observedMetrics := observer.GetMetrics(host)

@@ -621,7 +629,7 @@ func BenchmarkSingleConn(b *testing.B) {
 	srv := NewTestServer(b, 3, context.Background())
 	defer srv.Stop()

-	cluster := testCluster(3, srv.Address)
+	cluster := testCluster(protoVersion3, srv.Address)
 	// Set the timeout arbitrarily low so that the query hits the timeout in a
 	// timely manner.
 	cluster.Timeout = 500 * time.Millisecond
@@ -725,7 +733,7 @@ func TestStream0(t *testing.T) {

 	conn := &Conn{
 		r:       bufio.NewReader(&buf),
-		streams: streams.New(protoVersion4),
+		streams: streams.New(),
 		logger:  &defaultLogger{},
 	}

@@ -801,17 +809,17 @@ func TestInitialRetryPolicy(t *testing.T) {
 			ExpectedErr:              "gocql: unable to create session: unable to connect to the cluster, last error: unable to discover protocol version:"},
 		{
 			NumRetries:               1,
-			ProtoVersion:             4,
+			ProtoVersion:             protoVersion4,
 			ExpectedGetIntervalCalls: nil,
 			ExpectedErr:              "gocql: unable to create session: unable to connect to the cluster, last error: unable to create control connection: unable to connect to initial hosts:"},
 		{
 			NumRetries:               2,
-			ProtoVersion:             4,
+			ProtoVersion:             protoVersion4,
 			ExpectedGetIntervalCalls: []int{1},
 			ExpectedErr:              "gocql: unable to create session: unable to connect to the cluster, last error: unable to create control connection: unable to connect to initial hosts:"},
 		{
 			NumRetries:               3,
-			ProtoVersion:             4,
+			ProtoVersion:             protoVersion4,
 			ExpectedGetIntervalCalls: []int{1, 2},
 			ExpectedErr:              "gocql: unable to create session: unable to connect to the cluster, last error: unable to create control connection: unable to connect to initial hosts:"},
 	}
@@ -1155,10 +1163,7 @@ func (nts newTestServerOpts) newServer(t testing.TB, ctx context.Context) *TestS
 		t.Fatal(err)
 	}

-	headerSize := 8
-	if nts.protocol > protoVersion2 {
-		headerSize = 9
-	}
+	headerSize := 9

 	ctx, cancel := context.WithCancel(ctx)
 	srv := &TestServer{
@@ -1207,10 +1212,7 @@ func NewSSLTestServerWithSupportedFactory(t testing.TB, protocol uint8, ctx cont
 		t.Fatal(err)
 	}

-	headerSize := 8
-	if protocol > protoVersion2 {
-		headerSize = 9
-	}
+	headerSize := 9

 	ctx, cancel := context.WithCancel(ctx)
 	srv := &TestServer{
diff --git a/connectionpool.go b/connectionpool.go
index 9c1bc7e..d957a24 100644
--- a/connectionpool.go
+++ b/connectionpool.go
@@ -26,6 +26,7 @@ package gocql

 import (
 	"fmt"
+	"github.com/gocql/gocql/tablets"
 	"math/rand"
 	"net"
 	"sync"
@@ -46,7 +47,7 @@ type SetPartitioner interface {

 // interface to implement to receive the tablets value
 type SetTablets interface {
-	SetTablets(tablets TabletInfoList)
+	SetTablets(tablets tablets.TabletInfoList)
 }

 type policyConnPool struct {
diff --git a/control.go b/control.go
index cf6e126..b146500 100644
--- a/control.go
+++ b/control.go
@@ -227,7 +227,7 @@ func (c *controlConn) discoverProtocol(hosts []*HostInfo) (int, error) {
 	hosts = shuffleHosts(hosts)

 	connCfg := *c.session.connCfg
-	connCfg.ProtoVersion = 4 // TODO: define maxProtocol
+	connCfg.ProtoVersion = protoVersion4 // TODO: define maxProtocol

 	handler := connErrorHandlerFn(func(c *Conn, err error, closed bool) {
 		// we should never get here, but if we do it means we connected to a
diff --git a/control_integration_test.go b/control_integration_test.go
index 9b85273..e664414 100644
--- a/control_integration_test.go
+++ b/control_integration_test.go
@@ -21,12 +21,15 @@ func (d unixSocketDialer) DialContext(_ context.Context, _, _ string) (net.Conn,
 }

 func TestUnixSockets(t *testing.T) {
-	socketPath := "/tmp/scylla_node_1/cql.m"
+	socketFiles := getClusterSocketFile()
+	if len(socketFiles) == 0 {
+		t.Skip("this test needs path to socket file provided into -cluster-socket cli option")
+	}

 	c := createCluster()
 	c.NumConns = 1
 	c.DisableInitialHostLookup = true
-	c.ProtoVersion = 3
+	c.ProtoVersion = protoVersion3
 	c.ReconnectInterval = 0
 	c.WriteCoalesceWaitTime = 0

@@ -43,7 +46,7 @@ func TestUnixSockets(t *testing.T) {

 	c.Dialer = unixSocketDialer{
 		dialer:     d,
-		socketPath: socketPath,
+		socketPath: socketFiles[0],
 	}

 	sess, err := c.CreateSession()
diff --git a/control_test.go b/control_test.go
index d215654..e0ac9ed 100644
--- a/control_test.go
+++ b/control_test.go
@@ -73,7 +73,7 @@ func TestParseProtocol(t *testing.T) {
 					message: "Invalid or unsupported protocol version (5); the lowest supported version is 3 and the greatest is 4",
 				},
 			},
-			proto: 4,
+			proto: protoVersion4,
 		},
 		{
 			err: &protocolError{
@@ -85,7 +85,7 @@ func TestParseProtocol(t *testing.T) {
 					message: "Invalid or unsupported protocol version: 5",
 				},
 			},
-			proto: 3,
+			proto: protoVersion3,
 		},
 	}

diff --git a/dialer/recorder/recorder.go b/dialer/recorder/recorder.go
index 057ad09..010565c 100644
--- a/dialer/recorder/recorder.go
+++ b/dialer/recorder/recorder.go
@@ -72,15 +72,8 @@ func (f *FrameWriter) Write(b []byte, n int, file *os.File) (err error) {
 	f.record.Data = append(f.record.Data, b[:n]...)

 	if f.to_record == -1 && len(f.record.Data) >= 9 {
-		p := 4
-		stream_id := int(f.record.Data[2])
-		if b[0] > 0x02 {
-			p = 5
-			stream_id = int(f.record.Data[2])<<8 | int(f.record.Data[3])
-		}
-
-		f.to_record = p + 4 + int(f.record.Data[p+0])<<24 | int(f.record.Data[p+1])<<16 | int(f.record.Data[p+2])<<8 | int(f.record.Data[p+3]) - recorded_ealier
-		f.record.StreamID = stream_id
+		f.to_record = 9 + int(f.record.Data[5+0])<<24 | int(f.record.Data[6])<<16 | int(f.record.Data[7])<<8 | int(f.record.Data[8]) - recorded_ealier
+		f.record.StreamID = int(f.record.Data[2])<<8 | int(f.record.Data[3])
 	} else if f.to_record == -1 {
 		return err
 	}
diff --git a/doc.go b/doc.go
index 8c8112a..73fbfc8 100644
--- a/doc.go
+++ b/doc.go
@@ -44,7 +44,7 @@
 //
 //	cluster.Keyspace = "example"
 //	cluster.Consistency = gocql.Quorum
-//	cluster.ProtoVersion = 4
+//	cluster.ProtoVersion = protoVersion4
 //
 // The driver tries to automatically detect the protocol version to use if not set, but you might want to set the
 // protocol version explicitly, as it's not defined which version will be used in certain situations (for example
diff --git a/docker-compose.yml b/docker-compose.yml
deleted file mode 100644
index 59c348d..0000000
--- a/docker-compose.yml
+++ /dev/null
@@ -1,107 +0,0 @@
-version: "3.7"
-
-services:
-  node_1:
-    image: ${SCYLLA_IMAGE}
-    command: |
-      --smp 2
-      --memory 1G
-      --seeds 192.168.100.11
-      --overprovisioned 1
-      --experimental-features udf
-      --enable-user-defined-functions true
-    networks:
-      public:
-        ipv4_address: 192.168.100.11
-    volumes:
-    - /tmp/scylla_node_1:/var/lib/scylla/
-    - type: bind
-      source: ./testdata/config/scylla.yaml
-      target: /etc/scylla/scylla.yaml
-    - type: bind
-      source: ./testdata/pki/ca.crt
-      target: /etc/scylla/ca.crt
-    - type: bind
-      source: ./testdata/pki/cassandra.crt
-      target: /etc/scylla/db.crt
-    - type: bind
-      source: ./testdata/pki/cassandra.key
-      target: /etc/scylla/db.key
-    healthcheck:
-      test: [ "CMD", "cqlsh", "192.168.100.11", "-e", "select * from system.local where key='local'" ]
-      interval: 5s
-      timeout: 5s
-      retries: 18
-  node_2:
-    image: ${SCYLLA_IMAGE}
-    command: |
-      --smp 2
-      --memory 1G
-      --seeds 192.168.100.11
-      --experimental-features udf
-      --enable-user-defined-functions true
-    networks:
-      public:
-        ipv4_address: 192.168.100.12
-    volumes:
-    - /tmp/scylla_node_2:/var/lib/scylla/
-    - type: bind
-      source: ./testdata/config/scylla.yaml
-      target: /etc/scylla/scylla.yaml
-    - type: bind
-      source: ./testdata/pki/ca.crt
-      target: /etc/scylla/ca.crt
-    - type: bind
-      source: ./testdata/pki/cassandra.crt
-      target: /etc/scylla/db.crt
-    - type: bind
-      source: ./testdata/pki/cassandra.key
-      target: /etc/scylla/db.key
-    healthcheck:
-      test: [ "CMD", "cqlsh", "192.168.100.12", "-e", "select * from system.local where key='local'" ]
-      interval: 5s
-      timeout: 5s
-      retries: 18
-    depends_on:
-      node_1:
-        condition: service_healthy
-  node_3:
-    image: ${SCYLLA_IMAGE}
-    command: |
-      --smp 2
-      --memory 1G
-      --seeds 192.168.100.11
-      --experimental-features udf
-      --enable-user-defined-functions true
-    networks:
-      public:
-        ipv4_address: 192.168.100.13
-    volumes:
-    - /tmp/scylla_node_3:/var/lib/scylla/
-    - type: bind
-      source: ./testdata/config/scylla.yaml
-      target: /etc/scylla/scylla.yaml
-    - type: bind
-      source: ./testdata/pki/ca.crt
-      target: /etc/scylla/ca.crt
-    - type: bind
-      source: ./testdata/pki/cassandra.crt
-      target: /etc/scylla/db.crt
-    - type: bind
-      source: ./testdata/pki/cassandra.key
-      target: /etc/scylla/db.key
-    healthcheck:
-      test: [ "CMD", "cqlsh", "192.168.100.13", "-e", "select * from system.local where key='local'" ]
-      interval: 5s
-      timeout: 5s
-      retries: 18
-    depends_on:
-      node_2:
-        condition: service_healthy
-networks:
-  public:
-    driver: bridge
-    ipam:
-      driver: default
-      config:
-        - subnet: 192.168.100.0/24
diff --git a/exec.go b/exec.go
index 0ffe4cd..ee94e19 100644
--- a/exec.go
+++ b/exec.go
@@ -51,7 +51,7 @@ func NewSingleHostQueryExecutor(cfg *ClusterConfig) (e SingleHostQueryExecutor,

 	// If protocol version not set assume 4 and skip discovery
 	if c.ProtoVersion == 0 {
-		c.ProtoVersion = 4
+		c.ProtoVersion = protoVersion4
 	}

 	// Close in case of error
diff --git a/frame.go b/frame.go
index 95dff4e..0d0dfc4 100644
--- a/frame.go
+++ b/frame.go
@@ -299,8 +299,6 @@ var (
 	ErrFrameTooBig = errors.New("frame length is bigger than the maximum allowed")
 )

-const maxFrameHeaderSize = 9
-
 func readInt(p []byte) int32 {
 	return int32(p[0])<<24 | int32(p[1])<<16 | int32(p[2])<<8 | int32(p[3])
 }
@@ -358,13 +356,14 @@ type framerInterface interface {
 	GetHeaderWarnings() []string
 }

+const headSize = 9
+
 // a framer is responsible for reading, writing and parsing frames on a single stream
 type framer struct {
 	proto byte
 	// flags are for outgoing flags, enabling compression and tracing etc
-	flags    byte
-	compres  Compressor
-	headSize int
+	flags   byte
+	compres Compressor
 	// if this frame was read then the header will be here
 	header *frameHeader

@@ -399,17 +398,9 @@ func newFramer(compressor Compressor, version byte) *framer {
 	}

 	version &= protoVersionMask
-
-	headSize := 8
-	if version > protoVersion2 {
-		headSize = 9
-	}
-
 	f.compres = compressor
 	f.proto = version
 	f.flags = flags
-	f.headSize = headSize
-
 	f.header = nil
 	f.traceID = nil

@@ -470,15 +461,10 @@ func readHeader(r io.Reader, p []byte) (head frameHeader, err error) {

 	version := p[0] & protoVersionMask

-	if version < protoVersion1 || version > protoVersion5 {
+	if version < protoVersion3 || version > protoVersion5 {
 		return frameHeader{}, fmt.Errorf("gocql: unsupported protocol response version: %d", version)
 	}

-	headSize := 9
-	if version < protoVersion3 {
-		headSize = 8
-	}
-
 	_, err = io.ReadFull(r, p[1:headSize])
 	if err != nil {
 		return frameHeader{}, err
@@ -489,24 +475,14 @@ func readHeader(r io.Reader, p []byte) (head frameHeader, err error) {
 	head.version = protoVersion(p[0])
 	head.flags = p[1]

-	if version > protoVersion2 {
-		if len(p) != 9 {
-			return frameHeader{}, fmt.Errorf("not enough bytes to read header require 9 got: %d", len(p))
-		}
-
-		head.stream = int(int16(p[2])<<8 | int16(p[3]))
-		head.op = frameOp(p[4])
-		head.length = int(readInt(p[5:]))
-	} else {
-		if len(p) != 8 {
-			return frameHeader{}, fmt.Errorf("not enough bytes to read header require 8 got: %d", len(p))
-		}
-
-		head.stream = int(int8(p[2]))
-		head.op = frameOp(p[3])
-		head.length = int(readInt(p[4:]))
+	if len(p) != 9 {
+		return frameHeader{}, fmt.Errorf("not enough bytes to read header require 9 got: %d", len(p))
 	}

+	head.stream = int(int16(p[2])<<8 | int16(p[3]))
+	head.op = frameOp(p[4])
+	head.length = int(readInt(p[5:]))
+
 	return head, nil
 }

@@ -755,31 +731,18 @@ func (f *framer) readErrorMap() (errMap ErrorMap) {
 }

 func (f *framer) writeHeader(flags byte, op frameOp, stream int) {
-	if f.proto <= protoVersion2 {
-		f.buf = append(f.buf[:0],
-			f.proto, flags, byte(stream),
-			// pad out length
-			byte(op), 0, 0, 0, 0,
-		)
-	} else {
-		f.buf = append(f.buf[:0],
-			f.proto, flags, byte(stream>>8), byte(stream),
-			// pad out length
-			byte(op), 0, 0, 0, 0,
-		)
-	}
+	f.buf = append(f.buf[:0],
+		f.proto, flags, byte(stream>>8), byte(stream),
+		// pad out length
+		byte(op), 0, 0, 0, 0,
+	)
 }

 func (f *framer) setLength(length int) {
-	p := 5
-	if f.proto <= protoVersion2 {
-		p = 4
-	}
-
-	f.buf[p+0] = byte(length >> 24)
-	f.buf[p+1] = byte(length >> 16)
-	f.buf[p+2] = byte(length >> 8)
-	f.buf[p+3] = byte(length)
+	f.buf[5] = byte(length >> 24)
+	f.buf[6] = byte(length >> 16)
+	f.buf[7] = byte(length >> 8)
+	f.buf[8] = byte(length)
 }

 func (f *framer) finish() error {
@@ -795,14 +758,14 @@ func (f *framer) finish() error {
 		}

 		// TODO: only compress frames which are big enough
-		compressed, err := f.compres.Encode(f.buf[f.headSize:])
+		compressed, err := f.compres.Encode(f.buf[headSize:])
 		if err != nil {
 			return err
 		}

-		f.buf = append(f.buf[:f.headSize], compressed...)
+		f.buf = append(f.buf[:headSize], compressed...)
 	}
-	length := len(f.buf) - f.headSize
+	length := len(f.buf) - headSize
 	f.setLength(length)

 	return nil
@@ -1210,10 +1173,6 @@ func (f *framer) parseResultPrepared() frame {
 		reqMeta:     f.parsePreparedMetadata(),
 	}

-	if f.proto < protoVersion2 {
-		return frame
-	}
-
 	frame.respMeta = f.parseResultMetadata()

 	return frame
@@ -1269,85 +1228,64 @@ type schemaChangeAggregate struct {
 }

 func (f *framer) parseResultSchemaChange() frame {
-	if f.proto <= protoVersion2 {
-		change := f.readString()
-		keyspace := f.readString()
-		table := f.readString()
-
-		if table != "" {
-			return &schemaChangeTable{
-				frameHeader: *f.header,
-				change:      change,
-				keyspace:    keyspace,
-				object:      table,
-			}
-		} else {
-			return &schemaChangeKeyspace{
-				frameHeader: *f.header,
-				change:      change,
-				keyspace:    keyspace,
-			}
+	change := f.readString()
+	target := f.readString()
+
+	// TODO: could just use a separate type for each target
+	switch target {
+	case "KEYSPACE":
+		frame := &schemaChangeKeyspace{
+			frameHeader: *f.header,
+			change:      change,
 		}
-	} else {
-		change := f.readString()
-		target := f.readString()
-
-		// TODO: could just use a separate type for each target
-		switch target {
-		case "KEYSPACE":
-			frame := &schemaChangeKeyspace{
-				frameHeader: *f.header,
-				change:      change,
-			}

-			frame.keyspace = f.readString()
+		frame.keyspace = f.readString()

-			return frame
-		case "TABLE":
-			frame := &schemaChangeTable{
-				frameHeader: *f.header,
-				change:      change,
-			}
+		return frame
+	case "TABLE":
+		frame := &schemaChangeTable{
+			frameHeader: *f.header,
+			change:      change,
+		}

-			frame.keyspace = f.readString()
-			frame.object = f.readString()
+		frame.keyspace = f.readString()
+		frame.object = f.readString()

-			return frame
-		case "TYPE":
-			frame := &schemaChangeType{
-				frameHeader: *f.header,
-				change:      change,
-			}
+		return frame
+	case "TYPE":
+		frame := &schemaChangeType{
+			frameHeader: *f.header,
+			change:      change,
+		}

-			frame.keyspace = f.readString()
-			frame.object = f.readString()
+		frame.keyspace = f.readString()
+		frame.object = f.readString()

-			return frame
-		case "FUNCTION":
-			frame := &schemaChangeFunction{
-				frameHeader: *f.header,
-				change:      change,
-			}
+		return frame
+	case "FUNCTION":
+		frame := &schemaChangeFunction{
+			frameHeader: *f.header,
+			change:      change,
+		}

-			frame.keyspace = f.readString()
-			frame.name = f.readString()
-			frame.args = f.readStringList()
+		frame.keyspace = f.readString()
+		frame.name = f.readString()
+		frame.args = f.readStringList()

-			return frame
-		case "AGGREGATE":
-			frame := &schemaChangeAggregate{
-				frameHeader: *f.header,
-				change:      change,
-			}
+		return frame
+	case "AGGREGATE":
+		frame := &schemaChangeAggregate{
+			frameHeader: *f.header,
+			change:      change,
+		}

-			frame.keyspace = f.readString()
-			frame.name = f.readString()
-			frame.args = f.readStringList()
+		frame.keyspace = f.readString()
+		frame.name = f.readString()
+		frame.args = f.readStringList()

-			return frame
-		default:
-			panic(fmt.Errorf("gocql: unknown SCHEMA_CHANGE target: %q change: %q", target, change))
-		}
+		return frame
+	default:
+		panic(fmt.Errorf("gocql: unknown SCHEMA_CHANGE target: %q change: %q", target, change))
 	}

 }
@@ -1502,10 +1440,6 @@ func (q queryParams) String() string {
 func (f *framer) writeQueryParams(opts *queryParams) {
 	f.writeConsistency(opts.consistency)

-	if f.proto == protoVersion1 {
-		return
-	}
-
 	var flags byte
 	if len(opts.values) > 0 {
 		flags |= flagValues
@@ -1526,15 +1460,13 @@ func (f *framer) writeQueryParams(opts *queryParams) {
 	names := false

 	// protoV3 specific things
-	if f.proto > protoVersion2 {
-		if opts.defaultTimestamp {
-			flags |= flagDefaultTimestamp
-		}
+	if opts.defaultTimestamp {
+		flags |= flagDefaultTimestamp
+	}

-		if len(opts.values) > 0 && opts.values[0].name != "" {
-			flags |= flagWithNameValues
-			names = true
-		}
+	if len(opts.values) > 0 && opts.values[0].name != "" {
+		flags |= flagWithNameValues
+		names = true
 	}

 	if opts.keyspace != "" {
@@ -1578,7 +1510,7 @@ func (f *framer) writeQueryParams(opts *queryParams) {
 		f.writeConsistency(opts.serialConsistency)
 	}

-	if f.proto > protoVersion2 && opts.defaultTimestamp {
+	if opts.defaultTimestamp {
 		// timestamp in microseconds
 		var ts int64
 		if opts.defaultTimestampValue != 0 {
@@ -1655,20 +1587,7 @@ func (f *framer) writeExecuteFrame(streamID int, preparedID []byte, params *quer
 	f.writeHeader(f.flags, opExecute, streamID)
 	f.writeCustomPayload(customPayload)
 	f.writeShortBytes(preparedID)
-	if f.proto > protoVersion1 {
-		f.writeQueryParams(params)
-	} else {
-		n := len(params.values)
-		f.writeShort(uint16(n))
-		for i := 0; i < n; i++ {
-			if params.values[i].isUnset {
-				f.writeUnset()
-			} else {
-				f.writeBytes(params.values[i].value)
-			}
-		}
-		f.writeConsistency(params.consistency)
-	}
+	f.writeQueryParams(params)

 	return f.finish()
 }
@@ -1725,7 +1644,7 @@ func (f *framer) writeBatchFrame(streamID int, w *writeBatchFrame, customPayload
 		f.writeShort(uint16(len(b.values)))
 		for j := range b.values {
 			col := b.values[j]
-			if f.proto > protoVersion2 && col.name != "" {
+			if col.name != "" {
 				// TODO: move this check into the caller and set a flag on writeBatchFrame
 				// to indicate using named values
 				if f.proto <= protoVersion5 {
@@ -1744,33 +1663,31 @@ func (f *framer) writeBatchFrame(streamID int, w *writeBatchFrame, customPayload

 	f.writeConsistency(w.consistency)

-	if f.proto > protoVersion2 {
-		if w.serialConsistency > 0 {
-			flags |= flagWithSerialConsistency
-		}
-		if w.defaultTimestamp {
-			flags |= flagDefaultTimestamp
-		}
+	if w.serialConsistency > 0 {
+		flags |= flagWithSerialConsistency
+	}
+	if w.defaultTimestamp {
+		flags |= flagDefaultTimestamp
+	}

-		if f.proto > protoVersion4 {
-			f.writeUint(uint32(flags))
-		} else {
-			f.writeByte(flags)
-		}
+	if f.proto > protoVersion4 {
+		f.writeUint(uint32(flags))
+	} else {
+		f.writeByte(flags)
+	}

-		if w.serialConsistency > 0 {
-			f.writeConsistency(w.serialConsistency)
-		}
+	if w.serialConsistency > 0 {
+		f.writeConsistency(w.serialConsistency)
+	}

-		if w.defaultTimestamp {
-			var ts int64
-			if w.defaultTimestampValue != 0 {
-				ts = w.defaultTimestampValue
-			} else {
-				ts = time.Now().UnixNano() / 1000
-			}
-			f.writeLong(ts)
+	if w.defaultTimestamp {
+		var ts int64
+		if w.defaultTimestampValue != 0 {
+			ts = w.defaultTimestampValue
+		} else {
+			ts = time.Now().UnixNano() / 1000
 		}
+		f.writeLong(ts)
 	}

 	return f.finish()
diff --git a/frame_test.go b/frame_test.go
index 546467f..67827ac 100644
--- a/frame_test.go
+++ b/frame_test.go
@@ -91,7 +91,7 @@ func TestFrameWriteTooLong(t *testing.T) {
 		t.Skip("skipping test in travis due to memory pressure with the race detecor")
 	}

-	framer := newFramer(nil, 2)
+	framer := newFramer(nil, 3)

 	framer.writeHeader(0, opStartup, 1)
 	framer.writeBytes(make([]byte, maxFrameSize+1))
@@ -111,14 +111,14 @@ func TestFrameReadTooLong(t *testing.T) {
 	r := &bytes.Buffer{}
 	r.Write(make([]byte, maxFrameSize+1))
 	// write a new header right after this frame to verify that we can read it
-	r.Write([]byte{0x02, 0x00, 0x00, byte(opReady), 0x00, 0x00, 0x00, 0x00})
+	r.Write([]byte{0x03, 0x00, 0x00, 0x00, byte(opReady), 0x00, 0x00, 0x00, 0x00})

-	framer := newFramer(nil, 2)
+	framer := newFramer(nil, 3)

 	head := frameHeader{
-		version: 2,
+		version: protoVersion3,
 		op:      opReady,
-		length:  r.Len() - 8,
+		length:  r.Len() - 9,
 	}

 	err := framer.readFrame(r, &head)
@@ -126,7 +126,7 @@ func TestFrameReadTooLong(t *testing.T) {
 		t.Fatalf("expected to get %v got %v", ErrFrameTooBig, err)
 	}

-	head, err = readHeader(r, make([]byte, 8))
+	head, err = readHeader(r, make([]byte, 9))
 	if err != nil {
 		t.Fatal(err)
 	}
diff --git a/go.mod b/go.mod
index 48181f6..fe4be26 100644
--- a/go.mod
+++ b/go.mod
@@ -29,8 +29,9 @@ require (
 require (
 	github.com/bitly/go-hostpool v0.0.0-20171023180738-a3a6125de932 // indirect
 	github.com/bmizerany/assert v0.0.0-20160611221934-b7ed37b82869 // indirect
+	github.com/google/uuid v1.6.0
 	github.com/kr/pretty v0.1.0 // indirect
-	github.com/stretchr/testify v1.9.0 // indirect
+	github.com/stretchr/testify v1.9.0
 )

 retract (
diff --git a/go.sum b/go.sum
index c49e102..ebee6e1 100644
--- a/go.sum
+++ b/go.sum
@@ -7,6 +7,8 @@ github.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c
 github.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
 github.com/google/go-cmp v0.4.0 h1:xsAVV57WRhGj6kEIi8ReJzQlHHqcBYCElAvkovg3B/4=
 github.com/google/go-cmp v0.4.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=
+github.com/google/uuid v1.6.0 h1:NIvaJDMOsjHA8n1jAhLSgzrAzy1Hgr+hNrb57e+94F0=
+github.com/google/uuid v1.6.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=
 github.com/hailocab/go-hostpool v0.0.0-20160125115350-e80d13ce29ed h1:5upAirOpQc1Q53c0bnx2ufif5kANL7bfZWcc6VJWJd8=
 github.com/hailocab/go-hostpool v0.0.0-20160125115350-e80d13ce29ed/go.mod h1:tMWxXQ9wFIaZeTI9F+hmhFiGpFmhOHzyShyFUhRm0H4=
 github.com/klauspost/compress v1.17.9 h1:6KIumPrER1LHsvBVuDa0r5xaG0Es51mhhB9BQB2qeMA=
diff --git a/integration.sh b/integration.sh
index 41359e4..88f1eb9 100755
--- a/integration.sh
+++ b/integration.sh
@@ -35,7 +35,7 @@ readonly clusterSize=3
 readonly scylla_liveset="192.168.100.11,192.168.100.12,192.168.100.13"
 readonly cversion="3.11.4"
 readonly proto=4
-readonly args="-gocql.timeout=60s -proto=${proto} -rf=1 -clusterSize=${clusterSize} -autowait=2000ms -compressor=snappy -gocql.cversion=${cversion} -cluster=${scylla_liveset}"
+readonly args="-cluster-socket /tmp/scylla_node_1/cql.m -gocql.timeout=60s -proto=${proto} -rf=1 -clusterSize=${clusterSize} -autowait=2000ms -compressor=snappy -gocql.cversion=${cversion} -cluster=${scylla_liveset}"

 TAGS=$*

diff --git a/integration_test.go b/integration_test.go
index d59836a..8da7176 100644
--- a/integration_test.go
+++ b/integration_test.go
@@ -31,6 +31,7 @@ package gocql
 import (
 	"context"
 	"errors"
+	"github.com/gocql/gocql/internal/tests"
 	"reflect"
 	"testing"
 	"time"
@@ -39,10 +40,6 @@ import (
 // TestAuthentication verifies that gocql will work with a host configured to only accept authenticated connections
 func TestAuthentication(t *testing.T) {

-	if *flagProto < 2 {
-		t.Skip("Authentication is not supported with protocol < 2")
-	}
-
 	if !*flagRunAuthTest {
 		t.Skip("Authentication is not configured in the target cluster")
 	}
@@ -70,9 +67,9 @@ func TestGetHostsFromSystem(t *testing.T) {

 	hosts, partitioner, err := session.hostSource.GetHostsFromSystem()

-	assertTrue(t, "err == nil", err == nil)
-	assertEqual(t, "len(hosts)", len(clusterHosts), len(hosts))
-	assertTrue(t, "len(partitioner) != 0", len(partitioner) != 0)
+	tests.AssertTrue(t, "err == nil", err == nil)
+	tests.AssertEqual(t, "len(hosts)", len(clusterHosts), len(hosts))
+	tests.AssertTrue(t, "len(partitioner) != 0", len(partitioner) != 0)
 }

 // TestRingDiscovery makes sure that you can autodiscover other cluster members
@@ -124,7 +121,7 @@ func TestHostFilterDiscovery(t *testing.T) {
 	session := createSessionFromCluster(cluster, t)
 	defer session.Close()

-	assertEqual(t, "len(clusterHosts)-1 != len(rr.hosts.get())", len(clusterHosts)-1, len(rr.hosts.get()))
+	tests.AssertEqual(t, "len(clusterHosts)-1 != len(rr.hosts.get())", len(clusterHosts)-1, len(rr.hosts.get()))
 }

 // TestHostFilterInitial ensures that host filtering works for the initial
@@ -148,7 +145,7 @@ func TestHostFilterInitial(t *testing.T) {
 	session := createSessionFromCluster(cluster, t)
 	defer session.Close()

-	assertEqual(t, "len(clusterHosts)-1 != len(rr.hosts.get())", len(clusterHosts)-1, len(rr.hosts.get()))
+	tests.AssertEqual(t, "len(clusterHosts)-1 != len(rr.hosts.get())", len(clusterHosts)-1, len(rr.hosts.get()))
 }

 func TestWriteFailure(t *testing.T) {
@@ -167,7 +164,7 @@ func TestWriteFailure(t *testing.T) {
 	if err := session.Query(`INSERT INTO test.test (id, value) VALUES (1, 1)`).Exec(); err != nil {
 		errWrite, ok := err.(*RequestErrWriteFailure)
 		if ok {
-			if session.cfg.ProtoVersion >= 5 {
+			if session.cfg.ProtoVersion >= protoVersion5 {
 				// ErrorMap should be filled with some hosts that should've errored
 				if len(errWrite.ErrorMap) == 0 {
 					t.Fatal("errWrite.ErrorMap should have some failed hosts but it didn't have any")
diff --git a/internal/streams/streams.go b/internal/streams/streams.go
index b09f49d..595a147 100644
--- a/internal/streams/streams.go
+++ b/internal/streams/streams.go
@@ -43,12 +43,8 @@ type IDGenerator struct {
 	offset  uint32
 }

-func New(protocol int) *IDGenerator {
-	maxStreams := 128
-	if protocol > 2 {
-		maxStreams = 32768
-	}
-	return NewLimited(maxStreams)
+func New() *IDGenerator {
+	return NewLimited(32768)
 }

 func NewLimited(maxStreams int) *IDGenerator {
diff --git a/internal/streams/streams_test.go b/internal/streams/streams_test.go
index 489c235..425e341 100644
--- a/internal/streams/streams_test.go
+++ b/internal/streams/streams_test.go
@@ -37,7 +37,7 @@ import (
 func TestUsesAllStreams(t *testing.T) {
 	t.Parallel()

-	streams := New(1)
+	streams := New()

 	got := make(map[int]struct{})

@@ -78,7 +78,7 @@ func TestUsesAllStreams(t *testing.T) {
 func TestFullStreams(t *testing.T) {
 	t.Parallel()

-	streams := New(1)
+	streams := New()
 	for i := range streams.streams {
 		streams.streams[i] = math.MaxUint64
 	}
@@ -92,7 +92,7 @@ func TestFullStreams(t *testing.T) {
 func TestClearStreams(t *testing.T) {
 	t.Parallel()

-	streams := New(1)
+	streams := New()
 	for i := range streams.streams {
 		streams.streams[i] = math.MaxUint64
 	}
@@ -112,7 +112,7 @@ func TestClearStreams(t *testing.T) {
 func TestDoubleClear(t *testing.T) {
 	t.Parallel()

-	streams := New(1)
+	streams := New()
 	stream, ok := streams.GetStream()
 	if !ok {
 		t.Fatal("did not get stream")
@@ -127,7 +127,7 @@ func TestDoubleClear(t *testing.T) {
 }

 func BenchmarkConcurrentUse(b *testing.B) {
-	streams := New(2)
+	streams := New()

 	b.RunParallel(func(pb *testing.PB) {
 		for pb.Next() {
diff --git a/internal/tests/common.go b/internal/tests/common.go
new file mode 100644
index 0000000..a95fa28
--- /dev/null
+++ b/internal/tests/common.go
@@ -0,0 +1,64 @@
+package tests
+
+import (
+	"fmt"
+	"reflect"
+	"strconv"
+	"testing"
+
+	"github.com/google/uuid"
+)
+
+func AssertTrue(t *testing.T, description string, value bool) {
+	t.Helper()
+	if !value {
+		t.Fatalf("expected %s to be true", description)
+	}
+}
+
+func AssertEqual(t *testing.T, description string, expected, actual interface{}) {
+	t.Helper()
+	if expected != actual {
+		t.Fatalf("expected %s to be (%+v) but was (%+v) instead", description, expected, actual)
+	}
+}
+
+func AssertDeepEqual(t *testing.T, description string, expected, actual interface{}) {
+	t.Helper()
+	if !reflect.DeepEqual(expected, actual) {
+		t.Fatalf("expected %s to be (%+v) but was (%+v) instead", description, expected, actual)
+	}
+}
+
+func AssertNil(t *testing.T, description string, actual interface{}) {
+	t.Helper()
+	if actual != nil {
+		t.Fatalf("expected %s to be (nil) but was (%+v) instead", description, actual)
+	}
+}
+
+func RandomUUID() string {
+	val, err := uuid.NewRandom()
+	if err != nil {
+		panic(fmt.Sprintf("failed to generate UUID: %s", err.Error()))
+	}
+	return val.String()
+}
+
+// GenerateHostNames generates a slice of host names with the format "host0", "host1", ..., "hostN-1",
+// where N is the specified hostCount.
+//
+// Parameters:
+//
+//	hostCount - the number of host names to generate.
+//
+// Returns:
+//
+//	A slice of strings containing host names.
+func GenerateHostNames(hostCount int) []string {
+	hosts := make([]string, hostCount)
+	for i := 0; i < hostCount; i++ {
+		hosts[i] = "host" + strconv.Itoa(i)
+	}
+	return hosts
+}
diff --git a/internal/tests/rand.go b/internal/tests/rand.go
new file mode 100644
index 0000000..e5382eb
--- /dev/null
+++ b/internal/tests/rand.go
@@ -0,0 +1,164 @@
+package tests
+
+import (
+	"math/rand"
+	"sync"
+)
+
+// RandInterface defines the thread-safe random number generator interface.
+// It abstracts all methods provided by ThreadSafeRand.
+type RandInterface interface {
+	Uint64() uint64
+	Uint32() uint32
+	Int() int
+	Intn(n int) int
+	Int63() int64
+	Int63n(n int64) int64
+	Int31() int32
+	Int31n(n int32) int32
+	Float64() float64
+	Float32() float32
+	ExpFloat64() float64
+	NormFloat64() float64
+	Shuffle(n int, swap func(i, j int))
+	Read(p []byte) (n int, err error)
+}
+
+// RandomTokens generates a slice of n random int64 tokens using a thread-safe random number generator.
+//
+// Parameters:
+//
+//	n - the number of random tokens to generate.
+//
+// Returns:
+//
+//	A slice of n randomly generated int64 tokens.
+func RandomTokens(rnd RandInterface, n int) []int64 {
+	var tokens []int64
+	for i := 0; i < n; i++ {
+		tokens = append(tokens, rnd.Int63())
+	}
+	return tokens
+}
+
+// ShuffledIndexes returns a slice containing integers from 0 to n-1 in random order.
+//
+// It uses a thread-safe random number generator to perform an in-place shuffle.
+//
+// Parameters:
+//
+//	n - the number of elements to include in the shuffled list.
+//
+// Returns:
+//
+//	A randomly shuffled slice of integers from 0 to n-1.
+func ShuffledIndexes(rnd RandInterface, n int) []int {
+	indexes := make([]int, n)
+	for i := range indexes {
+		indexes[i] = i
+	}
+	rnd.Shuffle(n, func(i, j int) {
+		indexes[i], indexes[j] = indexes[j], indexes[i]
+	})
+	return indexes
+}
+
+// ThreadSafeRand provides a concurrency-safe wrapper around math/rand.Rand.
+// It allows safe usage of random number generation methods from multiple goroutines.
+// All access to the underlying rand.Rand is synchronized via a mutex.
+type ThreadSafeRand struct {
+	r   *rand.Rand
+	mux sync.Mutex
+}
+
+// NewThreadSafeRand creates and returns a new instance of ThreadSafeRand,
+// initialized with the given seed. The resulting generator is safe for concurrent use.
+func NewThreadSafeRand(seed int64) *ThreadSafeRand {
+	return &ThreadSafeRand{
+		r: rand.New(rand.NewSource(seed)),
+	}
+}
+
+func (r *ThreadSafeRand) Uint64() uint64 {
+	r.mux.Lock()
+	defer r.mux.Unlock()
+	return r.r.Uint64()
+}
+
+func (r *ThreadSafeRand) Uint32() uint32 {
+	r.mux.Lock()
+	defer r.mux.Unlock()
+	return r.r.Uint32()
+}
+
+func (r *ThreadSafeRand) Int() int {
+	r.mux.Lock()
+	defer r.mux.Unlock()
+	return r.r.Int()
+}
+
+func (r *ThreadSafeRand) Intn(n int) int {
+	r.mux.Lock()
+	defer r.mux.Unlock()
+	return r.r.Intn(n)
+}
+
+func (r *ThreadSafeRand) Int63() int64 {
+	r.mux.Lock()
+	defer r.mux.Unlock()
+	return r.r.Int63()
+}
+
+func (r *ThreadSafeRand) Int63n(n int64) int64 {
+	r.mux.Lock()
+	defer r.mux.Unlock()
+	return r.r.Int63n(n)
+}
+
+func (r *ThreadSafeRand) Int31() int32 {
+	r.mux.Lock()
+	defer r.mux.Unlock()
+	return r.r.Int31()
+}
+
+func (r *ThreadSafeRand) Int31n(n int32) int32 {
+	r.mux.Lock()
+	defer r.mux.Unlock()
+	return r.r.Int31n(n)
+}
+
+func (r *ThreadSafeRand) Float64() float64 {
+	r.mux.Lock()
+	defer r.mux.Unlock()
+	return r.r.Float64()
+}
+
+func (r *ThreadSafeRand) Float32() float32 {
+	r.mux.Lock()
+	defer r.mux.Unlock()
+	return r.r.Float32()
+}
+
+func (r *ThreadSafeRand) ExpFloat64() float64 {
+	r.mux.Lock()
+	defer r.mux.Unlock()
+	return r.r.ExpFloat64()
+}
+
+func (r *ThreadSafeRand) NormFloat64() float64 {
+	r.mux.Lock()
+	defer r.mux.Unlock()
+	return r.r.NormFloat64()
+}
+
+func (r *ThreadSafeRand) Shuffle(n int, swap func(i, j int)) {
+	r.mux.Lock()
+	defer r.mux.Unlock()
+	r.r.Shuffle(n, swap)
+}
+
+func (r *ThreadSafeRand) Read(p []byte) (n int, err error) {
+	r.mux.Lock()
+	defer r.mux.Unlock()
+	return r.r.Read(p)
+}
diff --git a/keyspace_table_test.go b/keyspace_table_test.go
index 0b93f62..d21ef2b 100644
--- a/keyspace_table_test.go
+++ b/keyspace_table_test.go
@@ -30,6 +30,7 @@ package gocql
 import (
 	"context"
 	"fmt"
+	"github.com/gocql/gocql/internal/tests"
 	"testing"
 )

@@ -100,6 +101,6 @@ func TestKeyspaceTable(t *testing.T) {

 	// cluster.Keyspace was set to "wrong_keyspace", but during prepering statement
 	// Keyspace in Query should be changed to "test" and Table should be changed to table1
-	assertEqual(t, "qry.Keyspace()", "test1", qry.Keyspace())
-	assertEqual(t, "qry.Table()", "table1", qry.Table())
+	tests.AssertEqual(t, "qry.Keyspace()", "test1", qry.Keyspace())
+	tests.AssertEqual(t, "qry.Table()", "table1", qry.Table())
 }
diff --git a/marshal.go b/marshal.go
index 6d76646..4aad0fd 100644
--- a/marshal.go
+++ b/marshal.go
@@ -30,7 +30,6 @@ import (
 	"fmt"
 	"math"
 	"reflect"
-	"strings"
 	"unsafe"

 	"github.com/gocql/gocql/serialization/ascii"
@@ -231,11 +230,6 @@ func Marshal(info TypeInfo, value interface{}) ([]byte, error) {
 		return marshalDuration(value)
 	}

-	// detect protocol 2 UDT
-	if strings.HasPrefix(info.Custom(), "org.apache.cassandra.db.marshal.UserType") && info.Version() < 3 {
-		return nil, ErrorUDTUnavailable
-	}
-
 	// TODO(tux21b): add the remaining types
 	return nil, fmt.Errorf("can not marshal %T into %s", value, info)
 }
@@ -343,11 +337,6 @@ func Unmarshal(info TypeInfo, data []byte, value interface{}) error {
 		return unmarshalDuration(data, value)
 	}

-	// detect protocol 2 UDT
-	if strings.HasPrefix(info.Custom(), "org.apache.cassandra.db.marshal.UserType") && info.Version() < 3 {
-		return ErrorUDTUnavailable
-	}
-
 	// TODO(tux21b): add the remaining types
 	return fmt.Errorf("can not unmarshal %s into %T", info, value)
 }
@@ -685,24 +674,15 @@ func unmarshalDuration(data []byte, value interface{}) error {
 }

 func writeCollectionSize(info CollectionType, n int, buf *bytes.Buffer) error {
-	if info.proto > protoVersion2 {
-		if n > math.MaxInt32 {
-			return marshalErrorf("marshal: collection too large")
-		}
-
-		buf.WriteByte(byte(n >> 24))
-		buf.WriteByte(byte(n >> 16))
-		buf.WriteByte(byte(n >> 8))
-		buf.WriteByte(byte(n))
-	} else {
-		if n > math.MaxUint16 {
-			return marshalErrorf("marshal: collection too large")
-		}
-
-		buf.WriteByte(byte(n >> 8))
-		buf.WriteByte(byte(n))
+	if n > math.MaxInt32 {
+		return marshalErrorf("marshal: collection too large")
 	}

+	buf.WriteByte(byte(n >> 24))
+	buf.WriteByte(byte(n >> 16))
+	buf.WriteByte(byte(n >> 8))
+	buf.WriteByte(byte(n))
+
 	return nil
 }

@@ -741,7 +721,7 @@ func marshalList(info TypeInfo, value interface{}) ([]byte, error) {
 			}
 			itemLen := len(item)
 			// Set the value to null for supported protocols
-			if item == nil && listInfo.proto > protoVersion2 {
+			if item == nil {
 				itemLen = -1
 			}
 			if err := writeCollectionSize(listInfo, itemLen, buf); err != nil {
@@ -765,19 +745,11 @@ func marshalList(info TypeInfo, value interface{}) ([]byte, error) {
 }

 func readCollectionSize(info CollectionType, data []byte) (size, read int, err error) {
-	if info.proto > protoVersion2 {
-		if len(data) < 4 {
-			return 0, 0, unmarshalErrorf("unmarshal list: unexpected eof")
-		}
-		size = int(int32(data[0])<<24 | int32(data[1])<<16 | int32(data[2])<<8 | int32(data[3]))
-		read = 4
-	} else {
-		if len(data) < 2 {
-			return 0, 0, unmarshalErrorf("unmarshal list: unexpected eof")
-		}
-		size = int(data[0])<<8 | int(data[1])
-		read = 2
+	if len(data) < 4 {
+		return 0, 0, unmarshalErrorf("unmarshal list: unexpected eof")
 	}
+	size = int(int32(data[0])<<24 | int32(data[1])<<16 | int32(data[2])<<8 | int32(data[3]))
+	read = 4
 	return
 }

@@ -881,7 +853,7 @@ func marshalMap(info TypeInfo, value interface{}) ([]byte, error) {
 		}
 		itemLen := len(item)
 		// Set the key to null for supported protocols
-		if item == nil && mapInfo.proto > protoVersion2 {
+		if item == nil {
 			itemLen = -1
 		}
 		if err := writeCollectionSize(mapInfo, itemLen, buf); err != nil {
@@ -895,7 +867,7 @@ func marshalMap(info TypeInfo, value interface{}) ([]byte, error) {
 		}
 		itemLen = len(item)
 		// Set the value to null for supported protocols
-		if item == nil && mapInfo.proto > protoVersion2 {
+		if item == nil {
 			itemLen = -1
 		}
 		if err := writeCollectionSize(mapInfo, itemLen, buf); err != nil {
diff --git a/marshal_test.go b/marshal_test.go
index 363a49d..e7cfebc 100644
--- a/marshal_test.go
+++ b/marshal_test.go
@@ -30,13 +30,14 @@ package gocql
 import (
 	"bytes"
 	"encoding/binary"
-	"gopkg.in/inf.v0"
 	"math"
 	"math/big"
 	"net"
 	"reflect"
 	"strings"
 	"testing"
+
+	"gopkg.in/inf.v0"
 )

 type AliasInt int
@@ -53,277 +54,10 @@ var marshalTests = []struct {
 	MarshalError   error
 	UnmarshalError error
 }{
-	{
-		NativeType{proto: 2, typ: TypeDecimal},
-		[]byte("\x00\x00\x00\x00\x00"),
-		inf.NewDec(0, 0),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeDecimal},
-		[]byte("\x00\x00\x00\x00\x64"),
-		inf.NewDec(100, 0),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeDecimal},
-		[]byte("\x00\x00\x00\x02\x19"),
-		decimalize("0.25"),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeDecimal},
-		[]byte("\x00\x00\x00\x13\xD5\a;\x20\x14\xA2\x91"),
-		decimalize("-0.0012095473475870063"), // From the iconara/cql-rb test suite
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeDecimal},
-		[]byte("\x00\x00\x00\x13*\xF8\xC4\xDF\xEB]o"),
-		decimalize("0.0012095473475870063"), // From the iconara/cql-rb test suite
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeDecimal},
-		[]byte("\x00\x00\x00\x12\xF2\xD8\x02\xB6R\x7F\x99\xEE\x98#\x99\xA9V"),
-		decimalize("-1042342234234.123423435647768234"), // From the iconara/cql-rb test suite
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeDecimal},
-		[]byte("\x00\x00\x00\r\nJ\x04\"^\x91\x04\x8a\xb1\x18\xfe"),
-		decimalize("1243878957943.1234124191998"), // From the datastax/python-driver test suite
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeDecimal},
-		[]byte("\x00\x00\x00\x06\xe5\xde]\x98Y"),
-		decimalize("-112233.441191"), // From the datastax/python-driver test suite
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeDecimal},
-		[]byte("\x00\x00\x00\x14\x00\xfa\xce"),
-		decimalize("0.00000000000000064206"), // From the datastax/python-driver test suite
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeDecimal},
-		[]byte("\x00\x00\x00\x14\xff\x052"),
-		decimalize("-0.00000000000000064206"), // From the datastax/python-driver test suite
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeDecimal},
-		[]byte("\xff\xff\xff\x9c\x00\xfa\xce"),
-		inf.NewDec(64206, -100), // From the datastax/python-driver test suite
-		nil,
-		nil,
-	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeList},
-			Elem:       NativeType{proto: 2, typ: TypeInt},
-		},
-		[]byte("\x00\x02\x00\x04\x00\x00\x00\x01\x00\x04\x00\x00\x00\x02"),
-		[]int{1, 2},
-		nil,
-		nil,
-	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeList},
-			Elem:       NativeType{proto: 2, typ: TypeInt},
-		},
-		[]byte("\x00\x02\x00\x04\x00\x00\x00\x01\x00\x04\x00\x00\x00\x02"),
-		[2]int{1, 2},
-		nil,
-		nil,
-	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeSet},
-			Elem:       NativeType{proto: 2, typ: TypeInt},
-		},
-		[]byte("\x00\x02\x00\x04\x00\x00\x00\x01\x00\x04\x00\x00\x00\x02"),
-		[]int{1, 2},
-		nil,
-		nil,
-	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeSet},
-			Elem:       NativeType{proto: 2, typ: TypeInt},
-		},
-		[]byte{0, 0}, // encoding of a list should always include the size of the collection
-		[]int{},
-		nil,
-		nil,
-	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeMap},
-			Key:        NativeType{proto: 2, typ: TypeVarchar},
-			Elem:       NativeType{proto: 2, typ: TypeInt},
-		},
-		[]byte("\x00\x01\x00\x03foo\x00\x04\x00\x00\x00\x01"),
-		map[string]int{"foo": 1},
-		nil,
-		nil,
-	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeMap},
-			Key:        NativeType{proto: 2, typ: TypeVarchar},
-			Elem:       NativeType{proto: 2, typ: TypeInt},
-		},
-		[]byte{0, 0},
-		map[string]int{},
-		nil,
-		nil,
-	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeMap},
-			Key:        NativeType{proto: 2, typ: TypeVarchar},
-			Elem:       NativeType{proto: 2, typ: TypeBlob},
-		},
-		[]byte("\x00\x01\x00\x03foo\x00\x05\x01\x02\x03\x04\x05"),
-		map[string]interface{}{
-			"foo": []byte{0x01, 0x02, 0x03, 0x04, 0x05},
-		},
-		nil,
-		nil,
-	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeList},
-			Elem:       NativeType{proto: 2, typ: TypeVarchar},
-		},
-		bytes.Join([][]byte{
-			[]byte("\x00\x01\xFF\xFF"),
-			bytes.Repeat([]byte("X"), math.MaxUint16)}, []byte("")),
-		[]string{strings.Repeat("X", math.MaxUint16)},
-		nil,
-		nil,
-	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeMap},
-			Key:        NativeType{proto: 2, typ: TypeVarchar},
-			Elem:       NativeType{proto: 2, typ: TypeVarchar},
-		},
-		bytes.Join([][]byte{
-			[]byte("\x00\x01\xFF\xFF"),
-			bytes.Repeat([]byte("X"), math.MaxUint16),
-			[]byte("\xFF\xFF"),
-			bytes.Repeat([]byte("Y"), math.MaxUint16)}, []byte("")),
-		map[string]string{
-			strings.Repeat("X", math.MaxUint16): strings.Repeat("Y", math.MaxUint16),
-		},
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeInet},
-		[]byte("\x7F\x00\x00\x01"),
-		net.ParseIP("127.0.0.1").To4(),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeInet},
-		[]byte("\xFF\xFF\xFF\xFF"),
-		net.ParseIP("255.255.255.255").To4(),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeInet},
-		[]byte("\x7F\x00\x00\x01"),
-		"127.0.0.1",
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeInet},
-		[]byte("\xFF\xFF\xFF\xFF"),
-		"255.255.255.255",
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeInet},
-		[]byte("\x21\xDA\x00\xd3\x00\x00\x2f\x3b\x02\xaa\x00\xff\xfe\x28\x9c\x5a"),
-		"21da:d3:0:2f3b:2aa:ff:fe28:9c5a",
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeInet},
-		[]byte("\xfe\x80\x00\x00\x00\x00\x00\x00\x02\x02\xb3\xff\xfe\x1e\x83\x29"),
-		"fe80::202:b3ff:fe1e:8329",
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeInet},
-		[]byte("\x21\xDA\x00\xd3\x00\x00\x2f\x3b\x02\xaa\x00\xff\xfe\x28\x9c\x5a"),
-		net.ParseIP("21da:d3:0:2f3b:2aa:ff:fe28:9c5a"),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeInet},
-		[]byte("\xfe\x80\x00\x00\x00\x00\x00\x00\x02\x02\xb3\xff\xfe\x1e\x83\x29"),
-		net.ParseIP("fe80::202:b3ff:fe1e:8329"),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeInet},
-		[]byte("\x7F\x00\x00\x01"),
-		func() *net.IP {
-			ip := net.ParseIP("127.0.0.1").To4()
-			return &ip
-		}(),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeInet},
-		[]byte(nil),
-		(*net.IP)(nil),
-		nil,
-		nil,
-	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeList},
-			Elem:       NativeType{proto: 2, typ: TypeInt},
-		},
-		[]byte("\x00\x02\x00\x04\x00\x00\x00\x01\x00\x04\x00\x00\x00\x02"),
-		func() *[]int {
-			l := []int{1, 2}
-			return &l
-		}(),
-		nil,
-		nil,
-	},
 	{
 		CollectionType{
-			NativeType: NativeType{proto: 3, typ: TypeList},
-			Elem:       NativeType{proto: 3, typ: TypeInt},
+			NativeType: NativeType{proto: protoVersion3, typ: TypeList},
+			Elem:       NativeType{proto: protoVersion3, typ: TypeInt},
 		},
 		[]byte("\x00\x00\x00\x02\x00\x00\x00\x04\x00\x00\x00\x01\x00\x00\x00\x04\x00\x00\x00\x02"),
 		func() *[]int {
@@ -333,139 +67,6 @@ var marshalTests = []struct {
 		nil,
 		nil,
 	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeList},
-			Elem:       NativeType{proto: 2, typ: TypeInt},
-		},
-		[]byte(nil),
-		(*[]int)(nil),
-		nil,
-		nil,
-	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeMap},
-			Key:        NativeType{proto: 2, typ: TypeVarchar},
-			Elem:       NativeType{proto: 2, typ: TypeInt},
-		},
-		[]byte("\x00\x01\x00\x03foo\x00\x04\x00\x00\x00\x01"),
-		func() *map[string]int {
-			m := map[string]int{"foo": 1}
-			return &m
-		}(),
-		nil,
-		nil,
-	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeMap},
-			Key:        NativeType{proto: 2, typ: TypeVarchar},
-			Elem:       NativeType{proto: 2, typ: TypeInt},
-		},
-		[]byte(nil),
-		(*map[string]int)(nil),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeTinyInt},
-		[]byte("\x7f"),
-		127, // math.MaxInt8
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeTinyInt},
-		[]byte("\x7f"),
-		"127", // math.MaxInt8
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeTinyInt},
-		[]byte("\x01"),
-		int16(1),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeTinyInt},
-		[]byte("\xff"),
-		int16(-1),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeTinyInt},
-		[]byte("\xff"),
-		uint8(255),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeTinyInt},
-		[]byte("\xff"),
-		uint64(255),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeTinyInt},
-		[]byte("\xff"),
-		uint32(255),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeTinyInt},
-		[]byte("\xff"),
-		uint16(255),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeTinyInt},
-		[]byte("\xff"),
-		uint(255),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeTinyInt},
-		[]byte("\xff"),
-		AliasUint8(255),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeTinyInt},
-		[]byte("\xff"),
-		AliasUint64(255),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeTinyInt},
-		[]byte("\xff"),
-		AliasUint32(255),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeTinyInt},
-		[]byte("\xff"),
-		AliasUint16(255),
-		nil,
-		nil,
-	},
-	{
-		NativeType{proto: 2, typ: TypeTinyInt},
-		[]byte("\xff"),
-		AliasUint(255),
-		nil,
-		nil,
-	},
 }

 var unmarshalTests = []struct {
@@ -476,8 +77,8 @@ var unmarshalTests = []struct {
 }{
 	{
 		CollectionType{
-			NativeType: NativeType{proto: 3, typ: TypeList},
-			Elem:       NativeType{proto: 3, typ: TypeInt},
+			NativeType: NativeType{proto: protoVersion3, typ: TypeList},
+			Elem:       NativeType{proto: protoVersion3, typ: TypeInt},
 		},
 		[]byte("\x00\x00\x00\x02\x00\x00\x00\x04\x00\x00"), // truncated data
 		func() *[]int {
@@ -486,26 +87,6 @@ var unmarshalTests = []struct {
 		}(),
 		unmarshalErrorf("unmarshal list: unexpected eof"),
 	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeMap},
-			Key:        NativeType{proto: 2, typ: TypeVarchar},
-			Elem:       NativeType{proto: 2, typ: TypeInt},
-		},
-		[]byte("\x00\x01\x00\x03fo"),
-		map[string]int{"foo": 1},
-		unmarshalErrorf("unmarshal map: unexpected eof"),
-	},
-	{
-		CollectionType{
-			NativeType: NativeType{proto: 2, typ: TypeMap},
-			Key:        NativeType{proto: 2, typ: TypeVarchar},
-			Elem:       NativeType{proto: 2, typ: TypeInt},
-		},
-		[]byte("\x00\x01\x00\x03foo\x00\x04\x00\x00"),
-		map[string]int{"foo": 1},
-		unmarshalErrorf("unmarshal map: unexpected eof"),
-	},
 }

 func decimalize(s string) *inf.Dec {
@@ -593,13 +174,9 @@ func equalStringPointerSlice(leftList, rightList []*string) bool {
 func TestMarshalList(t *testing.T) {
 	t.Parallel()

-	typeInfoV2 := CollectionType{
-		NativeType: NativeType{proto: 2, typ: TypeList},
-		Elem:       NativeType{proto: 2, typ: TypeVarchar},
-	}
 	typeInfoV3 := CollectionType{
-		NativeType: NativeType{proto: 3, typ: TypeList},
-		Elem:       NativeType{proto: 3, typ: TypeVarchar},
+		NativeType: NativeType{proto: protoVersion3, typ: TypeList},
+		Elem:       NativeType{proto: protoVersion3, typ: TypeVarchar},
 	}

 	type tc struct {
@@ -612,37 +189,6 @@ func TestMarshalList(t *testing.T) {
 	valueB := "valueB"
 	valueEmpty := ""
 	testCases := []tc{
-		{
-			typeInfo: typeInfoV2,
-			input:    []*string{&valueA},
-			expected: []*string{&valueA},
-		},
-		{
-			typeInfo: typeInfoV2,
-			input:    []*string{&valueA, &valueB},
-			expected: []*string{&valueA, &valueB},
-		},
-		{
-			typeInfo: typeInfoV2,
-			input:    []*string{&valueA, &valueEmpty, &valueB},
-			expected: []*string{&valueA, &valueEmpty, &valueB},
-		},
-		{
-			typeInfo: typeInfoV2,
-			input:    []*string{&valueEmpty},
-			expected: []*string{&valueEmpty},
-		},
-		{
-			// nil values are marshalled to empty values for protocol < 3
-			typeInfo: typeInfoV2,
-			input:    []*string{nil},
-			expected: []*string{&valueEmpty},
-		},
-		{
-			typeInfo: typeInfoV2,
-			input:    []*string{&valueA, nil, &valueB},
-			expected: []*string{&valueA, &valueEmpty, &valueB},
-		},
 		{
 			typeInfo: typeInfoV3,
 			input:    []*string{&valueEmpty},
@@ -756,30 +302,14 @@ func (m *MyPointerMarshaler) MarshalCQL(_ TypeInfo) ([]byte, error) {
 	return []byte{42}, nil
 }

-func TestMarshalPointer(t *testing.T) {
-	t.Parallel()
-
-	m := &MyPointerMarshaler{}
-	typ := NativeType{proto: 2, typ: TypeInt}
-
-	data, err := Marshal(typ, m)
-
-	if err != nil {
-		t.Errorf("Pointer marshaling failed. Error: %s", err)
-	}
-	if len(data) != 1 || data[0] != 42 {
-		t.Errorf("Pointer marshaling failed. Expected %+v, got %+v", []byte{42}, data)
-	}
-}
-
 func TestMarshalTuple(t *testing.T) {
 	t.Parallel()

 	info := TupleTypeInfo{
-		NativeType: NativeType{proto: 3, typ: TypeTuple},
+		NativeType: NativeType{proto: protoVersion3, typ: TypeTuple},
 		Elems: []TypeInfo{
-			NativeType{proto: 3, typ: TypeVarchar},
-			NativeType{proto: 3, typ: TypeVarchar},
+			NativeType{proto: protoVersion3, typ: TypeVarchar},
+			NativeType{proto: protoVersion3, typ: TypeVarchar},
 		},
 	}

@@ -925,10 +455,10 @@ func TestUnmarshalTuple(t *testing.T) {
 	t.Parallel()

 	info := TupleTypeInfo{
-		NativeType: NativeType{proto: 3, typ: TypeTuple},
+		NativeType: NativeType{proto: protoVersion3, typ: TypeTuple},
 		Elems: []TypeInfo{
-			NativeType{proto: 3, typ: TypeVarchar},
-			NativeType{proto: 3, typ: TypeVarchar},
+			NativeType{proto: protoVersion3, typ: TypeVarchar},
+			NativeType{proto: protoVersion3, typ: TypeVarchar},
 		},
 	}

@@ -1001,10 +531,10 @@ func TestUnmarshalTuple(t *testing.T) {
 func TestMarshalUDTMap(t *testing.T) {
 	t.Parallel()

-	typeInfo := UDTTypeInfo{NativeType{proto: 3, typ: TypeUDT}, "", "xyz", []UDTField{
-		{Name: "x", Type: NativeType{proto: 3, typ: TypeInt}},
-		{Name: "y", Type: NativeType{proto: 3, typ: TypeInt}},
-		{Name: "z", Type: NativeType{proto: 3, typ: TypeInt}},
+	typeInfo := UDTTypeInfo{NativeType{proto: protoVersion3, typ: TypeUDT}, "", "xyz", []UDTField{
+		{Name: "x", Type: NativeType{proto: protoVersion3, typ: TypeInt}},
+		{Name: "y", Type: NativeType{proto: protoVersion3, typ: TypeInt}},
+		{Name: "z", Type: NativeType{proto: protoVersion3, typ: TypeInt}},
 	}}

 	t.Run("partially bound", func(t *testing.T) {
@@ -1058,10 +588,10 @@ func TestMarshalUDTMap(t *testing.T) {
 func TestMarshalUDTStruct(t *testing.T) {
 	t.Parallel()

-	typeInfo := UDTTypeInfo{NativeType{proto: 3, typ: TypeUDT}, "", "xyz", []UDTField{
-		{Name: "x", Type: NativeType{proto: 3, typ: TypeInt}},
-		{Name: "y", Type: NativeType{proto: 3, typ: TypeInt}},
-		{Name: "z", Type: NativeType{proto: 3, typ: TypeInt}},
+	typeInfo := UDTTypeInfo{NativeType{proto: protoVersion3, typ: TypeUDT}, "", "xyz", []UDTField{
+		{Name: "x", Type: NativeType{proto: protoVersion3, typ: TypeInt}},
+		{Name: "y", Type: NativeType{proto: protoVersion3, typ: TypeInt}},
+		{Name: "z", Type: NativeType{proto: protoVersion3, typ: TypeInt}},
 	}}

 	type xyzStruct struct {
@@ -1148,7 +678,7 @@ func TestMarshalNil(t *testing.T) {
 	}

 	for _, typ := range types {
-		data, err := Marshal(NativeType{proto: 3, typ: typ}, nil)
+		data, err := Marshal(NativeType{proto: protoVersion3, typ: typ}, nil)
 		if err != nil {
 			t.Errorf("unable to marshal nil %v: %v\n", typ, err)
 		} else if data != nil {
@@ -1189,13 +719,9 @@ func BenchmarkUnmarshalVarchar(b *testing.B) {
 func TestReadCollectionSize(t *testing.T) {
 	t.Parallel()

-	listV2 := CollectionType{
-		NativeType: NativeType{proto: 2, typ: TypeList},
-		Elem:       NativeType{proto: 2, typ: TypeVarchar},
-	}
 	listV3 := CollectionType{
-		NativeType: NativeType{proto: 3, typ: TypeList},
-		Elem:       NativeType{proto: 3, typ: TypeVarchar},
+		NativeType: NativeType{proto: protoVersion3, typ: TypeList},
+		Elem:       NativeType{proto: protoVersion3, typ: TypeVarchar},
 	}

 	tests := []struct {
@@ -1205,24 +731,6 @@ func TestReadCollectionSize(t *testing.T) {
 		isError      bool
 		expectedSize int
 	}{
-		{
-			name:    "short read 0 proto 2",
-			info:    listV2,
-			data:    []byte{},
-			isError: true,
-		},
-		{
-			name:    "short read 1 proto 2",
-			info:    listV2,
-			data:    []byte{0x01},
-			isError: true,
-		},
-		{
-			name:         "good read proto 2",
-			info:         listV2,
-			data:         []byte{0x01, 0x38},
-			expectedSize: 0x0138,
-		},
 		{
 			name:    "short read 0 proto 3",
 			info:    listV3,
@@ -1290,17 +798,17 @@ func TestUnmarshalUDT(t *testing.T) {
 	t.Parallel()

 	info := UDTTypeInfo{
-		NativeType: NativeType{proto: 4, typ: TypeUDT},
+		NativeType: NativeType{proto: protoVersion4, typ: TypeUDT},
 		Name:       "myudt",
 		KeySpace:   "myks",
 		Elements: []UDTField{
 			{
 				Name: "first",
-				Type: NativeType{proto: 4, typ: TypeAscii},
+				Type: NativeType{proto: protoVersion4, typ: TypeAscii},
 			},
 			{
 				Name: "second",
-				Type: NativeType{proto: 4, typ: TypeSmallInt},
+				Type: NativeType{proto: protoVersion4, typ: TypeSmallInt},
 			},
 		},
 	}
diff --git a/metadata_scylla.go b/metadata_scylla.go
index dec4c23..5769eeb 100644
--- a/metadata_scylla.go
+++ b/metadata_scylla.go
@@ -11,6 +11,8 @@ import (
 	"strings"
 	"sync"
 	"sync/atomic"
+
+	"github.com/gocql/gocql/tablets"
 )

 // schema metadata for a keyspace
@@ -177,11 +179,15 @@ type TypeMetadata struct {
 }

 type IndexMetadata struct {
-	Name         string
-	KeyspaceName string
-	TableName    string
-	Kind         string
-	Options      map[string]string
+	Name              string
+	KeyspaceName      string
+	TableName         string // Name of corresponding view.
+	Kind              string
+	Options           map[string]string
+	Columns           map[string]*ColumnMetadata
+	OrderedColumns    []string
+	PartitionKey      []*ColumnMetadata
+	ClusteringColumns []*ColumnMetadata
 }

 func (t *TableMetadata) Equals(other *TableMetadata) bool {
@@ -434,7 +440,7 @@ func columnKindFromSchema(kind string) (ColumnKind, error) {
 }

 type Metadata struct {
-	tabletsMetadata  cowTabletList
+	tabletsMetadata  tablets.CowTabletList
 	keyspaceMetadata cowKeyspaceMetadataMap
 }

@@ -450,8 +456,10 @@ type metadataDescriber struct {
 // keyspace metadata and tablets metadata
 func newMetadataDescriber(session *Session) *metadataDescriber {
 	return &metadataDescriber{
-		session:  session,
-		metadata: &Metadata{},
+		session: session,
+		metadata: &Metadata{
+			tabletsMetadata: tablets.NewCowTabletList(),
+		},
 	}
 }

@@ -475,72 +483,30 @@ func (s *metadataDescriber) getSchema(keyspaceName string) (*KeyspaceMetadata, e
 	return metadata, nil
 }

-func (s *metadataDescriber) setTablets(tablets TabletInfoList) {
-	s.metadata.tabletsMetadata.set(tablets)
+func (s *metadataDescriber) getTablets() tablets.TabletInfoList {
+	return s.metadata.tabletsMetadata.Get()
 }

-func (s *metadataDescriber) getTablets() TabletInfoList {
-	return s.metadata.tabletsMetadata.get()
-}
-
-func (s *metadataDescriber) AddTablet(tablet *TabletInfo) {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-	s.addTablet(tablet)
-}
-
-func (s *metadataDescriber) addTablet(tablet *TabletInfo) {
-	tablets := s.getTablets()
-	tablets = tablets.addTabletToTabletsList(tablet)
-	s.setTablets(tablets)
+func (s *metadataDescriber) AddTablet(tablet *tablets.TabletInfo) {
+	s.metadata.tabletsMetadata.AddTablet(tablet)
 }

 // RemoveTabletsWithHost removes tablets that contains given host.
 // to be used outside the metadataDescriber
 func (s *metadataDescriber) RemoveTabletsWithHost(host *HostInfo) {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-	s.removeTabletsWithHost(host)
-}
-
-// removeTabletsWithHost removes tablets that contains given host.
-// s.mu should be locked
-func (s *metadataDescriber) removeTabletsWithHost(host *HostInfo) {
-	tablets := s.getTablets()
-	tablets = tablets.removeTabletsWithHostFromTabletsList(host)
-	s.setTablets(tablets)
+	s.metadata.tabletsMetadata.RemoveTabletsWithHost(host.HostID())
 }

 // RemoveTabletsWithKeyspace removes tablets for given keyspace.
 // to be used outside the metadataDescriber
 func (s *metadataDescriber) RemoveTabletsWithKeyspace(keyspace string) {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-	s.removeTabletsWithKeyspace(keyspace)
-}
-
-// removeTabletsWithKeyspace removes tablets for given keyspace.
-// s.mu should be locked
-func (s *metadataDescriber) removeTabletsWithKeyspace(keyspace string) {
-	tablets := s.getTablets()
-	tablets = tablets.removeTabletsWithKeyspaceFromTabletsList(keyspace)
-	s.setTablets(tablets)
+	s.metadata.tabletsMetadata.RemoveTabletsWithKeyspace(keyspace)
 }

 // RemoveTabletsWithTable removes tablets for given table.
 // to be used outside the metadataDescriber
 func (s *metadataDescriber) RemoveTabletsWithTable(keyspace string, table string) {
-	s.mu.Lock()
-	defer s.mu.Unlock()
-	s.removeTabletsWithTable(keyspace, table)
-}
-
-// removeTabletsWithTable removes tablets for given table.
-// s.mu should be locked
-func (s *metadataDescriber) removeTabletsWithTable(keyspace string, table string) {
-	tablets := s.getTablets()
-	tablets = tablets.removeTabletsWithTableFromTabletsList(keyspace, table)
-	s.setTablets(tablets)
+	s.metadata.tabletsMetadata.RemoveTabletsWithTableFromTabletsList(keyspace, table)
 }

 // clearSchema clears the cached keyspace metadata
@@ -579,7 +545,7 @@ func (s *metadataDescriber) refreshAllSchema() error {
 		err := s.refreshSchema(keyspaceName)
 		if errors.Is(err, ErrKeyspaceDoesNotExist) {
 			s.clearSchema(keyspaceName)
-			s.removeTabletsWithKeyspace(keyspaceName)
+			s.RemoveTabletsWithKeyspace(keyspaceName)
 			continue
 		} else if err != nil {
 			return err
@@ -591,13 +557,13 @@ func (s *metadataDescriber) refreshAllSchema() error {
 		}

 		if !compareInterfaceMaps(metadata.StrategyOptions, updatedMetadata.StrategyOptions) {
-			s.removeTabletsWithKeyspace(keyspaceName)
+			s.RemoveTabletsWithKeyspace(keyspaceName)
 			continue
 		}

 		for tableName, tableMetadata := range metadata.Tables {
 			if updatedTableMetadata, ok := updatedMetadata.Tables[tableName]; !ok || tableMetadata.Equals(updatedTableMetadata) {
-				s.removeTabletsWithTable(keyspaceName, tableName)
+				s.RemoveTabletsWithTable(keyspaceName, tableName)
 			}
 		}
 	}
@@ -695,7 +661,9 @@ func compileMetadata(
 	}
 	keyspace.Indexes = make(map[string]*IndexMetadata, len(indexes))
 	for i := range indexes {
+		indexes[i].Columns = make(map[string]*ColumnMetadata)
 		keyspace.Indexes[indexes[i].Name] = &indexes[i]
+
 	}
 	keyspace.Views = make(map[string]*ViewMetadata, len(views))
 	for i := range views {
@@ -718,6 +686,17 @@ func compileMetadata(

 		table, ok := keyspace.Tables[col.Table]
 		if !ok {
+			// If column owned by a table that the table name ends with `_index`
+			// suffix then the table is a view corresponding to some index.
+			if indexName, found := strings.CutSuffix(col.Table, "_index"); found {
+				ix, ok := keyspace.Indexes[indexName]
+				if ok {
+					ix.Columns[col.Name] = col
+					ix.OrderedColumns = append(ix.OrderedColumns, col.Name)
+					continue
+				}
+			}
+
 			view, ok := keyspace.Views[col.Table]
 			if !ok {
 				// if the schema is being updated we will race between seeing
@@ -744,6 +723,10 @@ func compileMetadata(
 		v := &views[i]
 		v.PartitionKey, v.ClusteringColumns, v.OrderedColumns = compileColumns(v.Columns, v.OrderedColumns)
 	}
+	for i := range indexes {
+		ix := &indexes[i]
+		ix.PartitionKey, ix.ClusteringColumns, ix.OrderedColumns = compileColumns(ix.Columns, ix.OrderedColumns)
+	}

 	keyspace.CreateStmts = string(createStmts)
 }
diff --git a/metadata_scylla_test.go b/metadata_scylla_test.go
index 8c6ebc9..61230a6 100644
--- a/metadata_scylla_test.go
+++ b/metadata_scylla_test.go
@@ -99,12 +99,39 @@ func TestCompileMetadata(t *testing.T) {
 			Kind:     ColumnPartitionKey,
 			Type:     "text",
 		},
-	}
-	indexes := []IndexMetadata{
 		{
-			Name: "sec_idx",
+			Keyspace:        "V2Keyspace",
+			Table:           "buckets_by_owner_index",
+			Name:            "idx_token",
+			Kind:            ColumnClusteringKey,
+			ComponentIndex:  0,
+			Type:            "bigint",
+			ClusteringOrder: "asc",
+		},
+		{
+			Keyspace:        "V2Keyspace",
+			Table:           "buckets_by_owner_index",
+			Name:            "name",
+			Kind:            ColumnClusteringKey,
+			ComponentIndex:  1,
+			Type:            "text",
+			ClusteringOrder: "asc",
+		},
+		{
+			Keyspace: "V2Keyspace",
+			Table:    "buckets_by_owner_index",
+			Name:     "owner",
+			Kind:     ColumnPartitionKey,
+			Type:     "text",
 		},
 	}
+	// Consider an index by column `owner` on the base table `buckets` with
+	// partition key `name`.
+	//
+	// CREATE INDEX buckets_by_owner ON stg_msk_a.buckets(owner);
+	indexes := []IndexMetadata{
+		{Name: "buckets_by_owner"},
+	}
 	views := []ViewMetadata{
 		{
 			KeyspaceName: "V2Keyspace",
@@ -112,7 +139,7 @@ func TestCompileMetadata(t *testing.T) {
 		},
 		{
 			KeyspaceName: "V2Keyspace",
-			ViewName:     "sec_idx_index",
+			ViewName:     "buckets_by_owner_index",
 		},
 	}
 	compileMetadata(keyspace, tables, columns, nil, nil, nil, indexes, views, nil)
@@ -230,6 +257,41 @@ func TestCompileMetadata(t *testing.T) {
 					},
 				},
 			},
+			Indexes: map[string]*IndexMetadata{
+				"buckets_by_owner": {
+					Name:      "buckets_by_owner",
+					TableName: "buckets_by_owner_index",
+					PartitionKey: []*ColumnMetadata{
+						{Name: "owner", Type: "text"},
+					},
+					ClusteringColumns: []*ColumnMetadata{
+						{Name: "idx_token", Type: "bigint"},
+						{Name: "name", Type: "text"},
+					},
+					OrderedColumns: []string{
+						"owner", "idx_token", "name",
+					},
+					Columns: map[string]*ColumnMetadata{
+						"owner": {
+							Name: "owner",
+							Type: "text",
+							Kind: ColumnPartitionKey,
+						},
+						"idx_token": {
+							Name:  "idx_token",
+							Type:  "bigint",
+							Order: ASC,
+							Kind:  ColumnClusteringKey,
+						},
+						"name": {
+							Name:  "name",
+							Type:  "text",
+							Order: ASC,
+							Kind:  ColumnClusteringKey,
+						},
+					},
+				},
+			},
 		},
 	)
 }
@@ -392,8 +454,32 @@ func assertViewsMetadata(t *testing.T, keyspaceName string, actual, expected map
 	}
 }

+func assertIndicesMetadata(t *testing.T, keyspaceName string, actual, expected map[string]*IndexMetadata) {
+	if len(expected) != len(actual) {
+		t.Errorf("Expected len(%s.Indexes) to be %v but was %v", keyspaceName, len(expected), len(actual))
+	}
+	for key := range expected {
+		viewName := key + "_index"
+		et := expected[key]
+		at, found := actual[key]
+
+		if !found {
+			t.Errorf("Expected %s.Indexes[%s] but was not found", keyspaceName, key)
+		} else {
+			if et.Name != at.Name {
+				t.Errorf("Expected %s.Indexes[%s].Name to be %v but was %v", keyspaceName, key, et.Name, at.Name)
+			}
+			assertPartitionKey(t, keyspaceName, viewName, at.PartitionKey, et.PartitionKey)
+			assertClusteringColumns(t, keyspaceName, viewName, at.ClusteringColumns, et.ClusteringColumns)
+			assertColumns(t, keyspaceName, viewName, at.Columns, et.Columns)
+			assertOrderedColumns(t, keyspaceName, viewName, at.OrderedColumns, et.OrderedColumns)
+		}
+	}
+}
+
 // Helper function for asserting that actual metadata returned was as expected
 func assertKeyspaceMetadata(t *testing.T, actual, expected *KeyspaceMetadata) {
 	assertTableMetadata(t, expected.Name, actual.Tables, expected.Tables)
 	assertViewsMetadata(t, expected.Name, actual.Views, expected.Views)
+	assertIndicesMetadata(t, expected.Name, actual.Indexes, expected.Indexes)
 }
diff --git a/policies.go b/policies.go
index bd066b6..c767ca6 100644
--- a/policies.go
+++ b/policies.go
@@ -466,6 +466,12 @@ func ShuffleReplicas() func(*tokenAwareHostPolicy) {
 	}
 }

+func DontShuffleReplicas() func(*tokenAwareHostPolicy) {
+	return func(t *tokenAwareHostPolicy) {
+		t.shuffleReplicas = false
+	}
+}
+
 // AvoidSlowReplicas enabled avoiding slow replicas
 //
 // TokenAwareHostPolicy normally does not check how busy replica is, with avoidSlowReplicas enabled it avoids replicas
@@ -493,7 +499,10 @@ func NonLocalReplicasFallback() func(policy *tokenAwareHostPolicy) {
 // selected based on the partition key, so queries are sent to the host which
 // owns the partition. Fallback is used when routing information is not available.
 func TokenAwareHostPolicy(fallback HostSelectionPolicy, opts ...func(*tokenAwareHostPolicy)) HostSelectionPolicy {
-	p := &tokenAwareHostPolicy{fallback: fallback}
+	p := &tokenAwareHostPolicy{
+		fallback:        fallback,
+		shuffleReplicas: true,
+	}
 	for _, opt := range opts {
 		opt(p)
 	}
@@ -735,20 +744,17 @@ func (t *tokenAwareHostPolicy) Pick(qry ExecutableQuery) NextHost {
 	}

 	token := partitioner.Hash(routingKey)
+	tokenCasted, isInt64Token := token.(int64Token)

 	var replicas []*HostInfo

-	if session := qry.GetSession(); session != nil && session.tabletsRoutingV1 {
-		tablets := session.metadataDescriber.getTablets()
-
-		// Search for tablets with Keyspace and Table from the Query
-		l, r := tablets.findTablets(qry.Keyspace(), qry.Table())
-		if l != -1 {
-			tablet := tablets.findTabletForToken(token, l, r)
+	if session := qry.GetSession(); session != nil && session.tabletsRoutingV1 && isInt64Token {
+		tabletReplicas := session.findTabletReplicasForToken(qry.Keyspace(), qry.Table(), int64(tokenCasted))
+		if len(tabletReplicas) != 0 {
 			hosts := t.hosts.get()
-			for _, replica := range tablet.Replicas() {
+			for _, replica := range tabletReplicas {
 				for _, host := range hosts {
-					if host.hostId == replica.hostId.String() {
+					if host.hostId == replica.HostID() {
 						replicas = append(replicas, host)
 						break
 					}
@@ -760,7 +766,11 @@ func (t *tokenAwareHostPolicy) Pick(qry ExecutableQuery) NextHost {
 	if len(replicas) == 0 {
 		ht := meta.replicas[qry.Keyspace()].replicasFor(token)
 		if ht != nil {
-			replicas = ht.hosts
+			// Clone ht.hosts, otherwise, if shuffling or avoidSlowReplicas is enabled, it will update ht.hosts
+			replicas = make([]*HostInfo, len(ht.hosts))
+			for id, replica := range ht.hosts {
+				replicas[id] = replica
+			}
 		}
 	}

diff --git a/policies_integration_test.go b/policies_integration_test.go
index 99d82f9..c352b9b 100644
--- a/policies_integration_test.go
+++ b/policies_integration_test.go
@@ -127,7 +127,8 @@ func TestNoHangAllHostsDown(t *testing.T) {
 			}
 		}

-		ctx, _ := context.WithTimeout(context.Background(), 12*time.Second)
+		ctx, cancel := context.WithTimeout(context.Background(), 12*time.Second)
+		defer cancel()
 		_ = session.Query("SELECT host_id FROM system.local").WithContext(ctx).Exec()
 		if ctx.Err() != nil {
 			t.Errorf("policy %T should be no hangups when all hosts are down", policy)
@@ -142,7 +143,8 @@ func TestNoHangAllHostsDown(t *testing.T) {
 			}
 		}

-		ctx, _ = context.WithTimeout(context.Background(), 12*time.Second)
+		ctx, cancel2 := context.WithTimeout(context.Background(), 12*time.Second)
+		defer cancel2()
 		_ = session.Query("SELECT host_id FROM system.local").WithContext(ctx).Exec()
 		if ctx.Err() != nil {
 			t.Errorf("policy %T should be no hangups when all hosts are down", policy)
diff --git a/policies_test.go b/policies_test.go
index 2b860b7..4c97e64 100644
--- a/policies_test.go
+++ b/policies_test.go
@@ -34,6 +34,7 @@ package gocql
 import (
 	"errors"
 	"fmt"
+	"github.com/gocql/gocql/internal/tests"
 	"net"
 	"sort"
 	"strings"
@@ -155,7 +156,7 @@ func TestHostPolicy_TokenAware_SimpleStrategy(t *testing.T) {

 	// The SimpleStrategy above should generate the following replicas.
 	// It's handy to have as reference here.
-	assertDeepEqual(t, "replicas", map[string]tokenRingReplicas{
+	tests.AssertDeepEqual(t, "replicas", map[string]tokenRingReplicas{
 		"myKeyspace": {
 			{orderedToken("00"), []*HostInfo{hosts[0], hosts[1]}},
 			{orderedToken("25"), []*HostInfo{hosts[1], hosts[2]}},
@@ -167,9 +168,8 @@ func TestHostPolicy_TokenAware_SimpleStrategy(t *testing.T) {
 	// now the token ring is configured
 	query.RoutingKey([]byte("20"))
 	iter = policy.Pick(query)
-	// first token-aware hosts
-	expectHosts(t, "hosts[0]", iter, "1")
-	expectHosts(t, "hosts[1]", iter, "2")
+	// shuffling is enabled by default, expecfing
+	expectHosts(t, "hosts[0]", iter, "1", "2")
 	// then rest of the hosts
 	expectHosts(t, "rest", iter, "0", "3")
 	expectNoMoreHosts(t, iter)
@@ -430,7 +430,7 @@ func TestLWTSimpleRetryPolicy(t *testing.T) {
 	// Verify that SimpleRetryPolicy implements both interfaces
 	var _ RetryPolicy = ebrp
 	var lwt_rt LWTRetryPolicy = ebrp
-	assertEqual(t, "retry type of LWT policy", lwt_rt.GetRetryTypeLWT(nil), Retry)
+	tests.AssertEqual(t, "retry type of LWT policy", lwt_rt.GetRetryTypeLWT(nil), Retry)
 }

 func TestExponentialBackoffPolicy(t *testing.T) {
@@ -470,7 +470,7 @@ func TestLWTExponentialBackoffPolicy(t *testing.T) {
 	// Verify that ExponentialBackoffRetryPolicy implements both interfaces
 	var _ RetryPolicy = ebrp
 	var lwt_rt LWTRetryPolicy = ebrp
-	assertEqual(t, "retry type of LWT policy", lwt_rt.GetRetryTypeLWT(nil), Retry)
+	tests.AssertEqual(t, "retry type of LWT policy", lwt_rt.GetRetryTypeLWT(nil), Retry)
 }

 func TestDowngradingConsistencyRetryPolicy(t *testing.T) {
@@ -746,7 +746,7 @@ func TestHostPolicy_TokenAware(t *testing.T) {

 	// The NetworkTopologyStrategy above should generate the following replicas.
 	// It's handy to have as reference here.
-	assertDeepEqual(t, "replicas", map[string]tokenRingReplicas{
+	tests.AssertDeepEqual(t, "replicas", map[string]tokenRingReplicas{
 		"myKeyspace": {
 			{orderedToken("05"), []*HostInfo{hosts[0], hosts[1], hosts[2]}},
 			{orderedToken("10"), []*HostInfo{hosts[1], hosts[2], hosts[3]}},
@@ -839,7 +839,7 @@ func TestHostPolicy_TokenAware_NetworkStrategy(t *testing.T) {

 	// The NetworkTopologyStrategy above should generate the following replicas.
 	// It's handy to have as reference here.
-	assertDeepEqual(t, "replicas", map[string]tokenRingReplicas{
+	tests.AssertDeepEqual(t, "replicas", map[string]tokenRingReplicas{
 		keyspace: {
 			{orderedToken("05"), []*HostInfo{hosts[0], hosts[1], hosts[2], hosts[3], hosts[4], hosts[5]}},
 			{orderedToken("10"), []*HostInfo{hosts[1], hosts[2], hosts[3], hosts[4], hosts[5], hosts[6]}},
@@ -984,7 +984,7 @@ func TestHostPolicy_TokenAware_RackAware(t *testing.T) {

 	// The NetworkTopologyStrategy above should generate the following replicas.
 	// It's handy to have as reference here.
-	assertDeepEqual(t, "replicas", map[string]tokenRingReplicas{
+	tests.AssertDeepEqual(t, "replicas", map[string]tokenRingReplicas{
 		"myKeyspace": {
 			{orderedToken("05"), []*HostInfo{hosts[0], hosts[1], hosts[2], hosts[3]}},
 			{orderedToken("10"), []*HostInfo{hosts[1], hosts[2], hosts[3], hosts[4]}},
@@ -1160,58 +1160,3 @@ func TestTokenAwarePolicyReset(t *testing.T) {
 		t.Fatal("logger is nil")
 	}
 }
-
-func TestTokenAwarePolicyResetInSessionClose(t *testing.T) {
-	t.Parallel()
-
-	policy := TokenAwareHostPolicy(
-		RackAwareRoundRobinPolicy("local", "b"),
-		NonLocalReplicasFallback(),
-	)
-	policyInternal := policy.(*tokenAwareHostPolicy)
-
-	if policyInternal.fallback == nil {
-		t.Fatal("fallback is nil")
-	}
-	if !policyInternal.nonLocalReplicasFallback {
-		t.Fatal("nonLocalReplicasFallback is false")
-	}
-
-	// emulate session initialization
-	session := &Session{
-		logger: &defaultLogger{},
-		policy: policy,
-	}
-	policy.Init(session)
-	// check that we are realy initialize policy
-	if policyInternal.getKeyspaceMetadata == nil {
-		t.Fatal("keyspace metatadata fn is nil")
-	}
-	if policyInternal.getKeyspaceName == nil {
-		t.Fatal("keyspace name fn is nil")
-	}
-	if policyInternal.logger == nil {
-		t.Fatal("logger is nil")
-	}
-
-	// session.Close should call policy.Reset method
-	session.Close()
-
-	// check that session.Close has called policy.Reset method
-
-	if policyInternal.fallback == nil { // we don't touch fallback in Reset
-		t.Fatal("fallback is nil")
-	}
-	if !policyInternal.nonLocalReplicasFallback { // we don't touch nonLocalReplicasFallback in Reset
-		t.Fatal("nonLocalReplicasFallback is false")
-	}
-	if policyInternal.getKeyspaceMetadata != nil {
-		t.Fatal("keyspace metatadata fn is not nil")
-	}
-	if policyInternal.getKeyspaceName != nil {
-		t.Fatal("keyspace name fn is not nil")
-	}
-	if policyInternal.logger != nil {
-		t.Fatal("logger is nil")
-	}
-}
diff --git a/recreate_test.go b/recreate_test.go
index ecc3257..9d18164 100644
--- a/recreate_test.go
+++ b/recreate_test.go
@@ -6,6 +6,7 @@
 package gocql

 import (
+	"context"
 	"encoding/json"
 	"flag"
 	"fmt"
@@ -21,16 +22,18 @@ import (
 var updateGolden = flag.Bool("update-golden", false, "update golden files")

 func TestRecreateSchema(t *testing.T) {
-	session := createSessionFromCluster(createCluster(), t)
+	session := createSessionFromClusterTabletsDisabled(createCluster(), t)
 	defer session.Close()

 	getStmtFromCluster := isDescribeKeyspaceSupported(t, session)
+	tabletsAutoEnabled := isTabletsSupported() && isTabletsAutoEnabled()

 	tcs := []struct {
-		Name     string
-		Keyspace string
-		Input    string
-		Golden   string
+		Name            string
+		Keyspace        string
+		FailWithTablets bool
+		Input           string
+		Golden          string
 	}{
 		{
 			Name:     "Keyspace",
@@ -45,22 +48,25 @@ func TestRecreateSchema(t *testing.T) {
 			Golden:   "testdata/recreate/table_golden.cql",
 		},
 		{
-			Name:     "Materialized Views",
-			Keyspace: "gocqlx_mv",
-			Input:    "testdata/recreate/materialized_views.cql",
-			Golden:   "testdata/recreate/materialized_views_golden.cql",
+			Name:            "Materialized Views",
+			Keyspace:        "gocqlx_mv",
+			FailWithTablets: true,
+			Input:           "testdata/recreate/materialized_views.cql",
+			Golden:          "testdata/recreate/materialized_views_golden.cql",
 		},
 		{
-			Name:     "Index",
-			Keyspace: "gocqlx_idx",
-			Input:    "testdata/recreate/index.cql",
-			Golden:   "testdata/recreate/index_golden.cql",
+			Name:            "Index",
+			Keyspace:        "gocqlx_idx",
+			FailWithTablets: true,
+			Input:           "testdata/recreate/index.cql",
+			Golden:          "testdata/recreate/index_golden.cql",
 		},
 		{
-			Name:     "Secondary Index",
-			Keyspace: "gocqlx_sec_idx",
-			Input:    "testdata/recreate/secondary_index.cql",
-			Golden:   "testdata/recreate/secondary_index_golden.cql",
+			Name:            "Secondary Index",
+			Keyspace:        "gocqlx_sec_idx",
+			FailWithTablets: true,
+			Input:           "testdata/recreate/secondary_index.cql",
+			Golden:          "testdata/recreate/secondary_index_golden.cql",
 		},
 		{
 			Name:     "UDT",
@@ -89,12 +95,34 @@ func TestRecreateSchema(t *testing.T) {
 			queries := trimQueries(strings.Split(string(in), ";"))
 			for _, q := range queries {
 				qr := session.Query(q, nil)
-				if err := qr.Exec(); err != nil {
-					t.Fatal("invalid input query", q, err)
+				err = qr.Exec()
+				if err != nil {
+					break
 				}
 				qr.Release()
 			}

+			err = session.AwaitSchemaAgreement(context.Background())
+			if err != nil {
+				t.Fatal("failed to await for schema agreement", err)
+			}
+			err = session.metadataDescriber.refreshSchema(test.Keyspace)
+			if err != nil {
+				t.Fatal("failed to read schema for keyspace", err)
+			}
+
+			if tabletsAutoEnabled && test.FailWithTablets {
+				if err == nil {
+					t.Errorf("did not get expected error or tablets")
+				} else if strings.Contains(err.Error(), "not supported") && strings.Contains(err.Error(), "tablets") {
+					return
+				} else {
+					t.Fatal("query failed with unexpected error", err)
+				}
+			} else if err != nil {
+				t.Fatal("invalid input query", err)
+			}
+
 			km, err := session.KeyspaceMetadata(test.Keyspace)
 			if err != nil {
 				t.Fatal("dump schema", err)
@@ -154,6 +182,14 @@ func TestRecreateSchema(t *testing.T) {
 			}

 			// Check if new dump is the same as previous
+			err = session.AwaitSchemaAgreement(context.Background())
+			if err != nil {
+				t.Fatal("failed to await for schema agreement", err)
+			}
+			err = session.metadataDescriber.refreshSchema(test.Keyspace)
+			if err != nil {
+				t.Fatal("failed to read schema for keyspace", err)
+			}
 			km, err = session.KeyspaceMetadata(test.Keyspace)
 			if err != nil {
 				t.Fatal("dump schema", err)
diff --git a/ring_describer_test.go b/ring_describer_test.go
index 5827cbc..5260b41 100644
--- a/ring_describer_test.go
+++ b/ring_describer_test.go
@@ -6,6 +6,7 @@ package gocql
 import (
 	"context"
 	"fmt"
+	"github.com/gocql/gocql/internal/tests"
 	"net"
 	"testing"

@@ -69,7 +70,7 @@ func TestGetClusterPeerInfoZeroToken(t *testing.T) {
 		if err != nil {
 			t.Fatalf("unable to get peers: %v", err)
 		}
-		assertEqual(t, "peers length", 2, len(peers))
+		tests.AssertEqual(t, "peers length", 2, len(peers))
 	})

 	t.Run("NoZeroTokenNodes", func(t *testing.T) {
@@ -84,7 +85,7 @@ func TestGetClusterPeerInfoZeroToken(t *testing.T) {
 		if err != nil {
 			t.Fatalf("unable to get peers: %v", err)
 		}
-		assertEqual(t, "peers length", 3, len(peers))
+		tests.AssertEqual(t, "peers length", 3, len(peers))
 	})
 }

@@ -105,99 +106,99 @@ var systemLocalResultMetadata = resultMetadata{
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "key",
-		TypeInfo: NativeType{proto: 4, typ: TypeVarchar},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeVarchar},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "bootstrapped",
-		TypeInfo: NativeType{proto: 4, typ: TypeVarchar},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeVarchar},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "broadcast_address",
-		TypeInfo: NativeType{proto: 4, typ: TypeInet},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeInet},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "cluster_name",
-		TypeInfo: NativeType{proto: 4, typ: TypeVarchar},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeVarchar},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "cql_version",
-		TypeInfo: NativeType{proto: 4, typ: TypeVarchar},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeVarchar},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "data_center",
-		TypeInfo: NativeType{proto: 4, typ: TypeVarchar},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeVarchar},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "gossip_generation",
-		TypeInfo: NativeType{proto: 4, typ: TypeInt},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeInt},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "host_id",
-		TypeInfo: NativeType{proto: 4, typ: TypeUUID},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeUUID},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "listen_address",
-		TypeInfo: NativeType{proto: 4, typ: TypeInet},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeInet},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "native_protocol_version",
-		TypeInfo: NativeType{proto: 4, typ: TypeVarchar},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeVarchar},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "partitioner",
-		TypeInfo: NativeType{proto: 4, typ: TypeVarchar},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeVarchar},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "rack",
-		TypeInfo: NativeType{proto: 4, typ: TypeVarchar},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeVarchar},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "release_version",
-		TypeInfo: NativeType{proto: 4, typ: TypeVarchar},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeVarchar},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "rpc_address",
-		TypeInfo: NativeType{proto: 4, typ: TypeInet},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeInet},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "schema_version",
-		TypeInfo: NativeType{proto: 4, typ: TypeUUID},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeUUID},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "supported_features",
-		TypeInfo: NativeType{proto: 4, typ: TypeVarchar},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeVarchar},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "tokens",
 		TypeInfo: CollectionType{
-			NativeType: NativeType{proto: 4, typ: TypeSet},
-			Elem:       NativeType{proto: 4, typ: TypeVarchar},
+			NativeType: NativeType{proto: protoVersion4, typ: TypeSet},
+			Elem:       NativeType{proto: protoVersion4, typ: TypeVarchar},
 		},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "truncated_at",
 		TypeInfo: CollectionType{
-			NativeType: NativeType{proto: 4, typ: TypeMap},
+			NativeType: NativeType{proto: protoVersion4, typ: TypeMap},

-			Key:  NativeType{proto: 4, typ: TypeUUID},
-			Elem: NativeType{proto: 4, typ: TypeBlob},
+			Key:  NativeType{proto: protoVersion4, typ: TypeUUID},
+			Elem: NativeType{proto: protoVersion4, typ: TypeBlob},
 		},
 	}},
 }
@@ -210,54 +211,54 @@ var systemPeersResultMetadata = resultMetadata{
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "peer",
-		TypeInfo: NativeType{proto: 4, typ: TypeInet},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeInet},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "data_center",
-		TypeInfo: NativeType{proto: 4, typ: TypeVarchar},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeVarchar},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "host_id",
-		TypeInfo: NativeType{proto: 4, typ: TypeUUID},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeUUID},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "preferred_ip",
-		TypeInfo: NativeType{proto: 4, typ: TypeInet},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeInet},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "rack",
-		TypeInfo: NativeType{proto: 4, typ: TypeVarchar},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeVarchar},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "release_version",
-		TypeInfo: NativeType{proto: 4, typ: TypeVarchar},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeVarchar},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "rpc_address",
-		TypeInfo: NativeType{proto: 4, typ: TypeInet},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeInet},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "schema_version",
-		TypeInfo: NativeType{proto: 4, typ: TypeUUID},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeUUID},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "supported_features",
-		TypeInfo: NativeType{proto: 4, typ: TypeVarchar},
+		TypeInfo: NativeType{proto: protoVersion4, typ: TypeVarchar},
 	}, {
 		Keyspace: "system",
 		Table:    "local",
 		Name:     "tokens",
 		TypeInfo: CollectionType{
-			NativeType: NativeType{proto: 4, typ: TypeSet},
-			Elem:       NativeType{proto: 4, typ: TypeVarchar},
+			NativeType: NativeType{proto: protoVersion4, typ: TypeSet},
+			Elem:       NativeType{proto: protoVersion4, typ: TypeVarchar},
 		},
 	}},
 }
@@ -335,8 +336,8 @@ func TestMockGetHostsFromSystem(t *testing.T) {
 	}

 	// local host and one of the peers are zero token so only one peer should be returned with 2 tokens
-	assertEqual(t, "hosts length", 1, len(hosts))
-	assertEqual(t, "host token length", 2, len(hosts[0].tokens))
+	tests.AssertEqual(t, "hosts length", 1, len(hosts))
+	tests.AssertEqual(t, "host token length", 2, len(hosts[0].tokens))
 }

 func TestRing_AddHostIfMissing_Missing(t *testing.T) {
diff --git a/schema_queries_test.go b/schema_queries_test.go
index 634a9bf..a8f7cdc 100644
--- a/schema_queries_test.go
+++ b/schema_queries_test.go
@@ -4,6 +4,7 @@
 package gocql

 import (
+	"github.com/gocql/gocql/internal/tests"
 	"testing"
 )

@@ -20,5 +21,5 @@ func TestSchemaQueries(t *testing.T) {
 	if err != nil {
 		t.Fatal("unable to get keyspace metadata for keyspace: ", err)
 	}
-	assertTrue(t, "keyspace present in metadataDescriber", keyspaceMetadata.Name == "gocql_test")
+	tests.AssertTrue(t, "keyspace present in metadataDescriber", keyspaceMetadata.Name == "gocql_test")
 }
diff --git a/scylla.go b/scylla.go
index ca158b5..b1ba258 100644
--- a/scylla.go
+++ b/scylla.go
@@ -372,24 +372,17 @@ func (p *scyllaConnPicker) Pick(t Token, qry ExecutableQuery) *Conn {

 	idx := -1

+outer:
 	for _, conn := range p.conns {
 		if conn == nil {
 			continue
 		}

 		if qry != nil && conn.isTabletSupported() {
-			tablets := conn.session.getTablets()
-
-			// Search for tablets with Keyspace and Table from the Query
-			l, r := tablets.findTablets(qry.Keyspace(), qry.Table())
-
-			if l != -1 {
-				tablet := tablets.findTabletForToken(mmt, l, r)
-
-				for _, replica := range tablet.replicas {
-					if replica.hostId.String() == p.hostId {
-						idx = replica.shardId
-					}
+			for _, replica := range conn.session.findTabletReplicasForToken(qry.Keyspace(), qry.Table(), int64(mmt)) {
+				if replica.HostID() == p.hostId {
+					idx = replica.ShardID()
+					break outer
 				}
 			}
 		}
diff --git a/scylla_shard_aware_port_common_test.go b/scylla_shard_aware_port_common_test.go
index cc7fff7..dd3b265 100644
--- a/scylla_shard_aware_port_common_test.go
+++ b/scylla_shard_aware_port_common_test.go
@@ -17,12 +17,21 @@ type makeClusterTestFunc func() *ClusterConfig

 func testShardAwarePortNoReconnections(t *testing.T, makeCluster makeClusterTestFunc) {
 	ctx, cancel := context.WithCancel(context.Background())
+	defer cancel()
 	wg := &sync.WaitGroup{}

 	// Initialize 10 sessions in parallel.
 	// If shard-aware port is used and configured properly, we should get
 	// a connection to each shard without any retries.
 	// For each host, there should be N-1 connections to the special port.
+	var errs []error
+	var errLock sync.Mutex
+
+	pushErr := func(err error) {
+		errLock.Lock()
+		errs = append(errs, err)
+		errLock.Unlock()
+	}

 	// Run 10 sessions in parallel
 	for i := 0; i < 10; i++ {
@@ -56,7 +65,8 @@ func testShardAwarePortNoReconnections(t *testing.T, makeCluster makeClusterTest
 				t.Logf("checking host %q hostID: %q", host.hostname, host.hostId)
 				hostPool, ok := sess.pool.getPool(host)
 				if !ok {
-					t.Fatalf("host %q not found in session connection pool", host.HostID())
+					pushErr(fmt.Errorf("host %q hostID not found", host.hostname))
+					return
 				}

 				shardAwarePort := getShardAwarePort(hostPool, useTLS)
@@ -105,6 +115,9 @@ func testShardAwarePortNoReconnections(t *testing.T, makeCluster makeClusterTest
 	}

 	wg.Wait()
+	for _, err := range errs {
+		t.Error(err.Error())
+	}
 }

 func testShardAwarePortMaliciousNAT(t *testing.T, makeCluster makeClusterTestFunc) {
diff --git a/scylla_shard_aware_port_integration_test.go b/scylla_shard_aware_port_integration_test.go
index b6aa1fc..c087d7c 100644
--- a/scylla_shard_aware_port_integration_test.go
+++ b/scylla_shard_aware_port_integration_test.go
@@ -7,24 +7,32 @@ import "testing"

 func TestShardAwarePortIntegrationNoReconnections(t *testing.T) {
 	testShardAwarePortNoReconnections(t, func() *ClusterConfig {
-		return createCluster()
+		c := createCluster()
+		c.Port = 9042
+		return c
 	})
 }

 func TestShardAwarePortIntegrationMaliciousNAT(t *testing.T) {
 	testShardAwarePortMaliciousNAT(t, func() *ClusterConfig {
-		return createCluster()
+		c := createCluster()
+		c.Port = 9042
+		return c
 	})
 }

 func TestShardAwarePortIntegrationUnreachable(t *testing.T) {
 	testShardAwarePortUnreachable(t, func() *ClusterConfig {
-		return createCluster()
+		c := createCluster()
+		c.Port = 9042
+		return c
 	})
 }

 func TestShardAwarePortIntegrationUnusedIfNotEnabled(t *testing.T) {
 	testShardAwarePortUnusedIfNotEnabled(t, func() *ClusterConfig {
-		return createCluster()
+		c := createCluster()
+		c.Port = 9042
+		return c
 	})
 }
diff --git a/scylla_test.go b/scylla_test.go
index d541ecc..07baed4 100644
--- a/scylla_test.go
+++ b/scylla_test.go
@@ -25,7 +25,7 @@ func TestScyllaConnPickerPickNilToken(t *testing.T) {

 	t.Run("no conns", func(t *testing.T) {
 		s.conns = []*Conn{{
-			streams: streams.New(protoVersion4),
+			streams: streams.New(),
 		}}
 		if s.Pick(Token(nil), nil) != s.conns[0] {
 			t.Fatal("expected connection")
@@ -34,7 +34,7 @@ func TestScyllaConnPickerPickNilToken(t *testing.T) {

 	t.Run("one shard", func(t *testing.T) {
 		s.conns = []*Conn{{
-			streams: streams.New(protoVersion4),
+			streams: streams.New(),
 		}}
 		if s.Pick(Token(nil), nil) != s.conns[0] {
 			t.Fatal("expected connection")
@@ -43,7 +43,7 @@ func TestScyllaConnPickerPickNilToken(t *testing.T) {

 	t.Run("multiple shards", func(t *testing.T) {
 		s.conns = []*Conn{nil, {
-			streams: streams.New(protoVersion4),
+			streams: streams.New(),
 		}}
 		if s.Pick(Token(nil), nil) != s.conns[1] {
 			t.Fatal("expected connection")
@@ -87,7 +87,7 @@ func TestScyllaConnPickerHammerPickNilToken(t *testing.T) {
 			continue
 		}
 		s.conns[i] = &Conn{
-			streams: streams.New(protoVersion4),
+			streams: streams.New(),
 		}
 	}

@@ -130,7 +130,7 @@ func TestScyllaConnPickerRemove(t *testing.T) {

 func mockConn(shard int) *Conn {
 	return &Conn{
-		streams: streams.New(protoVersion4),
+		streams: streams.New(),
 		scyllaSupported: scyllaSupported{
 			shard:             shard,
 			nrShards:          4,
diff --git a/session.go b/session.go
index 417910c..9523438 100644
--- a/session.go
+++ b/session.go
@@ -40,6 +40,7 @@ import (

 	"github.com/gocql/gocql/debounce"
 	"github.com/gocql/gocql/internal/lru"
+	"github.com/gocql/gocql/tablets"
 )

 // Session is the interface used by users to interact with the database.
@@ -179,7 +180,7 @@ func newSessionCommon(cfg ClusterConfig) (*Session, error) {
 	})

 	if cfg.PoolConfig.HostSelectionPolicy == nil {
-		cfg.PoolConfig.HostSelectionPolicy = RoundRobinHostPolicy()
+		cfg.PoolConfig.HostSelectionPolicy = TokenAwareHostPolicy(RoundRobinHostPolicy())
 	}
 	s.pool = cfg.PoolConfig.buildPool(s)

@@ -269,21 +270,19 @@ func (s *Session) init() error {
 	if !s.cfg.disableControlConn {
 		s.control = createControlConn(s)
 		reconnectionPolicy := s.cfg.InitialReconnectionPolicy
-		var lastErr error
 		for i := 0; i < reconnectionPolicy.GetMaxRetries(); i++ {
-			lastErr = nil
 			if i != 0 {
 				time.Sleep(reconnectionPolicy.GetInterval(i))
 			}

 			if s.cfg.ProtoVersion == 0 {
-				proto, err := s.control.discoverProtocol(hosts)
+				var proto int
+				proto, err = s.control.discoverProtocol(hosts)
 				if err != nil {
 					err = fmt.Errorf("unable to discover protocol version: %v\n", err)
 					if gocqlDebug {
 						s.logger.Println(err.Error())
 					}
-					lastErr = err
 					continue
 				} else if proto == 0 {
 					return errors.New("unable to discovery protocol version")
@@ -294,17 +293,17 @@ func (s *Session) init() error {
 				s.connCfg.ProtoVersion = proto
 			}

-			if err := s.control.connect(hosts); err != nil {
+			if err = s.control.connect(hosts); err != nil {
 				err = fmt.Errorf("unable to create control connection: %v\n", err)
 				if gocqlDebug {
 					s.logger.Println(err.Error())
 				}
-				lastErr = err
 				continue
 			}
+			break
 		}
-		if lastErr != nil {
-			return fmt.Errorf("unable to connect to the cluster, last error: %v", lastErr.Error())
+		if err != nil {
+			return fmt.Errorf("unable to connect to the cluster, last error: %v", err.Error())
 		}

 		conn := s.control.getConn().conn.(*Conn)
@@ -332,11 +331,6 @@ func (s *Session) init() error {
 			}

 			hosts = filteredHosts
-
-			if s.tabletsRoutingV1 {
-				tablets := TabletInfoList{}
-				s.metadataDescriber.setTablets(tablets)
-			}
 		}

 		newer, _ := checkSystemSchema(s.control)
@@ -612,10 +606,6 @@ func (s *Session) Close() {
 		s.cancel()
 	}

-	if s.policy != nil {
-		s.policy.Reset()
-	}
-
 	s.sessionStateMu.Lock()
 	s.isClosed = true
 	s.sessionStateMu.Unlock()
@@ -692,7 +682,7 @@ func (s *Session) KeyspaceMetadata(keyspace string) (*KeyspaceMetadata, error) {
 }

 // TabletsMetadata returns the metadata about tablets
-func (s *Session) TabletsMetadata() (TabletInfoList, error) {
+func (s *Session) TabletsMetadata() (tablets.TabletInfoList, error) {
 	// fail fast
 	if s.Closed() {
 		return nil, ErrSessionClosed
@@ -723,8 +713,8 @@ func (s *Session) getConn() *Conn {
 	return nil
 }

-func (s *Session) getTablets() TabletInfoList {
-	return s.metadataDescriber.getTablets()
+func (s *Session) findTabletReplicasForToken(keyspace, table string, token int64) []tablets.ReplicaInfo {
+	return s.metadataDescriber.metadata.tabletsMetadata.FindReplicasForToken(keyspace, table, token)
 }

 // returns routing key indexes and type info
@@ -1011,11 +1001,11 @@ func (qm *queryMetrics) hostMetrics(host *HostInfo) *hostMetrics {
 // hostMetricsLocked gets or creates host metrics for given host.
 // It must be called only while holding qm.l lock.
 func (qm *queryMetrics) hostMetricsLocked(host *HostInfo) *hostMetrics {
-	metrics, exists := qm.m[host.ConnectAddress().String()]
+	metrics, exists := qm.m[host.HostID()]
 	if !exists {
 		// if the host is not in the map, it means it's been accessed for the first time
 		metrics = &hostMetrics{}
-		qm.m[host.ConnectAddress().String()] = metrics
+		qm.m[host.HostID()] = metrics
 	}

 	return metrics
diff --git a/tablet_integration_test.go b/tablet_integration_test.go
index 6a9de13..6ee5152 100644
--- a/tablet_integration_test.go
+++ b/tablet_integration_test.go
@@ -11,6 +11,9 @@ import (

 // Check if TokenAwareHostPolicy works correctly when using tablets
 func TestTablets(t *testing.T) {
+	if !isTabletsSupported() {
+		t.Skip("Tablets are not supported by this server")
+	}
 	cluster := createCluster()

 	fallback := RoundRobinHostPolicy()
@@ -101,6 +104,9 @@ func TestTablets(t *testing.T) {

 // Check if shard awareness works correctly when using tablets
 func TestTabletsShardAwareness(t *testing.T) {
+	if !isTabletsSupported() {
+		t.Skip("Tablets are not supported by this server")
+	}
 	cluster := createCluster()

 	fallback := RoundRobinHostPolicy()
diff --git a/tablets.go b/tablets.go
deleted file mode 100644
index fd29cb6..0000000
--- a/tablets.go
+++ /dev/null
@@ -1,198 +0,0 @@
-package gocql
-
-import (
-	"sync"
-)
-
-type ReplicaInfo struct {
-	hostId  UUID
-	shardId int
-}
-
-type TabletInfo struct {
-	keyspaceName string
-	tableName    string
-	firstToken   int64
-	lastToken    int64
-	replicas     []ReplicaInfo
-}
-
-func (t *TabletInfo) KeyspaceName() string {
-	return t.keyspaceName
-}
-
-func (t *TabletInfo) FirstToken() int64 {
-	return t.firstToken
-}
-
-func (t *TabletInfo) LastToken() int64 {
-	return t.lastToken
-}
-
-func (t *TabletInfo) TableName() string {
-	return t.tableName
-}
-
-func (t *TabletInfo) Replicas() []ReplicaInfo {
-	return t.replicas
-}
-
-type TabletInfoList []*TabletInfo
-
-// Search for place in tablets table with specific Keyspace and Table name
-func (t TabletInfoList) findTablets(keyspace string, table string) (int, int) {
-	l := -1
-	r := -1
-	for i, tablet := range t {
-		if tablet.KeyspaceName() == keyspace && tablet.TableName() == table {
-			if l == -1 {
-				l = i
-			}
-			r = i
-		} else if l != -1 {
-			break
-		}
-	}
-
-	return l, r
-}
-
-func (t TabletInfoList) addTabletToTabletsList(tablet *TabletInfo) TabletInfoList {
-	l, r := t.findTablets(tablet.keyspaceName, tablet.tableName)
-	if l == -1 && r == -1 {
-		l = 0
-		r = 0
-	} else {
-		r = r + 1
-	}
-
-	l1, r1 := l, r
-	l2, r2 := l1, r1
-
-	// find first overlaping range
-	for l1 < r1 {
-		mid := (l1 + r1) / 2
-		if t[mid].FirstToken() < tablet.FirstToken() {
-			l1 = mid + 1
-		} else {
-			r1 = mid
-		}
-	}
-	start := l1
-
-	if start > l && t[start-1].LastToken() > tablet.FirstToken() {
-		start = start - 1
-	}
-
-	// find last overlaping range
-	for l2 < r2 {
-		mid := (l2 + r2) / 2
-		if t[mid].LastToken() < tablet.LastToken() {
-			l2 = mid + 1
-		} else {
-			r2 = mid
-		}
-	}
-	end := l2
-	if end < r && t[end].FirstToken() >= tablet.LastToken() {
-		end = end - 1
-	}
-	if end == len(t) {
-		end = end - 1
-	}
-
-	updated_tablets := t
-	if start <= end {
-		// Delete elements from index start to end
-		updated_tablets = append(t[:start], t[end+1:]...)
-	}
-	// Insert tablet element at index start
-	t = append(updated_tablets[:start], append([]*TabletInfo{tablet}, updated_tablets[start:]...)...)
-	return t
-}
-
-// Remove all tablets that have given host as a replica
-func (t TabletInfoList) removeTabletsWithHostFromTabletsList(host *HostInfo) TabletInfoList {
-	filteredTablets := make([]*TabletInfo, 0, len(t)) // Preallocate for efficiency
-
-	for _, tablet := range t {
-		// Check if any replica matches the given host ID
-		shouldExclude := false
-		for _, replica := range tablet.replicas {
-			if replica.hostId.String() == host.HostID() {
-				shouldExclude = true
-				break
-			}
-		}
-		if !shouldExclude {
-			filteredTablets = append(filteredTablets, tablet)
-		}
-	}
-
-	t = filteredTablets
-	return t
-}
-
-func (t TabletInfoList) removeTabletsWithKeyspaceFromTabletsList(keyspace string) TabletInfoList {
-	filteredTablets := make([]*TabletInfo, 0, len(t))
-
-	for _, tablet := range t {
-		if tablet.keyspaceName != keyspace {
-			filteredTablets = append(filteredTablets, tablet)
-		}
-	}
-
-	t = filteredTablets
-	return t
-}
-
-func (t TabletInfoList) removeTabletsWithTableFromTabletsList(keyspace string, table string) TabletInfoList {
-	filteredTablets := make([]*TabletInfo, 0, len(t))
-
-	for _, tablet := range t {
-		if !(tablet.keyspaceName == keyspace && tablet.tableName == table) {
-			filteredTablets = append(filteredTablets, tablet)
-		}
-	}
-
-	t = filteredTablets
-	return t
-}
-
-// Search for place in tablets table for token starting from index l to index r
-func (t TabletInfoList) findTabletForToken(token Token, l int, r int) *TabletInfo {
-	for l < r {
-		var m int
-		if r*l > 0 {
-			m = l + (r-l)/2
-		} else {
-			m = (r + l) / 2
-		}
-		if int64Token(t[m].LastToken()).Less(token) {
-			l = m + 1
-		} else {
-			r = m
-		}
-	}
-
-	return t[l]
-}
-
-// cowTabletList implements a copy on write tablet list, its equivalent type is TabletInfoList
-type cowTabletList struct {
-	list TabletInfoList
-	mu   sync.RWMutex
-}
-
-func (c *cowTabletList) get() TabletInfoList {
-	c.mu.RLock()
-	defer c.mu.RUnlock()
-	return c.list
-}
-
-func (c *cowTabletList) set(tablets TabletInfoList) {
-	c.mu.Lock()
-	defer c.mu.Unlock()
-
-	c.list = tablets
-}
diff --git a/tablets/tabets_utils_test.go b/tablets/tabets_utils_test.go
new file mode 100644
index 0000000..8cb6359
--- /dev/null
+++ b/tablets/tabets_utils_test.go
@@ -0,0 +1,76 @@
+package tablets
+
+import (
+	"math"
+	"testing"
+
+	"github.com/gocql/gocql/internal/tests"
+)
+
+func TestCreateTablets(t *testing.T) {
+	t.Run("BasicDistribution", func(t *testing.T) {
+		hosts := tests.GenerateHostNames(3)
+		tl := createTablets("ks", "tbl", hosts, 2, 6, 6)
+		if len(tl) != 6 {
+			t.Errorf("expected 6 tablets, got %d", len(tl))
+		}
+
+		for _, tablet := range tl {
+			if len(tablet.replicas) != 2 {
+				t.Errorf("each tablet should have 2 replicas, got %d", len(tablet.replicas))
+			}
+			replicaSet := map[string]bool{}
+			for _, r := range tablet.replicas {
+				if replicaSet[r.hostId] {
+					t.Errorf("duplicate replica %s in tablet", r.hostId)
+				}
+				replicaSet[r.hostId] = true
+			}
+		}
+	})
+
+	t.Run("SingleTabletFullRange", func(t *testing.T) {
+		hosts := tests.GenerateHostNames(3)
+		tl := createTablets("ks", "tbl", hosts, 3, 1, 1)
+		t0 := tl[0]
+		if t0.firstToken != math.MinInt64 {
+			t.Errorf("unexpected firstToken: %d", t0.firstToken)
+		}
+		if t0.lastToken != math.MaxInt64 {
+			t.Errorf("unexpected lastToken: %d", t0.lastToken)
+		}
+	})
+}
+
+func TestReplicaGenerator(t *testing.T) {
+	hosts := []string{"a", "b", "c", "d"}
+	rf := 2
+	g := NewReplicaSetGenerator(hosts, rf)
+
+	var seen [][]string
+	for i := 0; i < 6; i++ {
+		gen := g.Next()
+
+		if len(gen) != rf {
+			t.Fatalf("expected %d replicas, got %d", rf, len(gen))
+		}
+
+		var ids []string
+		for _, r := range gen {
+			ids = append(ids, r.HostID())
+		}
+		seen = append(seen, ids)
+	}
+
+	for i := 0; i < len(seen); i++ {
+	outer:
+		for j := i + 1; j < len(seen); j++ {
+			for k := 0; k < len(seen[i]); k++ {
+				if seen[i][k] != seen[j][k] {
+					continue outer
+				}
+			}
+			t.Errorf("expected different output for different seeds, but found same seeds for %d and %d: %s == %s", i, j, seen[i], seen[j])
+		}
+	}
+}
diff --git a/tablets/tablet_utils.go b/tablets/tablet_utils.go
new file mode 100644
index 0000000..40ee27e
--- /dev/null
+++ b/tablets/tablet_utils.go
@@ -0,0 +1,158 @@
+package tablets
+
+import (
+	"github.com/gocql/gocql/internal/tests"
+	"math"
+	"math/rand"
+	"sync/atomic"
+)
+
+const randSeed = 100
+
+// ReplicaSetGenerator generates all possible k-combinations (replica sets) of a given list of hosts,
+// where each combination contains `rf` elements. The generator cycles through all possible combinations
+// infinitely in a thread-safe manner using an atomic counter.
+type ReplicaSetGenerator struct {
+	hosts   []string // List of available hosts
+	rf      int      // Replication factor (number of hosts per combination)
+	len     int      // Total number of hosts
+	counter uint64   // Current position in the sequence of combinations
+	total   uint64   // Total number of possible combinations (n choose rf)
+}
+
+// NewReplicaSetGenerator creates and returns a new ReplicaSetGenerator for the given set of hosts
+// and replication factor `rf`. It panics if `rf` is non-positive or greater than the number of hosts.
+// The generator produces all k-combinations of the input set and loops over them indefinitely.
+func NewReplicaSetGenerator(hosts []string, rf int) *ReplicaSetGenerator {
+	n := len(hosts)
+	if rf <= 0 {
+		panic("replication factor must be positive")
+	}
+	if rf > len(hosts) {
+		panic("replication factor cannot exceed number of hosts")
+	}
+	return &ReplicaSetGenerator{
+		hosts: hosts,
+		rf:    rf,
+		len:   n,
+		total: uint64(binomial(n, rf)),
+	}
+}
+
+// Next returns the next replica set as a slice of ReplicaInfo. The combinations are returned in a
+// deterministic order and wrap around after exhausting all possible combinations.
+// This method is safe for concurrent use.
+func (it *ReplicaSetGenerator) Next() []ReplicaInfo {
+	// Advance and wrap around
+	counter := atomic.AddUint64(&it.counter, 1) % it.total
+	// Map current counter to combination
+	return unrankCombination(it.len, it.rf, int(counter), it.hosts)
+}
+
+// binomial calculates the number of unique combinations (n choose k)
+// for selecting `rf` elements from a set of `hosts` elements.
+//
+// It returns the binomial coefficient C(hosts, rf), which represents
+// the number of ways to choose `rf` items from a total of `hosts` without
+// regard to order.
+//
+// If rf < 0 or rf > hosts, the function returns 0.
+// If rf == 0 or rf == hosts, the function returns 1.
+func binomial(hosts, rf int) int {
+	if rf < 0 || rf > hosts {
+		return 0
+	}
+	if rf == 0 || rf == hosts {
+		return 1
+	}
+	num := 1
+	den := 1
+	for i := 1; i <= rf; i++ {
+		num *= hosts - (i - 1)
+		den *= i
+	}
+	return num / den
+}
+
+// unrankCombination returns the k-combination of elements from the input slice
+// corresponding to the given rank (counter) in lexicographic order.
+//
+// Parameters:
+//
+//	n       - total number of elements in the input slice (should be len(input))
+//	k       - number of elements to choose in the combination
+//	counter - the index (rank) of the desired combination in lexicographic order
+//	input   - a slice of strings to choose elements from; assumed to have n elements
+//
+// Returns:
+//
+//	A slice of ReplicaInfo structs representing the combination at the given rank.
+//	Each ReplicaInfo contains a hostId from the input and a shardId set to 0.
+//
+// Example:
+//
+//	input := []string{"a", "b", "c", "d"}
+//	result := unrankCombination(4, 2, 3, input) // returns the 4th combination (zero-based)
+func unrankCombination(n, k, counter int, input []string) []ReplicaInfo {
+	comb := make([]ReplicaInfo, 0, k)
+	x := 0
+	for i := 0; i < k; i++ {
+		for {
+			b := binomial(n-x-1, k-i-1)
+			if counter < b {
+				comb = append(comb, ReplicaInfo{
+					hostId:  input[x],
+					shardId: 0,
+				})
+				x++
+				break
+			} else {
+				counter -= b
+				x++
+			}
+		}
+	}
+	return comb
+}
+
+func getThreadSafeRnd() *tests.ThreadSafeRand {
+	return tests.NewThreadSafeRand(randSeed)
+}
+
+func getRnd() *rand.Rand {
+	return rand.New(rand.NewSource(randSeed))
+}
+
+// createTablets generates a list of TabletInfo entries for a given keyspace and table.
+// Each tablet is assigned a token range and a set of replica hosts.
+//
+// Parameters:
+//
+//	ks              - the keyspace name.
+//	table           - the table name.
+//	hosts           - a list of available host identifiers.
+//	rf              - replication factor, number of replicas per tablet.
+//	count           - total number of tablets to create.
+//	tokenRangeCount - total number of distinct token ranges to divide the ring into.
+//
+// Returns:
+//
+//	A TabletInfoList containing 'count' tablets, each with its own token range
+//	and a replica set selected using a round-robin combination generator.
+func createTablets(ks, table string, hosts []string, rf, count int, tokenRangeCount int64) TabletInfoList {
+	out := make([]*TabletInfo, count)
+	step := math.MaxUint64 / uint64(tokenRangeCount)
+	repGen := NewReplicaSetGenerator(hosts, rf)
+	firstToken := int64(math.MinInt64)
+	for i := 0; i < count; i++ {
+		out[i] = &TabletInfo{
+			keyspaceName: ks,
+			tableName:    table,
+			firstToken:   firstToken,
+			lastToken:    firstToken + int64(step),
+			replicas:     repGen.Next(),
+		}
+		firstToken = firstToken + int64(step)
+	}
+	return out
+}
diff --git a/tablets/tablets.go b/tablets/tablets.go
new file mode 100644
index 0000000..d33c040
--- /dev/null
+++ b/tablets/tablets.go
@@ -0,0 +1,468 @@
+package tablets
+
+import (
+	"fmt"
+	"sync"
+	"sync/atomic"
+)
+
+type ReplicaInfo struct {
+	// hostId for sake of better performance, it has to be same type as HostInfo.hostId
+	hostId  string
+	shardId int
+}
+
+func (r ReplicaInfo) HostID() string {
+	return r.hostId
+}
+
+func (r ReplicaInfo) ShardID() int {
+	return r.shardId
+}
+
+type TabletInfoBuilder struct {
+	KeyspaceName string
+	TableName    string
+	FirstToken   int64
+	LastToken    int64
+	Replicas     [][]interface{}
+}
+
+func NewTabletInfoBuilder() TabletInfoBuilder {
+	return TabletInfoBuilder{}
+}
+
+type toString interface {
+	String() string
+}
+
+func (b TabletInfoBuilder) Build() (*TabletInfo, error) {
+	tabletReplicas := make([]ReplicaInfo, 0, len(b.Replicas))
+	for _, replica := range b.Replicas {
+		if len(replica) != 2 {
+			return nil, fmt.Errorf("replica info should have exactly two elements, but it has %d: %v", len(replica), replica)
+		}
+		if hostId, ok := replica[0].(toString); ok {
+			if shardId, ok := replica[1].(int); ok {
+				repInfo := ReplicaInfo{hostId.String(), shardId}
+				tabletReplicas = append(tabletReplicas, repInfo)
+			} else {
+				return nil, fmt.Errorf("second element (shard) of replica is not int: %v", replica)
+			}
+		} else {
+			return nil, fmt.Errorf("first element (hostID) of replica is not UUID: %v", replica)
+		}
+	}
+
+	return &TabletInfo{
+		keyspaceName: b.KeyspaceName,
+		tableName:    b.TableName,
+		firstToken:   b.FirstToken,
+		lastToken:    b.LastToken,
+		replicas:     tabletReplicas,
+	}, nil
+}
+
+type TabletInfo struct {
+	keyspaceName string
+	tableName    string
+	firstToken   int64
+	lastToken    int64
+	replicas     []ReplicaInfo
+}
+
+func (t *TabletInfo) KeyspaceName() string {
+	return t.keyspaceName
+}
+
+func (t *TabletInfo) FirstToken() int64 {
+	return t.firstToken
+}
+
+func (t *TabletInfo) LastToken() int64 {
+	return t.lastToken
+}
+
+func (t *TabletInfo) TableName() string {
+	return t.tableName
+}
+
+func (t *TabletInfo) Replicas() []ReplicaInfo {
+	return t.replicas
+}
+
+type TabletInfoList []*TabletInfo
+
+// FindTablets returns the range [l, r] of indices within the TabletInfoList
+// that correspond to consecutive tablets matching the given keyspace and table.
+//
+// If no matching tablets are found, both l and r are set to -1.
+// The search stops at the first non-matching tablet after finding the first match.
+//
+// Parameters:
+//
+//	keyspace - the name of the keyspace to match.
+//	table    - the name of the table to match.
+//
+// Returns:
+//
+//	l - the index of the first matching tablet.
+//	r - the index of the last matching tablet in the contiguous block.
+func (t TabletInfoList) FindTablets(keyspace string, table string) (int, int) {
+	l := -1
+	r := -1
+	for i, tablet := range t {
+		if tablet.KeyspaceName() == keyspace && tablet.TableName() == table {
+			if l == -1 {
+				l = i
+			}
+			r = i
+		} else if l != -1 {
+			break
+		}
+	}
+
+	return l, r
+}
+
+// AddTabletToTabletsList inserts a new tablet into the TabletInfoList while preserving sorted order
+// and removing any existing overlapping tablets for the same keyspace and table.
+//
+// It first locates the range of tablets corresponding to the same keyspace and table,
+// then determines the overlapping region (if any) based on token ranges.
+// Any overlapping tablets in that range are removed, and the new tablet is inserted
+// at the appropriate position.
+//
+// Parameters:
+//
+//	tablet - pointer to the TabletInfo to be added.
+//
+// Returns:
+//
+//	A new TabletInfoList with the given tablet inserted and any overlapping tablets removed.
+func (t TabletInfoList) AddTabletToTabletsList(tablet *TabletInfo) TabletInfoList {
+	l, r := t.FindTablets(tablet.keyspaceName, tablet.tableName)
+	if l == -1 && r == -1 {
+		l = 0
+		r = 0
+	} else {
+		r = r + 1
+	}
+
+	l1, r1 := l, r
+	l2, r2 := l1, r1
+
+	// find first overlaping range
+	for l1 < r1 {
+		mid := (l1 + r1) / 2
+		if t[mid].FirstToken() < tablet.FirstToken() {
+			l1 = mid + 1
+		} else {
+			r1 = mid
+		}
+	}
+	start := l1
+
+	if start > l && t[start-1].LastToken() > tablet.FirstToken() {
+		start = start - 1
+	}
+
+	// find last overlaping range
+	for l2 < r2 {
+		mid := (l2 + r2) / 2
+		if t[mid].LastToken() < tablet.LastToken() {
+			l2 = mid + 1
+		} else {
+			r2 = mid
+		}
+	}
+	end := l2
+	if end < r && t[end].FirstToken() >= tablet.LastToken() {
+		end = end - 1
+	}
+	if end == len(t) {
+		end = end - 1
+	}
+
+	updated_tablets := t
+	if start <= end {
+		// Delete elements from index start to end
+		updated_tablets = append(t[:start], t[end+1:]...)
+	}
+	// Insert tablet element at index start
+	t = append(updated_tablets[:start], append([]*TabletInfo{tablet}, updated_tablets[start:]...)...)
+	return t
+}
+
+// BulkAddTabletsToTabletsList inserts a sorted list of tablets into the TabletInfoList,
+// replacing any overlapping tablets for the same keyspace and table.
+//
+// The method assumes the input tablets are sorted by token range. It locates the existing
+// tablet range matching the keyspace and table, finds and removes any tablets whose token
+// ranges overlap with the new ones, and inserts the new tablets at the appropriate position.
+//
+// Parameters:
+//
+//	tablets - a slice of *TabletInfo to insert.
+//
+// Returns:
+//
+//	A new TabletInfoList with the given tablets inserted and any overlapping tablets removed.
+func (t TabletInfoList) BulkAddTabletsToTabletsList(tablets []*TabletInfo) TabletInfoList {
+	firstToken := tablets[0].FirstToken()
+	lastToken := tablets[len(tablets)-1].LastToken()
+	l, r := t.FindTablets(tablets[0].keyspaceName, tablets[0].tableName)
+	if l == -1 && r == -1 {
+		l = 0
+		r = 0
+	} else {
+		r = r + 1
+	}
+
+	l1, r1 := l, r
+	l2, r2 := l1, r1
+
+	// find first overlaping range
+	for l1 < r1 {
+		mid := (l1 + r1) / 2
+		if t[mid].FirstToken() < firstToken {
+			l1 = mid + 1
+		} else {
+			r1 = mid
+		}
+	}
+	start := l1
+
+	if start > l && t[start-1].LastToken() > firstToken {
+		start = start - 1
+	}
+
+	// find last overlaping range
+	for l2 < r2 {
+		mid := (l2 + r2) / 2
+		if t[mid].LastToken() < lastToken {
+			l2 = mid + 1
+		} else {
+			r2 = mid
+		}
+	}
+	end := l2
+	if end < r && t[end].FirstToken() >= lastToken {
+		end = end - 1
+	}
+	if end == len(t) {
+		end = end - 1
+	}
+
+	updated_tablets := t
+	if start <= end {
+		// Delete elements from index start to end
+		updated_tablets = append(t[:start], t[end+1:]...)
+	}
+	// Insert tablet element at index start
+	t = append(updated_tablets[:start], append(append([]*TabletInfo(nil), tablets...), updated_tablets[start:]...)...)
+	return t
+}
+
+// RemoveTabletsWithHost returns a new TabletInfoList excluding any tablets
+// that have a replica hosted on the specified host ID.
+//
+// It iterates through the list and filters out tablets where any replica's hostId
+// matches the provided value.
+//
+// Parameters:
+//
+//	hostID - the ID of the host to filter out.
+//
+// Returns:
+//
+//	A new TabletInfoList excluding tablets with replicas on the specified host.
+func (t TabletInfoList) RemoveTabletsWithHost(hostID string) TabletInfoList {
+	filteredTablets := make([]*TabletInfo, 0, len(t)) // Preallocate for efficiency
+
+	for _, tablet := range t {
+		// Check if any replica matches the given host ID
+		shouldExclude := false
+		for _, replica := range tablet.replicas {
+			if replica.hostId == hostID {
+				shouldExclude = true
+				break
+			}
+		}
+		if !shouldExclude {
+			filteredTablets = append(filteredTablets, tablet)
+		}
+	}
+
+	t = filteredTablets
+	return t
+}
+
+// RemoveTabletsWithKeyspace returns a new TabletInfoList excluding all tablets
+// that belong to the specified keyspace.
+//
+// It filters out any tablet whose keyspace name matches the given keyspace.
+//
+// Parameters:
+//
+//	keyspace - the name of the keyspace to remove.
+//
+// Returns:
+//
+//	A new TabletInfoList without tablets from the specified keyspace.
+func (t TabletInfoList) RemoveTabletsWithKeyspace(keyspace string) TabletInfoList {
+	filteredTablets := make([]*TabletInfo, 0, len(t))
+
+	for _, tablet := range t {
+		if tablet.keyspaceName != keyspace {
+			filteredTablets = append(filteredTablets, tablet)
+		}
+	}
+
+	t = filteredTablets
+	return t
+}
+
+// RemoveTabletsWithTableFromTabletsList returns a new TabletInfoList excluding all tablets
+// that belong to the specified keyspace and table.
+//
+// It filters out any tablet whose keyspace and table name both match the provided values.
+//
+// Parameters:
+//
+//	keyspace - the name of the keyspace to remove.
+//	table    - the name of the table to remove.
+//
+// Returns:
+//
+//	A new TabletInfoList without tablets from the specified keyspace and table.
+func (t TabletInfoList) RemoveTabletsWithTableFromTabletsList(keyspace string, table string) TabletInfoList {
+	filteredTablets := make([]*TabletInfo, 0, len(t))
+
+	for _, tablet := range t {
+		if !(tablet.keyspaceName == keyspace && tablet.tableName == table) {
+			filteredTablets = append(filteredTablets, tablet)
+		}
+	}
+
+	t = filteredTablets
+	return t
+}
+
+// FindTabletForToken performs a binary search within the specified range [l, r)
+// of the TabletInfoList to find the tablet that owns the given token.
+//
+// It assumes the tablets are sorted by token range and returns the first tablet
+// whose LastToken is greater than or equal to the given token.
+//
+// Parameters:
+//
+//	token - the token to search for.
+//	l     - the start index of the search range (inclusive).
+//	r     - the end index of the search range (exclusive).
+//
+// Returns:
+//
+//	A pointer to the TabletInfo that owns the token.
+func (t TabletInfoList) FindTabletForToken(token int64, l int, r int) *TabletInfo {
+	for l < r {
+		var m int
+		if r*l > 0 {
+			m = l + (r-l)/2
+		} else {
+			m = (r + l) / 2
+		}
+		if t[m].LastToken() < token {
+			l = m + 1
+		} else {
+			r = m
+		}
+	}
+
+	return t[l]
+}
+
+// CowTabletList is a copy-on-write wrapper around a TabletInfoList.
+// It allows concurrent reads without locking by storing the list atomically,
+// while ensuring writes are serialized via a mutex to avoid lost updates.
+type CowTabletList struct {
+	list      atomic.Value // Stores the current TabletInfoList
+	writeLock sync.Mutex   // Ensures exclusive access during write operations
+}
+
+// NewCowTabletList creates a new CowTabletList instance initialized with an empty TabletInfoList.
+func NewCowTabletList() CowTabletList {
+	list := atomic.Value{}
+	list.Store(make(TabletInfoList, 0))
+	return CowTabletList{
+		list: list,
+	}
+}
+
+// Get returns the current snapshot of the tablet list.
+// It is safe for concurrent use.
+func (c *CowTabletList) Get() TabletInfoList {
+	return c.list.Load().(TabletInfoList)
+}
+
+// set replaces the current tablet list with the provided one.
+// It is not safe for concurrent use and should be called only from within a locked context.
+func (c *CowTabletList) set(tablets TabletInfoList) {
+	c.list.Store(tablets)
+}
+
+// AddTablet adds a single tablet to the list in a thread-safe manner.
+func (c *CowTabletList) AddTablet(tablet *TabletInfo) {
+	c.writeLock.Lock()
+	defer c.writeLock.Unlock()
+	c.set(c.Get().AddTabletToTabletsList(tablet))
+}
+
+// BulkAddTablets adds multiple tablets to the list in a single atomic update.
+func (c *CowTabletList) BulkAddTablets(tablets []*TabletInfo) {
+	c.writeLock.Lock()
+	defer c.writeLock.Unlock()
+	c.set(c.Get().BulkAddTabletsToTabletsList(tablets))
+}
+
+// RemoveTabletsWithHost removes all tablets associated with the specified host ID.
+func (c *CowTabletList) RemoveTabletsWithHost(hostID string) {
+	c.writeLock.Lock()
+	defer c.writeLock.Unlock()
+	c.set(c.Get().RemoveTabletsWithHost(hostID))
+}
+
+// RemoveTabletsWithKeyspace removes all tablets belonging to the given keyspace.
+func (c *CowTabletList) RemoveTabletsWithKeyspace(keyspace string) {
+	c.writeLock.Lock()
+	defer c.writeLock.Unlock()
+	c.set(c.Get().RemoveTabletsWithKeyspace(keyspace))
+}
+
+// RemoveTabletsWithTableFromTabletsList removes all tablets for the specified keyspace and table.
+func (c *CowTabletList) RemoveTabletsWithTableFromTabletsList(keyspace string, table string) {
+	c.writeLock.Lock()
+	defer c.writeLock.Unlock()
+	c.set(c.Get().RemoveTabletsWithTableFromTabletsList(keyspace, table))
+}
+
+// FindReplicasForToken returns the replica set responsible for the given token,
+// within the specified keyspace and table.
+func (c *CowTabletList) FindReplicasForToken(keyspace, table string, token int64) []ReplicaInfo {
+	tl := c.FindTabletForToken(keyspace, table, token)
+	if tl == nil {
+		return nil
+	}
+	return tl.Replicas()
+}
+
+// FindTabletForToken locates the tablet that covers the given token
+// for the specified keyspace and table. Returns nil if not found.
+func (c *CowTabletList) FindTabletForToken(keyspace, table string, token int64) *TabletInfo {
+	tablets := c.Get()
+	l, r := tablets.FindTablets(keyspace, table)
+	if l == -1 {
+		return nil
+	}
+	return tablets.FindTabletForToken(token, l, r)
+}
diff --git a/tablets/tablets_bench_test.go b/tablets/tablets_bench_test.go
new file mode 100644
index 0000000..3d7d3af
--- /dev/null
+++ b/tablets/tablets_bench_test.go
@@ -0,0 +1,200 @@
+package tablets
+
+import (
+	"fmt"
+	"github.com/gocql/gocql/internal/tests"
+	"math"
+	"runtime"
+	"sync/atomic"
+	"testing"
+)
+
+const tabletsCountMedium = 1500
+
+func BenchmarkTabletInfoList(b *testing.B) {
+	hosts := tests.GenerateHostNames(3)
+	tlist := createTablets("k", "t", hosts, 2, tabletsCountMedium, tabletsCountMedium)
+	tlist2 := createTablets("k", "t2", hosts, 2, tabletsCountMedium, tabletsCountMedium)
+	tlist3 := createTablets("k", "t3", hosts, 2, tabletsCountMedium, tabletsCountMedium)
+	tlist = append(tlist, tlist2...)
+	tlist = append(tlist, tlist3...)
+
+	b.ResetTimer()
+
+	b.Run("FindTablets", func(b *testing.B) {
+		for i := 0; i < b.N; i++ {
+			tlist.FindTablets("k", "t3")
+		}
+	})
+
+	b.Run("FindTabletForToken", func(b *testing.B) {
+		tokens := tests.RandomTokens(getThreadSafeRnd(), b.N)
+		l, r := tlist.FindTablets("k", "t3")
+		b.ResetTimer()
+		for i := 0; i < b.N; i++ {
+			tlist.FindTabletForToken(tokens[i], l, r)
+		}
+	})
+
+	b.Run("AddTabletToTabletsList", func(b *testing.B) {
+		b.Run("FromEmpty", func(b *testing.B) {
+			runtime.GC()
+			var tlist TabletInfoList
+			indexes := tests.ShuffledIndexes(getRnd(), b.N)
+			multiplier := int64(math.MaxUint64 / uint64(b.N))
+			replicas := []ReplicaInfo{{hostId: "h1"}, {hostId: "h2"}, {hostId: "h3"}}
+			b.ResetTimer()
+			for i := 0; i < b.N; i++ {
+				token := int64(indexes[i]) * multiplier
+				tlist = tlist.AddTabletToTabletsList(&TabletInfo{
+					keyspaceName: "k",
+					tableName:    "t3",
+					firstToken:   token - multiplier,
+					lastToken:    token,
+					replicas:     replicas,
+				})
+			}
+		})
+
+		b.Run("NewTable", func(b *testing.B) {
+			runtime.GC()
+			tl := createTablets("k", "t1", tests.GenerateHostNames(3), 2, tabletsCountMedium, tabletsCountMedium)
+			indexes := tests.ShuffledIndexes(getRnd(), b.N)
+			multiplier := int64(math.MaxUint64 / uint64(b.N))
+			replicas := []ReplicaInfo{{hostId: "h1"}, {hostId: "h2"}, {hostId: "h3"}}
+			b.ResetTimer()
+			for i := 0; i < b.N; i++ {
+				token := int64(indexes[i]) * multiplier
+				tl = tl.AddTabletToTabletsList(&TabletInfo{
+					keyspaceName: "k",
+					tableName:    "t3",
+					firstToken:   token - multiplier,
+					lastToken:    token,
+					replicas:     replicas,
+				})
+			}
+		})
+	})
+}
+
+type opConfig struct {
+	opRemoveKeyspace int64
+	opRemoveTable    int64
+	opRemoveHost     int64
+}
+
+func BenchmarkCowTabletList(b *testing.B) {
+	const (
+		rf = 3
+	)
+	b.Run("Parallel-10", func(b *testing.B) {
+		runCowTabletListTestSuit(b, "ManyTables", 6, 10, rf, 1500, 5)
+		runCowTabletListTestSuit(b, "SingleTable", 6, 10, rf, 1500, 0)
+	})
+
+	b.Run("SingleThread", func(b *testing.B) {
+		runCowTabletListTestSuit(b, "ManyTables", 6, 1, rf, 1500, 5)
+		runCowTabletListTestSuit(b, "SingleTable", 6, 1, rf, 1500, 0)
+	})
+}
+
+func runCowTabletListTestSuit(b *testing.B, name string, hostsCount, parallelism, rf, totalTablets, extraTables int) {
+	b.Run(name, func(b *testing.B) {
+
+		b.Run("New", func(b *testing.B) {
+			runSingleCowTabletListTest(b, hostsCount, parallelism, rf, totalTablets, extraTables, false, opConfig{
+				opRemoveKeyspace: -1,
+				opRemoveHost:     -1,
+				opRemoveTable:    -1,
+			})
+		})
+
+		b.Run("Prepopulated", func(b *testing.B) {
+			runSingleCowTabletListTest(b, hostsCount, parallelism, rf, totalTablets, extraTables, true, opConfig{
+				opRemoveKeyspace: -1,
+				opRemoveHost:     -1,
+				opRemoveTable:    -1,
+			})
+		})
+
+		b.Run("RemoveHost", func(b *testing.B) {
+			runSingleCowTabletListTest(b, hostsCount, parallelism, rf, totalTablets, extraTables, true, opConfig{
+				opRemoveKeyspace: -1,
+				opRemoveTable:    -1,
+				opRemoveHost:     1000, // Every 1000 query is remove host, to measure congestion
+			})
+		})
+
+		b.Run("RemoveTable", func(b *testing.B) {
+			runSingleCowTabletListTest(b, hostsCount, parallelism, rf, totalTablets, extraTables, true, opConfig{
+				opRemoveKeyspace: -1,
+				opRemoveHost:     -1,
+				opRemoveTable:    1000, // Every 1000 query is remove table, to measure congestion
+			})
+		})
+
+		b.Run("RemoveKeyspace", func(b *testing.B) {
+			runSingleCowTabletListTest(b, hostsCount, parallelism, rf, totalTablets, extraTables, true, opConfig{
+				opRemoveHost:     -1,
+				opRemoveTable:    -1,
+				opRemoveKeyspace: 1000, // Every 1000 query is remove keyspace, to measure congestion
+			})
+		})
+	})
+}
+
+func runSingleCowTabletListTest(b *testing.B, hostsCount, parallelism, rf, totalTablets, extraTables int, prepopulate bool, ratios opConfig) {
+	tokenRangeCount64 := int64(totalTablets)
+	hosts := tests.GenerateHostNames(hostsCount)
+	targetKS := "kstarget"
+	targetTable := "ttarget"
+	removeKs := "ksremove"
+	removeTable := "tremove"
+	repGen := NewReplicaSetGenerator(hosts, rf)
+	readyTablets := createTablets(removeKs, removeTable, hosts, rf, totalTablets, tokenRangeCount64)
+	b.SetParallelism(parallelism)
+	tl := NewCowTabletList()
+	rnd := getThreadSafeRnd()
+	opID := atomic.Int64{}
+
+	if prepopulate {
+		tl.BulkAddTablets(createTablets(targetKS, targetTable, hosts, rf, totalTablets, tokenRangeCount64))
+	}
+
+	for i := 0; i < extraTables; i++ {
+		tl.BulkAddTablets(createTablets(targetKS, fmt.Sprintf("table-%d", i), hosts, rf, totalTablets, tokenRangeCount64))
+	}
+
+	runtime.GC()
+	b.ResetTimer()
+	b.RunParallel(func(pb *testing.PB) {
+		for pb.Next() {
+			id := opID.Add(1)
+			token := rnd.Int63()
+			tablet := tl.FindTabletForToken(targetKS, targetTable, token)
+			if tablet == nil || tablet.lastToken > token || tablet.firstToken < token {
+				// If there is no tablet for token, emulate update, same way it is usually happening
+				firstToken := (token / tokenRangeCount64) * tokenRangeCount64
+				lastToken := firstToken + tokenRangeCount64
+				tl.AddTablet(&TabletInfo{
+					keyspaceName: targetKS,
+					tableName:    targetTable,
+					firstToken:   firstToken,
+					lastToken:    lastToken,
+					replicas:     repGen.Next(),
+				})
+			}
+			if ratios.opRemoveTable == 0 || ((ratios.opRemoveTable != -1) && id%ratios.opRemoveTable == 0) {
+				tl.BulkAddTablets(readyTablets)
+				tl.RemoveTabletsWithTableFromTabletsList(targetKS, removeTable)
+			}
+			if ratios.opRemoveKeyspace == 0 || ((ratios.opRemoveKeyspace != -1) && id%ratios.opRemoveKeyspace == 0) {
+				tl.BulkAddTablets(readyTablets)
+				tl.RemoveTabletsWithKeyspace(removeKs)
+			}
+			if ratios.opRemoveHost == 0 || ((ratios.opRemoveHost != -1) && id%ratios.opRemoveHost == 0) {
+				tl.RemoveTabletsWithHost(hosts[rnd.Intn(len(hosts))])
+			}
+		}
+	})
+}
diff --git a/tablet_test.go b/tablets/tablets_test.go
similarity index 58%
rename from tablet_test.go
rename to tablets/tablets_test.go
index b4d8258..aad422b 100644
--- a/tablet_test.go
+++ b/tablets/tablets_test.go
@@ -1,10 +1,12 @@
 //go:build unit
 // +build unit

-package gocql
+package tablets

 import (
 	"testing"
+
+	"github.com/gocql/gocql/internal/tests"
 )

 var tablets = TabletInfoList{
@@ -13,142 +15,142 @@ var tablets = TabletInfoList{
 		"table1",
 		-7917529027641081857,
 		-6917529027641081857,
-		[]ReplicaInfo{{TimeUUID(), 9}},
+		[]ReplicaInfo{{tests.RandomUUID(), 9}},
 	},
 	{
 		"test1",
 		"table1",
 		-6917529027641081857,
 		-4611686018427387905,
-		[]ReplicaInfo{{TimeUUID(), 8}},
+		[]ReplicaInfo{{tests.RandomUUID(), 8}},
 	},
 	{
 		"test1",
 		"table1",
 		-4611686018427387905,
 		-2305843009213693953,
-		[]ReplicaInfo{{TimeUUID(), 9}},
+		[]ReplicaInfo{{tests.RandomUUID(), 9}},
 	},
 	{
 		"test1",
 		"table1",
 		-2305843009213693953,
 		-1,
-		[]ReplicaInfo{{TimeUUID(), 8}},
+		[]ReplicaInfo{{tests.RandomUUID(), 8}},
 	},
 	{
 		"test1",
 		"table1",
 		-1,
 		2305843009213693951,
-		[]ReplicaInfo{{TimeUUID(), 3}},
+		[]ReplicaInfo{{tests.RandomUUID(), 3}},
 	},
 	{
 		"test1",
 		"table1",
 		2305843009213693951,
 		4611686018427387903,
-		[]ReplicaInfo{{TimeUUID(), 3}},
+		[]ReplicaInfo{{tests.RandomUUID(), 3}},
 	},
 	{
 		"test1",
 		"table1",
 		4611686018427387903,
 		6917529027641081855,
-		[]ReplicaInfo{{TimeUUID(), 7}},
+		[]ReplicaInfo{{tests.RandomUUID(), 7}},
 	},
 	{
 		"test1",
 		"table1",
 		6917529027641081855,
 		9223372036854775807,
-		[]ReplicaInfo{{TimeUUID(), 7}},
+		[]ReplicaInfo{{tests.RandomUUID(), 7}},
 	},
 	{
 		"test2",
 		"table1",
 		-7917529027641081857,
 		-6917529027641081857,
-		[]ReplicaInfo{{TimeUUID(), 9}},
+		[]ReplicaInfo{{tests.RandomUUID(), 9}},
 	},
 	{
 		"test2",
 		"table1",
 		-6917529027641081857,
 		-4611686018427387905,
-		[]ReplicaInfo{{TimeUUID(), 8}},
+		[]ReplicaInfo{{tests.RandomUUID(), 8}},
 	},
 	{
 		"test2",
 		"table1",
 		-4611686018427387905,
 		-2305843009213693953,
-		[]ReplicaInfo{{TimeUUID(), 9}},
+		[]ReplicaInfo{{tests.RandomUUID(), 9}},
 	},
 	{
 		"test2",
 		"table1",
 		-2305843009213693953,
 		-1,
-		[]ReplicaInfo{{TimeUUID(), 8}},
+		[]ReplicaInfo{{tests.RandomUUID(), 8}},
 	},
 	{
 		"test2",
 		"table1",
 		-1,
 		2305843009213693951,
-		[]ReplicaInfo{{TimeUUID(), 3}},
+		[]ReplicaInfo{{tests.RandomUUID(), 3}},
 	},
 	{
 		"test2",
 		"table1",
 		2305843009213693951,
 		4611686018427387903,
-		[]ReplicaInfo{{TimeUUID(), 3}},
+		[]ReplicaInfo{{tests.RandomUUID(), 3}},
 	},
 	{
 		"test2",
 		"table1",
 		4611686018427387903,
 		6917529027641081855,
-		[]ReplicaInfo{{TimeUUID(), 7}},
+		[]ReplicaInfo{{tests.RandomUUID(), 7}},
 	},
 	{
 		"test2",
 		"table1",
 		6917529027641081855,
 		9223372036854775807,
-		[]ReplicaInfo{{TimeUUID(), 7}},
+		[]ReplicaInfo{{tests.RandomUUID(), 7}},
 	},
 }

 func TestFindTablets(t *testing.T) {
 	t.Parallel()

-	id, id2 := tablets.findTablets("test1", "table1")
-	assertEqual(t, "id", 0, id)
-	assertEqual(t, "id2", 7, id2)
+	id, id2 := tablets.FindTablets("test1", "table1")
+	tests.AssertEqual(t, "id", 0, id)
+	tests.AssertEqual(t, "id2", 7, id2)

-	id, id2 = tablets.findTablets("test2", "table1")
-	assertEqual(t, "id", 8, id)
-	assertEqual(t, "id2", 15, id2)
+	id, id2 = tablets.FindTablets("test2", "table1")
+	tests.AssertEqual(t, "id", 8, id)
+	tests.AssertEqual(t, "id2", 15, id2)

-	id, id2 = tablets.findTablets("test3", "table1")
-	assertEqual(t, "id", -1, id)
-	assertEqual(t, "id2", -1, id2)
+	id, id2 = tablets.FindTablets("test3", "table1")
+	tests.AssertEqual(t, "id", -1, id)
+	tests.AssertEqual(t, "id2", -1, id2)
 }

 func TestFindTabletForToken(t *testing.T) {
 	t.Parallel()

-	tablet := tablets.findTabletForToken(parseInt64Token("0"), 0, 7)
-	assertTrue(t, "tablet.lastToken == 2305843009213693951", tablet.lastToken == 2305843009213693951)
+	tablet := tablets.FindTabletForToken(0, 0, 7)
+	tests.AssertTrue(t, "tablet.lastToken == 2305843009213693951", tablet.lastToken == 2305843009213693951)

-	tablet = tablets.findTabletForToken(parseInt64Token("9223372036854775807"), 0, 7)
-	assertTrue(t, "tablet.lastToken == 9223372036854775807", tablet.lastToken == 9223372036854775807)
+	tablet = tablets.FindTabletForToken(9223372036854775807, 0, 7)
+	tests.AssertTrue(t, "tablet.lastToken == 9223372036854775807", tablet.lastToken == 9223372036854775807)

-	tablet = tablets.findTabletForToken(parseInt64Token("-4611686018427387904"), 0, 7)
-	assertTrue(t, "tablet.lastToken == -2305843009213693953", tablet.lastToken == -2305843009213693953)
+	tablet = tablets.FindTabletForToken(-4611686018427387904, 0, 7)
+	tests.AssertTrue(t, "tablet.lastToken == -2305843009213693953", tablet.lastToken == -2305843009213693953)
 }

 func CompareRanges(tablets TabletInfoList, ranges [][]int64) bool {
@@ -168,7 +170,7 @@ func TestAddTabletToEmptyTablets(t *testing.T) {

 	tablets := TabletInfoList{}

-	tablets = tablets.addTabletToTabletsList(&TabletInfo{
+	tablets = tablets.AddTabletToTabletsList(&TabletInfo{
 		"test_ks",
 		"test_tb",
 		-6917529027641081857,
@@ -176,7 +178,7 @@ func TestAddTabletToEmptyTablets(t *testing.T) {
 		[]ReplicaInfo{},
 	})

-	assertTrue(t, "Token range in tablets table not correct", CompareRanges(tablets, [][]int64{{-6917529027641081857, -4611686018427387905}}))
+	tests.AssertTrue(t, "Token range in tablets table not correct", CompareRanges(tablets, [][]int64{{-6917529027641081857, -4611686018427387905}}))
 }

 func TestAddTabletAtTheBeggining(t *testing.T) {
@@ -190,7 +192,7 @@ func TestAddTabletAtTheBeggining(t *testing.T) {
 		[]ReplicaInfo{},
 	}}

-	tablets = tablets.addTabletToTabletsList(&TabletInfo{
+	tablets = tablets.AddTabletToTabletsList(&TabletInfo{
 		"test_ks",
 		"test_tb",
 		-8611686018427387905,
@@ -198,7 +200,7 @@ func TestAddTabletAtTheBeggining(t *testing.T) {
 		[]ReplicaInfo{},
 	})

-	assertTrue(t, "Token range in tablets table not correct",
+	tests.AssertTrue(t, "Token range in tablets table not correct",
 		CompareRanges(tablets, [][]int64{{-8611686018427387905, -7917529027641081857}, {-6917529027641081857, -4611686018427387905}}))
 }

@@ -213,7 +215,7 @@ func TestAddTabletAtTheEnd(t *testing.T) {
 		[]ReplicaInfo{},
 	}}

-	tablets = tablets.addTabletToTabletsList(&TabletInfo{
+	tablets = tablets.AddTabletToTabletsList(&TabletInfo{
 		"test_ks",
 		"test_tb",
 		-1,
@@ -221,7 +223,7 @@ func TestAddTabletAtTheEnd(t *testing.T) {
 		[]ReplicaInfo{},
 	})

-	assertTrue(t, "Token range in tablets table not correct", CompareRanges(tablets, [][]int64{{-6917529027641081857, -4611686018427387905},
+	tests.AssertTrue(t, "Token range in tablets table not correct", CompareRanges(tablets, [][]int64{{-6917529027641081857, -4611686018427387905},
 		{-1, 2305843009213693951}}))
 }

@@ -242,7 +244,7 @@ func TestAddTabletInTheMiddle(t *testing.T) {
 		[]ReplicaInfo{},
 	}}

-	tablets = tablets.addTabletToTabletsList(&TabletInfo{
+	tablets = tablets.AddTabletToTabletsList(&TabletInfo{
 		"test_ks",
 		"test_tb",
 		-4611686018427387905,
@@ -250,7 +252,7 @@ func TestAddTabletInTheMiddle(t *testing.T) {
 		[]ReplicaInfo{},
 	})

-	assertTrue(t, "Token range in tablets table not correct", CompareRanges(tablets, [][]int64{{-6917529027641081857, -4611686018427387905},
+	tests.AssertTrue(t, "Token range in tablets table not correct", CompareRanges(tablets, [][]int64{{-6917529027641081857, -4611686018427387905},
 		{-4611686018427387905, -2305843009213693953},
 		{-1, 2305843009213693951}}))
 }
@@ -284,7 +286,7 @@ func TestAddTabletIntersecting(t *testing.T) {
 		[]ReplicaInfo{},
 	}}

-	tablets = tablets.addTabletToTabletsList(&TabletInfo{
+	tablets = tablets.AddTabletToTabletsList(&TabletInfo{
 		"test_ks",
 		"test_tb",
 		-3611686018427387905,
@@ -292,7 +294,7 @@ func TestAddTabletIntersecting(t *testing.T) {
 		[]ReplicaInfo{},
 	})

-	assertTrue(t, "Token range in tablets table not correct",
+	tests.AssertTrue(t, "Token range in tablets table not correct",
 		CompareRanges(tablets, [][]int64{{-6917529027641081857, -4611686018427387905},
 			{-3611686018427387905, -6},
 			{-1, 2305843009213693951}}))
@@ -315,7 +317,7 @@ func TestAddTabletIntersectingWithFirst(t *testing.T) {
 		[]ReplicaInfo{},
 	}}

-	tablets = tablets.addTabletToTabletsList(&TabletInfo{
+	tablets = tablets.AddTabletToTabletsList(&TabletInfo{
 		"test_ks",
 		"test_tb",
 		-8011686018427387905,
@@ -323,7 +325,7 @@ func TestAddTabletIntersectingWithFirst(t *testing.T) {
 		[]ReplicaInfo{},
 	})

-	assertTrue(t, "Token range in tablets table not correct", CompareRanges(tablets, [][]int64{{-8011686018427387905, -7987529027641081857},
+	tests.AssertTrue(t, "Token range in tablets table not correct", CompareRanges(tablets, [][]int64{{-8011686018427387905, -7987529027641081857},
 		{-6917529027641081857, -4611686018427387905}}))
 }

@@ -344,7 +346,7 @@ func TestAddTabletIntersectingWithLast(t *testing.T) {
 		[]ReplicaInfo{},
 	}}

-	tablets = tablets.addTabletToTabletsList(&TabletInfo{
+	tablets = tablets.AddTabletToTabletsList(&TabletInfo{
 		"test_ks",
 		"test_tb",
 		-5011686018427387905,
@@ -352,40 +354,38 @@ func TestAddTabletIntersectingWithLast(t *testing.T) {
 		[]ReplicaInfo{},
 	})

-	assertTrue(t, "Token range in tablets table not correct", CompareRanges(tablets, [][]int64{{-8611686018427387905, -7917529027641081857},
+	tests.AssertTrue(t, "Token range in tablets table not correct", CompareRanges(tablets, [][]int64{{-8611686018427387905, -7917529027641081857},
 		{-5011686018427387905, -2987529027641081857}}))
 }

 func TestRemoveTabletsWithHost(t *testing.T) {
 	t.Parallel()

-	removed_host_id := TimeUUID()
+	removed_host_id := tests.RandomUUID()

 	tablets := TabletInfoList{{
 		"test_ks",
 		"test_tb",
 		-8611686018427387905,
 		-7917529027641081857,
-		[]ReplicaInfo{{TimeUUID(), 9}, {TimeUUID(), 8}, {TimeUUID(), 3}},
+		[]ReplicaInfo{{tests.RandomUUID(), 9}, {tests.RandomUUID(), 8}, {tests.RandomUUID(), 3}},
 	}, {
 		"test_ks",
 		"test_tb",
 		-6917529027641081857,
 		-4611686018427387905,
-		[]ReplicaInfo{{removed_host_id, 9}, {TimeUUID(), 8}, {TimeUUID(), 3}},
+		[]ReplicaInfo{{removed_host_id, 9}, {tests.RandomUUID(), 8}, {tests.RandomUUID(), 3}},
 	}, {
 		"test_ks",
 		"test_tb",
 		-4611686018427387905,
 		-2305843009213693953,
-		[]ReplicaInfo{{TimeUUID(), 9}, {removed_host_id, 8}, {TimeUUID(), 3}},
+		[]ReplicaInfo{{tests.RandomUUID(), 9}, {removed_host_id, 8}, {tests.RandomUUID(), 3}},
 	}}

-	tablets = tablets.removeTabletsWithHostFromTabletsList(&HostInfo{
-		hostId: removed_host_id.String(),
-	})
+	tablets = tablets.RemoveTabletsWithHost(removed_host_id)

-	assertEqual(t, "TabletsList length", 1, len(tablets))
+	tests.AssertEqual(t, "TabletsList length", 1, len(tablets))
 }

 func TestRemoveTabletsWithKeyspace(t *testing.T) {
@@ -396,24 +396,24 @@ func TestRemoveTabletsWithKeyspace(t *testing.T) {
 		"test_tb",
 		-8611686018427387905,
 		-7917529027641081857,
-		[]ReplicaInfo{{TimeUUID(), 9}, {TimeUUID(), 8}, {TimeUUID(), 3}},
+		[]ReplicaInfo{{tests.RandomUUID(), 9}, {tests.RandomUUID(), 8}, {tests.RandomUUID(), 3}},
 	}, {
 		"removed_ks",
 		"test_tb",
 		-6917529027641081857,
 		-4611686018427387905,
-		[]ReplicaInfo{{TimeUUID(), 9}, {TimeUUID(), 8}, {TimeUUID(), 3}},
+		[]ReplicaInfo{{tests.RandomUUID(), 9}, {tests.RandomUUID(), 8}, {tests.RandomUUID(), 3}},
 	}, {
 		"test_ks",
 		"test_tb",
 		-4611686018427387905,
 		-2305843009213693953,
-		[]ReplicaInfo{{TimeUUID(), 9}, {TimeUUID(), 8}, {TimeUUID(), 3}},
+		[]ReplicaInfo{{tests.RandomUUID(), 9}, {tests.RandomUUID(), 8}, {tests.RandomUUID(), 3}},
 	}}

-	tablets = tablets.removeTabletsWithKeyspaceFromTabletsList("removed_ks")
+	tablets = tablets.RemoveTabletsWithKeyspace("removed_ks")

-	assertEqual(t, "TabletsList length", 1, len(tablets))
+	tests.AssertEqual(t, "TabletsList length", 1, len(tablets))
 }

 func TestRemoveTabletsWithTable(t *testing.T) {
@@ -424,22 +424,22 @@ func TestRemoveTabletsWithTable(t *testing.T) {
 		"test_tb",
 		-8611686018427387905,
 		-7917529027641081857,
-		[]ReplicaInfo{{TimeUUID(), 9}, {TimeUUID(), 8}, {TimeUUID(), 3}},
+		[]ReplicaInfo{{tests.RandomUUID(), 9}, {tests.RandomUUID(), 8}, {tests.RandomUUID(), 3}},
 	}, {
 		"test_ks",
 		"test_tb",
 		-6917529027641081857,
 		-4611686018427387905,
-		[]ReplicaInfo{{TimeUUID(), 9}, {TimeUUID(), 8}, {TimeUUID(), 3}},
+		[]ReplicaInfo{{tests.RandomUUID(), 9}, {tests.RandomUUID(), 8}, {tests.RandomUUID(), 3}},
 	}, {
 		"test_ks",
 		"removed_tb",
 		-4611686018427387905,
 		-2305843009213693953,
-		[]ReplicaInfo{{TimeUUID(), 9}, {TimeUUID(), 8}, {TimeUUID(), 3}},
+		[]ReplicaInfo{{tests.RandomUUID(), 9}, {tests.RandomUUID(), 8}, {tests.RandomUUID(), 3}},
 	}}

-	tablets = tablets.removeTabletsWithTableFromTabletsList("test_ks", "removed_tb")
+	tablets = tablets.RemoveTabletsWithTableFromTabletsList("test_ks", "removed_tb")

-	assertEqual(t, "TabletsList length", 2, len(tablets))
+	tests.AssertEqual(t, "TabletsList length", 2, len(tablets))
 }
diff --git a/testdata/config/scylla.yaml b/testdata/config/scylla.yaml
deleted file mode 100644
index 469e494..0000000
--- a/testdata/config/scylla.yaml
+++ /dev/null
@@ -1,12 +0,0 @@
-native_transport_port_ssl: 9142
-native_transport_port: 9042
-native_shard_aware_transport_port: 19042
-native_shard_aware_transport_port_ssl: 19142
-client_encryption_options:
-  enabled: true
-  certificate: /etc/scylla/db.crt
-  keyfile: /etc/scylla/db.key
-  truststore: /etc/scylla/ca.crt
-  require_client_auth: true
-maintenance_socket: workdir
-enable_tablets: true

diff --git a/testdata/pki/generate_certs.sh b/testdata/pki/generate_certs.sh
index ba06bb9..7d8fe94 100644
--- a/testdata/pki/generate_certs.sh
+++ b/testdata/pki/generate_certs.sh
@@ -31,7 +31,7 @@ VALIDITY=36500
 # Generate 4096-bit unencrypted RSA private key using aes256
 function generatePrivateKey() {
     base=$1
-    rm -fv ${base}.key
+    rm -fv ${base}.key || true
     echo "Generating private key ${base}.key"
     # Generate Private Key
     openssl genrsa -aes256 -out ${base}.key -passout pass:cassandra 4096
@@ -43,7 +43,7 @@ function generatePrivateKey() {
 # Generate a X509 Certificate signed by the generated CA
 function generateCASignedCert() {
     base=$1
-    rm -fv ${base}.csr ${base}.crt
+    rm -fv ${base}.csr ${base}.crt || true
     # Generate Certificate Signing Request
     echo "Generating certificate signing request ${base}.csr"
     openssl req -new -key ${base}.key -out ${base}.csr -config ${base}.cnf
@@ -52,7 +52,7 @@ function generateCASignedCert() {
     openssl x509 -req -in ${base}.csr -CA ca.crt -CAkey ca.key \
                  -CAcreateserial -out ${base}.crt -days $VALIDITY \
                  -extensions req_ext -extfile ${base}.cnf -text
-    rm -fv ${base}.csr
+    rm -fv ${base}.csr || true
 }

 # CA
@@ -60,13 +60,13 @@ function generateCASignedCert() {
 generatePrivateKey ca
 # Generate CA Certificate
 echo "Generating CA certificate ca.crt"
-rm -fv ca.crt
+rm -fv ca.crt || true
 openssl req -x509 -new -nodes -key ca.key -days $VALIDITY \
             -out ca.crt -config ca.cnf -text

 # Import CA certificate into JKS truststore so it can be used by Cassandra.
 echo "Generating truststore .truststore for Cassandra"
-rm -fv .truststore
+rm -fv .truststore || true
 keytool -import -keystore .truststore -trustcacerts \
         -file ca.crt -alias ca -storetype JKS \
         -storepass cassandra -noprompt
@@ -84,14 +84,14 @@ generateCASignedCert cassandra
 # Import cassandra private key and certificate into a PKCS12 keystore
 # and to a JKS keystore so it can be used by cassandra.
 echo "Generating cassandra.p12 and .keystore for Cassandra"
-rm -fv cassandra.p12
+rm -fv cassandra.p12 || true
 openssl pkcs12 -export -in cassandra.crt -inkey cassandra.key \
                -out cassandra.p12 -name cassandra \
                -CAfile ca.crt -caname ca \
                -password pass:cassandra \
                -noiter -nomaciter

-rm -fv .keystore
+rm -fv .keystore || true
 keytool -importkeystore -srckeystore cassandra.p12 -srcstoretype PKCS12 \
 	-srcstorepass cassandra -srcalias cassandra \
 	-destkeystore .keystore -deststoretype JKS \
diff --git a/tests/bench/go.sum b/tests/bench/go.sum
index 45b17c3..f064b7b 100644
--- a/tests/bench/go.sum
+++ b/tests/bench/go.sum
@@ -8,6 +8,7 @@ github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSs
 github.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
 github.com/google/go-cmp v0.4.0 h1:xsAVV57WRhGj6kEIi8ReJzQlHHqcBYCElAvkovg3B/4=
 github.com/google/go-cmp v0.4.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=
+github.com/google/uuid v1.6.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=
 github.com/hailocab/go-hostpool v0.0.0-20160125115350-e80d13ce29ed h1:5upAirOpQc1Q53c0bnx2ufif5kANL7bfZWcc6VJWJd8=
 github.com/hailocab/go-hostpool v0.0.0-20160125115350-e80d13ce29ed/go.mod h1:tMWxXQ9wFIaZeTI9F+hmhFiGpFmhOHzyShyFUhRm0H4=
 github.com/klauspost/compress v1.17.9 h1:6KIumPrER1LHsvBVuDa0r5xaG0Es51mhhB9BQB2qeMA=
diff --git a/tests/serialization/marshal_0_unset_test.go b/tests/serialization/marshal_0_unset_test.go
index f9c0652..4cdb334 100644
--- a/tests/serialization/marshal_0_unset_test.go
+++ b/tests/serialization/marshal_0_unset_test.go
@@ -18,7 +18,7 @@ func TestMarshalUnsetColumn(t *testing.T) {
 		err     bool
 	}

-	elem := gocql.NewNativeType(2, gocql.TypeSmallInt, "")
+	elem := gocql.NewNativeType(3, gocql.TypeSmallInt, "")
 	cases := []tCase{
 		{gocql.NewNativeType(4, gocql.TypeBoolean, ""), true, false},
 		{gocql.NewNativeType(4, gocql.TypeTinyInt, ""), true, false},
@@ -42,12 +42,9 @@ func TestMarshalUnsetColumn(t *testing.T) {
 		{gocql.NewNativeType(4, gocql.TypeDate, ""), true, false},
 		{gocql.NewNativeType(4, gocql.TypeDuration, ""), true, false},

-		{gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeList, ""), nil, elem), true, false},
-		{gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeSet, ""), nil, elem), true, false},
 		{gocql.NewCollectionType(gocql.NewNativeType(3, gocql.TypeList, ""), nil, elem), true, false},
 		{gocql.NewCollectionType(gocql.NewNativeType(3, gocql.TypeSet, ""), nil, elem), true, false},

-		{gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeMap, ""), nil, elem), true, false},
 		{gocql.NewCollectionType(gocql.NewNativeType(3, gocql.TypeMap, ""), elem, elem), true, false},

 		{gocql.NewUDTType(3, "udt1", "", gocql.UDTField{Name: "1", Type: elem}), true, true},
diff --git a/tests/serialization/marshal_19_list_set_v2_corrupt_test.go b/tests/serialization/marshal_19_list_set_v2_corrupt_test.go
deleted file mode 100644
index 1b33c75..0000000
--- a/tests/serialization/marshal_19_list_set_v2_corrupt_test.go
+++ /dev/null
@@ -1,228 +0,0 @@
-//go:build unit
-// +build unit
-
-package serialization_test
-
-import (
-	"fmt"
-	"math"
-	"testing"
-
-	"github.com/gocql/gocql"
-	"github.com/gocql/gocql/internal/tests/serialization"
-	"github.com/gocql/gocql/internal/tests/serialization/mod"
-)
-
-func TestMarshalSetListV2Corrupt(t *testing.T) {
-	t.Parallel()
-
-	elem := gocql.NewNativeType(2, gocql.TypeSmallInt, "")
-	tTypes := []gocql.TypeInfo{
-		gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeList, ""), nil, elem),
-		gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeSet, ""), nil, elem),
-	}
-
-	// unmarshal data than bigger the normal data, does not return error.
-	brokenBigData := serialization.GetTypes(mod.Values{
-		[]int16{}, []*int16{},
-		[]mod.Int16{}, []*mod.Int16{},
-		[1]int16{}, [1]*int16{},
-		[1]mod.Int16{}, [1]*mod.Int16{},
-	}.AddVariants(mod.All...)...)
-
-	brokenBigDataSlices := serialization.GetTypes(mod.Values{
-		[]int16{}, []*int16{},
-		[]mod.Int16{}, []*mod.Int16{},
-	}.AddVariants(mod.All...)...)
-
-	refInt32 := func(v int32) *int32 { return &v }
-	refModInt32 := func(v mod.Int32) *mod.Int32 { return &v }
-
-	for _, tType := range tTypes {
-		marshal := func(i interface{}) ([]byte, error) { return gocql.Marshal(tType, i) }
-		unmarshal := func(bytes []byte, i interface{}) error {
-			return gocql.Unmarshal(tType, bytes, i)
-		}
-
-		t.Run(tType.Type().String(), func(t *testing.T) {
-
-			val := int32(math.MaxInt16 + 1)
-			valc := mod.Int32(val)
-			serialization.NegativeMarshalSet{
-				Values: mod.Values{
-					[]int32{val}, []*int32{refInt32(val)},
-					[1]int32{val}, [1]*int32{refInt32(val)},
-					[]mod.Int32{valc}, []*mod.Int32{refModInt32(valc)},
-					[1]mod.Int32{valc}, [1]*mod.Int32{refModInt32(valc)},
-				}.AddVariants(mod.All...),
-			}.Run("big_vals", t, marshal)
-
-			serialization.NegativeUnmarshalSet{
-				Data: []byte("\x00\x01\x00\x02\xff\xff\x01"),
-				Values: mod.Values{
-					[]int16{}, []*int16{},
-					[]mod.Int16{}, []*mod.Int16{},
-					[1]int16{}, [1]*int16{},
-					[1]mod.Int16{}, [1]*mod.Int16{},
-				}.AddVariants(mod.All...),
-				BrokenTypes: brokenBigData,
-			}.Run("big_data_elem1+", t, unmarshal)
-
-			serialization.NegativeUnmarshalSet{
-				Data: []byte("\x00\x01\x00\x00\xff"),
-				Values: mod.Values{
-					[]int16{}, []*int16{},
-					[]mod.Int16{}, []*mod.Int16{},
-					[1]int16{}, [1]*int16{},
-					[1]mod.Int16{}, [1]*mod.Int16{},
-				}.AddVariants(mod.All...),
-				BrokenTypes: brokenBigData,
-			}.Run("big_data_zeroElem1+", t, unmarshal)
-
-			serialization.NegativeUnmarshalSet{
-				Data: []byte("\x00\x00\x01"),
-				Values: mod.Values{
-					[]int16{}, []*int16{},
-					[]mod.Int16{}, []*mod.Int16{},
-					[1]int16{}, [1]*int16{},
-					[1]mod.Int16{}, [1]*mod.Int16{},
-				}.AddVariants(mod.All...),
-				BrokenTypes: brokenBigDataSlices,
-			}.Run("big_data_elem0+", t, unmarshal)
-
-			serialization.NegativeUnmarshalSet{
-				Data: []byte("\x00\x01\x00\x02\xff"),
-				Values: mod.Values{
-					[]int16{}, []*int16{},
-					[]mod.Int16{}, []*mod.Int16{},
-					[1]int16{}, [1]*int16{},
-					[1]mod.Int16{}, [1]*mod.Int16{},
-				}.AddVariants(mod.All...),
-			}.Run("small_data_elem_value-", t, unmarshal)
-
-			serialization.NegativeUnmarshalSet{
-				Data: []byte("\x00\x01\x00\x02"),
-				Values: mod.Values{
-					[]int16{}, []*int16{},
-					[]mod.Int16{}, []*mod.Int16{},
-					[1]int16{}, [1]*int16{},
-					[1]mod.Int16{}, [1]*mod.Int16{},
-				}.AddVariants(mod.All...),
-			}.Run("small_data_elem_value--", t, unmarshal)
-
-			serialization.NegativeUnmarshalSet{
-				Data: []byte("\x00\x01\x00"),
-				Values: mod.Values{
-					[]int16{}, []*int16{},
-					[]mod.Int16{}, []*mod.Int16{},
-					[1]int16{}, [1]*int16{},
-					[1]mod.Int16{}, [1]*mod.Int16{},
-				}.AddVariants(mod.All...),
-			}.Run("small_data_elem_len-", t, unmarshal)
-
-			serialization.NegativeUnmarshalSet{
-				Data: []byte("\x00\x01"),
-				Values: mod.Values{
-					[]int16{}, []*int16{},
-					[]mod.Int16{}, []*mod.Int16{},
-					[1]int16{}, [1]*int16{},
-					[1]mod.Int16{}, [1]*mod.Int16{},
-				}.AddVariants(mod.All...),
-			}.Run("small_data_elem-", t, unmarshal)
-
-			serialization.NegativeUnmarshalSet{
-				Data: []byte("\x00"),
-				Values: mod.Values{
-					[]int16{}, []*int16{},
-					[]mod.Int16{}, []*mod.Int16{},
-					[1]int16{}, [1]*int16{},
-					[1]mod.Int16{}, [1]*mod.Int16{},
-				}.AddVariants(mod.All...),
-			}.Run("small_data_elems-", t, unmarshal)
-
-			serialization.NegativeUnmarshalSet{
-				Data: nil,
-				Values: mod.Values{
-					[1]int16{}, [1]*int16{},
-					[1]mod.Int16{}, [1]*mod.Int16{},
-				}.AddVariants(mod.CustomType),
-			}.Run("nil_data_to_array", t, unmarshal)
-
-			serialization.NegativeUnmarshalSet{
-				Data: make([]byte, 0),
-				Values: mod.Values{
-					[1]int16{}, [1]*int16{},
-					[1]mod.Int16{}, [1]*mod.Int16{},
-				}.AddVariants(mod.CustomType),
-			}.Run("zero_data_to_array", t, unmarshal)
-
-			serialization.NegativeUnmarshalSet{
-				Data: []byte("\x00\x00"),
-				Values: mod.Values{
-					[1]int16{}, [1]*int16{},
-					[1]mod.Int16{}, [1]*mod.Int16{},
-				}.AddVariants(mod.All...),
-			}.Run("zero_elems_to_array", t, unmarshal)
-		})
-	}
-}
-
-func TestMarshalSetListV2CorruptMax(t *testing.T) {
-	t.Parallel()
-
-	elem := gocql.NewNativeType(2, gocql.TypeSmallInt, "")
-
-	tTypes := []gocql.TypeInfo{
-		gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeList, ""), nil, elem),
-		gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeSet, ""), nil, elem),
-	}
-
-	elems := math.MaxUint16 + 1
-	values := []func() interface{}{
-		func() interface{} {
-			out := make([]int16, elems)
-			for i := range out {
-				out[i] = int16(1)
-			}
-			return out
-		},
-		func() interface{} {
-			out := make([]*int16, elems)
-			for i := range out {
-				tmp := int16(1)
-				out[i] = &tmp
-			}
-			return out
-		},
-		func() interface{} {
-			out := make([]mod.Int16, elems)
-			for i := range out {
-				out[i] = mod.Int16(1)
-			}
-			return out
-		},
-		func() interface{} {
-			out := make([]*mod.Int16, elems)
-			for i := range out {
-				tmp := mod.Int16(1)
-				out[i] = &tmp
-			}
-			return out
-		},
-	}
-
-	for _, tType := range tTypes {
-		marshal := func(i interface{}) ([]byte, error) { return gocql.Marshal(tType, i) }
-
-		t.Run(tType.Type().String(), func(t *testing.T) {
-			for _, v := range values {
-				value := v()
-				name := fmt.Sprintf("%T", value)
-
-				serialization.NegativeMarshalSet{
-					Values: mod.Values{value}.AddVariants(mod.All...),
-				}.Run(name, t, marshal)
-			}
-		})
-	}
-}
diff --git a/tests/serialization/marshal_19_list_set_v2_test.go b/tests/serialization/marshal_19_list_set_v2_test.go
deleted file mode 100644
index bc1874f..0000000
--- a/tests/serialization/marshal_19_list_set_v2_test.go
+++ /dev/null
@@ -1,179 +0,0 @@
-//go:build unit
-// +build unit
-
-package serialization_test
-
-import (
-	"fmt"
-	"math"
-	"testing"
-
-	"github.com/gocql/gocql"
-	"github.com/gocql/gocql/internal/tests/serialization"
-	"github.com/gocql/gocql/internal/tests/serialization/mod"
-)
-
-func TestMarshalSetListV2(t *testing.T) {
-	elem := gocql.NewNativeType(2, gocql.TypeSmallInt, "")
-
-	tTypes := []gocql.TypeInfo{
-		gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeList, ""), nil, elem),
-		gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeSet, ""), nil, elem),
-	}
-
-	// unmarshal `zero` data return an error
-	brokenZeroDataUnmarshal := serialization.GetTypes(mod.Values{
-		[]int16{}, []*int16{},
-		[]mod.Int16{}, []*mod.Int16{},
-		&[]int16{}, &[]*int16{},
-		&[]mod.Int16{}, &[]*mod.Int16{},
-		(*[1]int16)(nil), (*[1]*int16)(nil),
-		(*[1]mod.Int16)(nil), (*[1]*mod.Int16)(nil),
-	}.AddVariants(mod.CustomType)...)
-
-	refInt16 := func(v int16) *int16 { return &v }
-	refModInt16 := func(v mod.Int16) *mod.Int16 { return &v }
-
-	for _, tType := range tTypes {
-		marshal := func(i interface{}) ([]byte, error) { return gocql.Marshal(tType, i) }
-		unmarshal := func(bytes []byte, i interface{}) error {
-			return gocql.Unmarshal(tType, bytes, i)
-		}
-
-		t.Run(tType.Type().String(), func(t *testing.T) {
-
-			serialization.PositiveSet{
-				Data: nil,
-				Values: mod.Values{
-					([]int16)(nil), ([]*int16)(nil),
-					([]mod.Int16)(nil), ([]*mod.Int16)(nil),
-					(*[]int16)(nil), (*[]*int16)(nil),
-					(*[]mod.Int16)(nil), (*[]*mod.Int16)(nil),
-					(*[1]int16)(nil), (*[1]*int16)(nil),
-					(*[1]mod.Int16)(nil), (*[1]*mod.Int16)(nil),
-				}.AddVariants(mod.CustomType),
-			}.Run("[nil]nullable", t, marshal, unmarshal)
-
-			serialization.PositiveSet{
-				Data: make([]byte, 0),
-				Values: mod.Values{
-					[]int16{}, []*int16{},
-					[]mod.Int16{}, []*mod.Int16{},
-					&[]int16{}, &[]*int16{},
-					&[]mod.Int16{}, &[]*mod.Int16{},
-					(*[1]int16)(nil), (*[1]*int16)(nil),
-					(*[1]mod.Int16)(nil), (*[1]*mod.Int16)(nil),
-				}.AddVariants(mod.CustomType),
-				BrokenUnmarshalTypes: brokenZeroDataUnmarshal,
-			}.Run("[]unmarshal", t, nil, unmarshal)
-
-			serialization.PositiveSet{
-				Data: []byte("\x00\x00"),
-				Values: mod.Values{
-					[]int16{}, []*int16{},
-					[]mod.Int16{}, []*mod.Int16{},
-				}.AddVariants(mod.All...),
-			}.Run("zero elems", t, marshal, unmarshal)
-
-			serialization.PositiveSet{
-				Data: []byte("\x00\x01\x00\x02\x00\x00"),
-				Values: mod.Values{
-					[]int16{0}, []*int16{refInt16(0)},
-					[]mod.Int16{0}, []*mod.Int16{refModInt16(0)},
-					[1]int16{0}, [1]*int16{refInt16(0)},
-					[1]mod.Int16{0}, [1]*mod.Int16{refModInt16(0)},
-				}.AddVariants(mod.All...),
-			}.Run("[]{0}", t, marshal, unmarshal)
-
-			serialization.PositiveSet{
-				Data: []byte("\x00\x01\x00\x00"),
-				Values: mod.Values{
-					[]int16{0}, []*int16{refInt16(0)},
-					[]mod.Int16{0}, []*mod.Int16{refModInt16(0)},
-					[1]int16{0}, [1]*int16{refInt16(0)},
-					[1]mod.Int16{0}, [1]*mod.Int16{refModInt16(0)},
-				}.AddVariants(mod.All...),
-			}.Run("[]{zero elem}unmarshal", t, nil, unmarshal)
-
-			serialization.PositiveSet{
-				Data: []byte("\x00\x01\x00\x02\x7f\xff"),
-				Values: mod.Values{
-					[]int16{32767}, []*int16{refInt16(32767)},
-					[]mod.Int16{32767}, []*mod.Int16{refModInt16(32767)},
-					[1]int16{32767}, [1]*int16{refInt16(32767)},
-					[1]mod.Int16{32767}, [1]*mod.Int16{refModInt16(32767)},
-				}.AddVariants(mod.All...),
-			}.Run("[]{max}", t, marshal, unmarshal)
-		})
-	}
-}
-
-func TestMarshalSetListV2Max(t *testing.T) {
-	t.Parallel()
-	elem := gocql.NewNativeType(2, gocql.TypeSmallInt, "")
-
-	tTypes := []gocql.TypeInfo{
-		gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeList, ""), nil, elem),
-		gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeSet, ""), nil, elem),
-	}
-
-	elems := math.MaxUint16
-
-	data := make([]byte, 0, elems*4+2)
-	data = append(data, 255, 255)
-	for v := 0; v < elems; v++ {
-		data = append(data, 0, 2, 0, 1)
-	}
-
-	values := []func() interface{}{
-		func() interface{} {
-			out := make([]int16, elems)
-			for i := range out {
-				out[i] = int16(1)
-			}
-			return out
-		},
-		func() interface{} {
-			out := make([]*int16, elems)
-			for i := range out {
-				tmp := int16(1)
-				out[i] = &tmp
-			}
-			return out
-		},
-		func() interface{} {
-			out := make([]mod.Int16, elems)
-			for i := range out {
-				out[i] = mod.Int16(1)
-			}
-			return out
-		},
-		func() interface{} {
-			out := make([]*mod.Int16, elems)
-			for i := range out {
-				tmp := mod.Int16(1)
-				out[i] = &tmp
-			}
-			return out
-		},
-	}
-
-	for _, tType := range tTypes {
-		marshal := func(i interface{}) ([]byte, error) { return gocql.Marshal(tType, i) }
-		unmarshal := func(bytes []byte, i interface{}) error {
-			return gocql.Unmarshal(tType, bytes, i)
-		}
-
-		t.Run(tType.Type().String(), func(t *testing.T) {
-			for _, v := range values {
-				value := v()
-				name := fmt.Sprintf("%T", value)
-
-				serialization.PositiveSet{
-					Data:   data,
-					Values: mod.Values{value}.AddVariants(mod.All...),
-				}.Run(name, t, marshal, unmarshal)
-			}
-		})
-	}
-}
diff --git a/tests/serialization/marshal_20_map_v2_corrupt_test.go b/tests/serialization/marshal_20_map_v2_corrupt_test.go
deleted file mode 100644
index 540f0c8..0000000
--- a/tests/serialization/marshal_20_map_v2_corrupt_test.go
+++ /dev/null
@@ -1,197 +0,0 @@
-//go:build unit
-// +build unit
-
-package serialization_test
-
-import (
-	"fmt"
-	"math"
-	"testing"
-
-	"github.com/gocql/gocql"
-	"github.com/gocql/gocql/internal/tests/serialization"
-	"github.com/gocql/gocql/internal/tests/serialization/mod"
-)
-
-func TestMarshalMapV2Corrupt(t *testing.T) {
-	t.Parallel()
-
-	elem := gocql.NewNativeType(2, gocql.TypeSmallInt, "")
-	tType := gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeMap, ""), elem, elem)
-
-	//unmarshal data than bigger the normal data, does not return error.
-	brokenBigData := serialization.GetTypes(mod.Values{
-		make(map[int16]int16), make(map[int16]*int16),
-		make(map[mod.Int16]mod.Int16), make(map[mod.Int16]*mod.Int16),
-	}.AddVariants(mod.All...)...)
-
-	refInt32 := func(v int32) *int32 { return &v }
-	refModInt32 := func(v mod.Int32) *mod.Int32 { return &v }
-
-	marshal := func(i interface{}) ([]byte, error) { return gocql.Marshal(tType, i) }
-	unmarshal := func(bytes []byte, i interface{}) error {
-		return gocql.Unmarshal(tType, bytes, i)
-	}
-
-	val := int32(math.MaxInt16 + 1)
-	valc := mod.Int32(val)
-	serialization.NegativeMarshalSet{
-		Values: mod.Values{
-			map[int32]int32{val: val}, map[int32]int32{val: 0}, map[int32]int32{0: val},
-			map[int32]*int32{val: refInt32(val)}, map[int32]*int32{val: refInt32(0)}, map[int32]*int32{0: refInt32(val)},
-			map[mod.Int32]mod.Int32{valc: valc}, map[mod.Int32]mod.Int32{valc: 0}, map[mod.Int32]mod.Int32{0: valc},
-			map[mod.Int32]*mod.Int32{valc: refModInt32(valc)}, map[mod.Int32]*mod.Int32{valc: refModInt32(0)}, map[mod.Int32]*mod.Int32{0: refModInt32(valc)},
-		}.AddVariants(mod.All...),
-	}.Run("big_vals", t, marshal)
-
-	serialization.NegativeUnmarshalSet{
-		Data: []byte("\x00\x01\x00\x02\xff\xff\x00\x02\xff\xff\x01"),
-		Values: mod.Values{
-			make(map[int16]int16), make(map[int16]*int16),
-			make(map[mod.Int16]mod.Int16), make(map[mod.Int16]*mod.Int16),
-		}.AddVariants(mod.All...),
-		BrokenTypes: brokenBigData,
-	}.Run("big_data_elem1+", t, unmarshal)
-
-	serialization.NegativeUnmarshalSet{
-		Data: []byte("\x00\x01\x00\x00\x00\x00\xff"),
-		Values: mod.Values{
-			make(map[int16]int16), make(map[int16]*int16),
-			make(map[mod.Int16]mod.Int16), make(map[mod.Int16]*mod.Int16),
-		}.AddVariants(mod.All...),
-		BrokenTypes: brokenBigData,
-	}.Run("big_data_zeroElem1+", t, unmarshal)
-
-	serialization.NegativeUnmarshalSet{
-		Data: []byte("\x00\x00\x01"),
-		Values: mod.Values{
-			make(map[int16]int16), make(map[int16]*int16),
-			make(map[mod.Int16]mod.Int16), make(map[mod.Int16]*mod.Int16),
-		}.AddVariants(mod.All...),
-		BrokenTypes: brokenBigData,
-	}.Run("big_data_elems0+", t, unmarshal)
-
-	serialization.NegativeUnmarshalSet{
-		Data: []byte("\x00\x01\x00\x02\xff\xff\x00\x02\xff"),
-		Values: mod.Values{
-			make(map[int16]int16), make(map[int16]*int16),
-			make(map[mod.Int16]mod.Int16), make(map[mod.Int16]*mod.Int16),
-		}.AddVariants(mod.All...),
-	}.Run("small_data_val_value-", t, unmarshal)
-
-	serialization.NegativeUnmarshalSet{
-		Data: []byte("\x00\x01\x00\x02\xff\xff\x00\x02"),
-		Values: mod.Values{
-			make(map[int16]int16), make(map[int16]*int16),
-			make(map[mod.Int16]mod.Int16), make(map[mod.Int16]*mod.Int16),
-		}.AddVariants(mod.All...),
-	}.Run("small_data_val_len", t, unmarshal)
-
-	serialization.NegativeUnmarshalSet{
-		Data: []byte("\x00\x01\x00\x02\xff\xff\x00"),
-		Values: mod.Values{
-			make(map[int16]int16), make(map[int16]*int16),
-			make(map[mod.Int16]mod.Int16), make(map[mod.Int16]*mod.Int16),
-		}.AddVariants(mod.All...),
-	}.Run("small_data_val_len-", t, unmarshal)
-
-	serialization.NegativeUnmarshalSet{
-		Data: []byte("\x00\x01\x00\x02\xff\xff"),
-		Values: mod.Values{
-			make(map[int16]int16), make(map[int16]*int16),
-			make(map[mod.Int16]mod.Int16), make(map[mod.Int16]*mod.Int16),
-		}.AddVariants(mod.All...),
-	}.Run("small_data_val-", t, unmarshal)
-
-	serialization.NegativeUnmarshalSet{
-		Data: []byte("\x00\x01\x00\x02\xff"),
-		Values: mod.Values{
-			make(map[int16]int16), make(map[int16]*int16),
-			make(map[mod.Int16]mod.Int16), make(map[mod.Int16]*mod.Int16),
-		}.AddVariants(mod.All...),
-	}.Run("small_data_key_value-", t, unmarshal)
-
-	serialization.NegativeUnmarshalSet{
-		Data: []byte("\x00\x01\x00\x02"),
-		Values: mod.Values{
-			make(map[int16]int16), make(map[int16]*int16),
-			make(map[mod.Int16]mod.Int16), make(map[mod.Int16]*mod.Int16),
-		}.AddVariants(mod.All...),
-	}.Run("small_data_key_len", t, unmarshal)
-
-	serialization.NegativeUnmarshalSet{
-		Data: []byte("\x00\x01\x00"),
-		Values: mod.Values{
-			make(map[int16]int16), make(map[int16]*int16),
-			make(map[mod.Int16]mod.Int16), make(map[mod.Int16]*mod.Int16),
-		}.AddVariants(mod.All...),
-	}.Run("small_data_key_len-", t, unmarshal)
-
-	serialization.NegativeUnmarshalSet{
-		Data: []byte("\x00\x01"),
-		Values: mod.Values{
-			make(map[int16]int16), make(map[int16]*int16),
-			make(map[mod.Int16]mod.Int16), make(map[mod.Int16]*mod.Int16),
-		}.AddVariants(mod.All...),
-	}.Run("small_data_pair-", t, unmarshal)
-
-	serialization.NegativeUnmarshalSet{
-		Data: []byte("\x00"),
-		Values: mod.Values{
-			make(map[int16]int16), make(map[int16]*int16),
-			make(map[mod.Int16]mod.Int16), make(map[mod.Int16]*mod.Int16),
-		}.AddVariants(mod.All...),
-	}.Run("small_data_elems-", t, unmarshal)
-}
-
-func TestMarshalMapV2CorruptMax(t *testing.T) {
-	t.Parallel()
-
-	elem := gocql.NewNativeType(2, gocql.TypeSmallInt, "")
-	tType := gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeMap, ""), elem, elem)
-
-	elems := math.MaxUint16 + 1
-	values := []func() interface{}{
-		func() interface{} {
-			out := make(map[int32]int32, elems)
-			for i := 0; i < elems; i++ {
-				out[int32(i)] = int32(1)
-			}
-			return out
-		},
-		func() interface{} {
-			out := make(map[int32]*int32, elems)
-			for i := 0; i < elems; i++ {
-				tmp := int32(1)
-				out[int32(i)] = &tmp
-			}
-			return out
-		},
-		func() interface{} {
-			out := make(map[mod.Int32]mod.Int32, elems)
-			for i := 0; i < elems; i++ {
-				out[mod.Int32(i)] = mod.Int32(1)
-			}
-			return out
-		},
-		func() interface{} {
-			out := make(map[mod.Int32]*mod.Int32, elems)
-			for i := 0; i < elems; i++ {
-				tmp := mod.Int32(1)
-				out[mod.Int32(i)] = &tmp
-			}
-			return out
-		},
-	}
-
-	marshal := func(i interface{}) ([]byte, error) { return gocql.Marshal(tType, i) }
-
-	for _, v := range values {
-		value := v()
-		name := fmt.Sprintf("%T", value)
-
-		serialization.NegativeMarshalSet{
-			Values: mod.Values{value}.AddVariants(mod.All...),
-		}.Run(name, t, marshal)
-	}
-}
diff --git a/tests/serialization/marshal_20_map_v2_test.go b/tests/serialization/marshal_20_map_v2_test.go
deleted file mode 100644
index bb3c5f5..0000000
--- a/tests/serialization/marshal_20_map_v2_test.go
+++ /dev/null
@@ -1,136 +0,0 @@
-//go:build unit
-// +build unit
-
-package serialization_test
-
-import (
-	"fmt"
-	"math"
-	"testing"
-
-	"github.com/gocql/gocql"
-	"github.com/gocql/gocql/internal/tests/serialization"
-	"github.com/gocql/gocql/internal/tests/serialization/mod"
-)
-
-func TestMarshalMapV2(t *testing.T) {
-	t.Parallel()
-
-	elem := gocql.NewNativeType(2, gocql.TypeSmallInt, "")
-	tType := gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeMap, ""), elem, elem)
-
-	refInt16 := func(v int16) *int16 { return &v }
-	refModInt16 := func(v mod.Int16) *mod.Int16 { return &v }
-
-	marshal := func(i interface{}) ([]byte, error) { return gocql.Marshal(tType, i) }
-	unmarshal := func(bytes []byte, i interface{}) error {
-		return gocql.Unmarshal(tType, bytes, i)
-	}
-
-	serialization.PositiveSet{
-		Data: nil,
-		Values: mod.Values{
-			(map[int16]int16)(nil), (map[int16]*int16)(nil),
-			(map[mod.Int16]mod.Int16)(nil), (map[mod.Int16]*mod.Int16)(nil),
-			(*map[int16]int16)(nil), (*map[int16]*int16)(nil),
-			(*map[mod.Int16]mod.Int16)(nil), (*map[mod.Int16]*mod.Int16)(nil),
-		}.AddVariants(mod.CustomType),
-	}.Run("[nil]nullable", t, marshal, unmarshal)
-
-	serialization.PositiveSet{
-		Data: []byte("\x00\x00"),
-		Values: mod.Values{
-			make(map[int16]int16), make(map[int16]*int16),
-			make(map[mod.Int16]mod.Int16), make(map[mod.Int16]*mod.Int16),
-		}.AddVariants(mod.All...),
-	}.Run("zero elems", t, marshal, unmarshal)
-
-	serialization.PositiveSet{
-		Data: []byte("\x00\x01\x00\x00\x00\x00"),
-		Values: mod.Values{
-			map[int16]int16{0: 0}, map[int16]*int16{0: refInt16(0)},
-			map[mod.Int16]mod.Int16{0: 0}, map[mod.Int16]*mod.Int16{0: refModInt16(0)},
-		}.AddVariants(mod.All...),
-	}.Run("[]{zero elem}unmarshal", t, nil, unmarshal)
-
-	serialization.PositiveSet{
-		Data: []byte("\x00\x01\x00\x02\x00\x00\x00\x02\x00\x00"),
-		Values: mod.Values{
-			map[int16]int16{0: 0}, map[int16]*int16{0: refInt16(0)},
-			map[mod.Int16]mod.Int16{0: 0}, map[mod.Int16]*mod.Int16{0: refModInt16(0)},
-		}.AddVariants(mod.All...),
-	}.Run("[]{0:0}", t, marshal, unmarshal)
-
-	serialization.PositiveSet{
-		Data: []byte("\x00\x01\x00\x02\x7f\xff\x00\x02\x7f\xff"),
-		Values: mod.Values{
-			map[int16]int16{32767: 32767}, map[int16]*int16{32767: refInt16(32767)},
-			map[mod.Int16]mod.Int16{32767: 32767}, map[mod.Int16]*mod.Int16{32767: refModInt16(32767)},
-		}.AddVariants(mod.All...),
-	}.Run("[]{max:max}", t, marshal, unmarshal)
-}
-
-func TestMarshalMapV2Max(t *testing.T) {
-	t.Parallel()
-
-	elem := gocql.NewNativeType(2, gocql.TypeSmallInt, "")
-	tType := gocql.NewCollectionType(gocql.NewNativeType(2, gocql.TypeMap, ""), elem, elem)
-
-	elems := math.MaxUint16
-
-	data := make([]byte, 0, elems*8+2)
-	data = append(data, 255, 255)
-	uintData := func(v uint) (byte, byte) {
-		return byte(v >> 8), byte(v)
-	}
-	for v := 0; v < elems; v++ {
-		b1, b2 := uintData(uint(v))
-		data = append(data, 0, 2, b1, b2, 0, 2, 0, 1)
-	}
-
-	values := []func() interface{}{
-		func() interface{} {
-			out := make(map[int16]int16, elems)
-			for i := 0; i < elems; i++ {
-				out[int16(i)] = int16(1)
-			}
-			return out
-		},
-		func() interface{} {
-			out := make(map[int16]*int16, elems)
-			for i := 0; i < elems; i++ {
-				tmp := int16(1)
-				out[int16(i)] = &tmp
-			}
-			return out
-		},
-		func() interface{} {
-			out := make(map[mod.Int16]mod.Int16, elems)
-			for i := 0; i < elems; i++ {
-				out[mod.Int16(i)] = mod.Int16(1)
-			}
-			return out
-		},
-		func() interface{} {
-			out := make(map[mod.Int16]*mod.Int16, elems)
-			for i := 0; i < elems; i++ {
-				tmp := mod.Int16(1)
-				out[mod.Int16(i)] = &tmp
-			}
-			return out
-		},
-	}
-	unmarshal := func(bytes []byte, i interface{}) error {
-		return gocql.Unmarshal(tType, bytes, i)
-	}
-
-	for _, v := range values {
-		value := v()
-		name := fmt.Sprintf("%T", value)
-
-		serialization.PositiveSet{
-			Data:   data,
-			Values: mod.Values{value}.AddVariants(mod.All...),
-		}.Run(name, t, nil, unmarshal)
-	}
-}
diff --git a/tuple_test.go b/tuple_test.go
index 446cd7f..9d2710d 100644
--- a/tuple_test.go
+++ b/tuple_test.go
@@ -35,9 +35,6 @@ import (
 func TestTupleSimple(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()
-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("tuple types are only available of proto>=3")
-	}

 	err := createTable(session, `CREATE TABLE gocql_test.tuple_test(
 		id int,
@@ -79,9 +76,6 @@ func TestTupleSimple(t *testing.T) {
 func TestTuple_NullTuple(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()
-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("tuple types are only available of proto>=3")
-	}

 	err := createTable(session, `CREATE TABLE gocql_test.tuple_nil_test(
 		id int,
@@ -117,9 +111,6 @@ func TestTuple_NullTuple(t *testing.T) {
 func TestTuple_TupleNotSet(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()
-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("tuple types are only available of proto>=3")
-	}

 	err := createTable(session, `CREATE TABLE gocql_test.tuple_not_set_test(
 		id int,
@@ -170,9 +161,6 @@ func TestTuple_TupleNotSet(t *testing.T) {
 func TestTupleMapScan(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()
-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("tuple types are only available of proto>=3")
-	}

 	err := createTable(session, `CREATE TABLE gocql_test.tuple_map_scan(
 		id int,
@@ -203,9 +191,7 @@ func TestTupleMapScan(t *testing.T) {
 func TestTupleMapScanNil(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()
-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("tuple types are only available of proto>=3")
-	}
+
 	err := createTable(session, `CREATE TABLE gocql_test.tuple_map_scan_nil(
 			id int,
 			val frozen<tuple<int, int>>,
@@ -234,9 +220,7 @@ func TestTupleMapScanNil(t *testing.T) {
 func TestTupleMapScanNotSet(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()
-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("tuple types are only available of proto>=3")
-	}
+
 	err := createTable(session, `CREATE TABLE gocql_test.tuple_map_scan_not_set(
 			id int,
 			val frozen<tuple<int, int>>,
@@ -266,9 +250,7 @@ func TestTupleLastFieldEmpty(t *testing.T) {
 	// Regression test - empty value used to be treated as NULL value in the last tuple field
 	session := createSession(t)
 	defer session.Close()
-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("tuple types are only available of proto>=3")
-	}
+
 	err := createTable(session, `CREATE TABLE gocql_test.tuple_last_field_empty(
 			id int,
 			val frozen<tuple<text, text>>,
@@ -304,9 +286,6 @@ func TestTupleLastFieldEmpty(t *testing.T) {
 func TestTuple_NestedCollection(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()
-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("tuple types are only available of proto>=3")
-	}

 	err := createTable(session, `CREATE TABLE gocql_test.nested_tuples(
 		id int,
@@ -356,9 +335,6 @@ func TestTuple_NestedCollection(t *testing.T) {
 func TestTuple_NullableNestedCollection(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()
-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("tuple types are only available of proto>=3")
-	}

 	err := createTable(session, `CREATE TABLE gocql_test.nested_tuples_with_nulls(
 		id int,
diff --git a/udt_test.go b/udt_test.go
index 5eab841..48a13a2 100644
--- a/udt_test.go
+++ b/udt_test.go
@@ -72,10 +72,6 @@ func TestUDT_Marshaler(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("UDT are only available on protocol >= 3")
-	}
-
 	err := createTable(session, `CREATE TYPE gocql_test.position(
 		lat int,
 		lon int,
@@ -129,10 +125,6 @@ func TestUDT_Reflect(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("UDT are only available on protocol >= 3")
-	}
-
 	err := createTable(session, `CREATE TYPE gocql_test.horse(
 		name text,
 		owner text);`)
@@ -176,22 +168,10 @@ func TestUDT_Reflect(t *testing.T) {
 	}
 }

-func TestUDT_Proto2error(t *testing.T) {
-	// TODO(zariel): move this to marshal test?
-	_, err := Marshal(NativeType{custom: "org.apache.cassandra.db.marshal.UserType.Type", proto: 2}, 1)
-	if err != ErrorUDTUnavailable {
-		t.Fatalf("expected %v got %v", ErrUnavailable, err)
-	}
-}
-
 func TestUDT_NullObject(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("UDT are only available on protocol >= 3")
-	}
-
 	err := createTable(session, `CREATE TYPE gocql_test.udt_null_type(
 		name text,
 		owner text);`)
@@ -242,10 +222,6 @@ func TestMapScanUDT(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("UDT are only available on protocol >= 3")
-	}
-
 	err := createTable(session, `CREATE TYPE gocql_test.log_entry (
 		created_timestamp timestamp,
 		message text
@@ -329,10 +305,6 @@ func TestUDT_MissingField(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("UDT are only available on protocol >= 3")
-	}
-
 	err := createTable(session, `CREATE TYPE gocql_test.missing_field(
 		name text,
 		owner text);`)
@@ -379,10 +351,6 @@ func TestUDT_EmptyCollections(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("UDT are only available on protocol >= 3")
-	}
-
 	err := createTable(session, `CREATE TYPE gocql_test.nil_collections(
 		a list<text>,
 		b map<text, text>,
@@ -435,10 +403,6 @@ func TestUDT_UpdateField(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("UDT are only available on protocol >= 3")
-	}
-
 	err := createTable(session, `CREATE TYPE gocql_test.update_field_udt(
 		name text,
 		owner text);`)
@@ -492,10 +456,6 @@ func TestUDT_ScanNullUDT(t *testing.T) {
 	session := createSession(t)
 	defer session.Close()

-	if session.cfg.ProtoVersion < protoVersion3 {
-		t.Skip("UDT are only available on protocol >= 3")
-	}
-
 	err := createTable(session, `CREATE TYPE gocql_test.scan_null_udt_position(
 		lat int,
 		lon int,
